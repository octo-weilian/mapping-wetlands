{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for mapping wetland surface water dynamics using Sentinel-2 time-series data in combination with the Water Change Tracking algorithm (Chen et al., 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from rasterio.plot import reshape_as_image\n",
    "import re\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from rasterio.features import sieve\n",
    "\n",
    "from python.misc import compute_index, compute_ipm,strat_rand_sampling, calc_acc, plot_acc\n",
    "from python.wct import compute_cluster, compute_rws,compute_mnws,render_wcf\n",
    "\n",
    "import seaborn as sns\n",
    "from rasterio.features import rasterize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#setup I/O directories\n",
    "parent_dir = os.path.join(os.path.abspath('..'),'image_data')\n",
    "results_dir = os.path.join(parent_dir,'results')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Computing invalid pixel masks (cloud, cloud shadow, land vegetation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#mosaic and dates\n",
    "mosaics = glob(f'{parent_dir}/images/*.tif')\n",
    "dates = [re.findall(r\"(\\d{8})\", file)[0] for file in mosaics]\n",
    "\n",
    "#get reference mosaics based \n",
    "ref_dates = [20170119,20170119,20170327,20170327,20170615,20170615,20170720,20170824,20171008,20171008,20171117,20171117]\n",
    "ref_mosaics = [mos for date in ref_dates for mos in mosaics if str(date) in mos ]\n",
    "months = pd.to_datetime(dates).strftime('%Y%m').unique().tolist()\n",
    "ref_dict = dict(zip(months,ref_mosaics))\n",
    "\n",
    "#data mask file\n",
    "data_mask_file = os.path.join(results_dir,'misc','data_mask.tif')\n",
    "\n",
    "with rio.open(data_mask_file) as src_data_mask:\n",
    "    profile = src_data_mask.profile.copy()\n",
    "    data_mask = src_data_mask.read()\n",
    "    \n",
    "    #loop over mosaic files\n",
    "    for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "        file = mosaics[i]\n",
    "        ref_file = [ref_dict[key] for key in list(ref_dict.keys()) if key in file][0]\n",
    "        \n",
    "        with rio.open(file) as src,rio.open(ref_file) as src_ref:\n",
    "            \n",
    "            #target image\n",
    "            tar_img = np.where(src.read()<0,0,src.read()).astype(rio.int16)\n",
    "            tar_img = np.where(data_mask==1,tar_img ,src.nodata).astype(rio.int16)\n",
    "            \n",
    "            #reference image\n",
    "            ref_img = np.where(src_ref.read()<0,0,src_ref.read()).astype(rio.int16)\n",
    "            ref_img = np.where(data_mask==1,ref_img ,src.nodata).astype(rio.int16)\n",
    "            \n",
    "            #additional mask based on RWS region\n",
    "            mndwi_img = compute_index(tar_img[1],tar_img[9],'MNDWI')\n",
    "            mgrn_img = (tar_img[[1,2,7]].astype(np.float32)/10000).min(0)\n",
    "            rws_region = compute_rws(mndwi_img,mgrn_img,thr='otsu')\n",
    "            cl_masks = compute_ipm(tar_img[[0,1,2,7,9]],ref_img[[0,1,2,7,10]]).astype(rio.int8)\n",
    "            cl_masks = np.where((tar_img[0]!=src.nodata)&(rws_region!=1),cl_masks,0).astype(rio.int8)\n",
    "            \n",
    "            #write to new geotiff\n",
    "            profile.update({'dtype':cl_masks.dtype,'nodata':0,'count':1})\n",
    "            outf = os.path.join(results_dir,'invalid_pixel_masks',f'invalid_{dates[i]}.tif')\n",
    "            with rio.open(outf ,'w',**profile) as dst:\n",
    "                dst.write_band(1, cl_masks)\n",
    "                dst.set_band_description(1, f'invalid_{dates[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Computing Minimum Normalized Water Score (MNWS) images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#mnws computation\n",
    "mosaics = glob(f'{parent_dir}/images/*.tif')\n",
    "dates = [re.findall(r\"(\\d{8})\", file)[0] for file in mosaics]\n",
    "\n",
    "data_mask_file = os.path.join(results_dir,'misc','data_mask.tif')\n",
    "\n",
    "with rio.open(data_mask_file) as src_data_mask:\n",
    "\n",
    "    data_mask = src_data_mask.read()\n",
    "\n",
    "    for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "        file = mosaics[i]\n",
    "\n",
    "        with rio.open(file) as src:\n",
    "            profile = src.profile.copy()\n",
    "            img = src.read()\n",
    "            \n",
    "            #set negative values to 0 and apply data mask (based on Sentinel-2 missing data strips)\n",
    "            img = np.where(img<0,0,img)\n",
    "            img = np.where(data_mask==1,img,src.nodata).astype(rio.int16)\n",
    "\n",
    "            #compute water sample clusters\n",
    "            mndwi_img = compute_index(img[1],img[9],'MNDWI')\n",
    "            mgrn_img = (img[[1,2,7]].astype(np.float32)/10000).min(0)\n",
    "            rws_region = compute_rws(mndwi_img,mgrn_img,thr='otsu')\n",
    "            rws_img = np.where(rws_region==1,img,0)\n",
    "            cluster_img = compute_cluster(rws_img[[0,1,2]],k=8)\n",
    "\n",
    "            #compute MNWS image\n",
    "            mnws_img = compute_mnws(img[[0, 1, 2, 7, 9, 10]],cluster_img)\n",
    "            mnws_img = np.where(img[0]==src.nodata,src.nodata,mnws_img).astype(rio.float32)\n",
    "\n",
    "            #export MNWS image\n",
    "            profile.update(nodata=src.nodata,count=1,dtype=mnws_img.dtype)\n",
    "            outf = os.path.join(results_dir,'mnws_images',f'rws_mnws_{dates[i]}.tif')\n",
    "            with rio.open(outf,'w',**profile) as dst:\n",
    "                dst.write_band(1,mnws_img)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Computing Sentinel-2 based Dynamic Water Map (S2-DWM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mnws_files = glob(f'{parent_dir}/results/mnws_images/rws_mnw*.tif')\n",
    "cl_mask_files = glob(f'{parent_dir}/results/invalid_pixel_masks/invalid*.tif')\n",
    "upland_file = f'{os.path.abspath(\"..\")}results/misc/upland_gte30.tif'\n",
    "\n",
    "# #compute water coverage frequency map\n",
    "wf_rws,water_sum,profile = render_wcf(mnws_files,cl_mask_files,upland_file,thr=3,dec=2)\n",
    "\n",
    "#reclassify to water seasonality classes \n",
    "data_mask_file = f'{os.path.abspath(\"..\")}results/misc/data_mask.tif'\n",
    "\n",
    "with rio.open(data_mask_file) as src_data_mask:\n",
    "    \n",
    "    #used to assign non-water pixels (class value = 0)\n",
    "    data_mask = src_data_mask.read(1)\n",
    "    \n",
    "    #reclassification of WF image\n",
    "    dwm = wf_rws.copy()\n",
    "    wetland = ((dwm >0)&(dwm <3))*2     #wetland\n",
    "    sw = ((dwm >=3)&(dwm <=9))*3        #seasonal water\n",
    "    pw = (dwm>9)*4                      #permanent water\n",
    "    \n",
    "    dwm_sum = np.array([wetland,sw,pw]).sum(0)\n",
    "    dwm_out = np.where(dwm_sum>0,dwm_sum,data_mask).astype(rio.uint8)\n",
    "\n",
    "    #sieve data\n",
    "    dwm_out_sieved = sieve(dwm_out,size=30,connectivity=8)\n",
    "    \n",
    "    #export rasters\n",
    "    out_wf = os.path.join(results_dir,'waterfreq.tif')\n",
    "    profile.update({'dtype':wf_rws.dtype,'nodata':0,'count':1})\n",
    "    with rio.open(out_wf,'w',**profile) as dst: dst.write_band(1,wf_rws)\n",
    "\n",
    "    out_water_sum = os.path.join(results_dir,'watersum.tif')\n",
    "    profile.update({'dtype':rio.uint8,'nodata':0,'count':1})\n",
    "    with rio.open(out_water_sum,'w',**profile) as dst: dst.write_band(1,water_sum.astype(rio.uint8))\n",
    "\n",
    "    out_dwm = os.path.join(results_dir,'dwm.tif')\n",
    "    profile.update({'dtype':rio.uint8,'nodata':0,'count':1})\n",
    "    with rio.open(out_dwm ,'w',**profile) as dst: dst.write_band(1,dwm_out_sieved)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Performing stratified random sampling based on S2-DWM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create stratified random sample sites\n",
    "file = os.path.join(results_dir,'dwm.tif')\n",
    "gdf,block_img,block_profile = strat_rand_sampling(file=file,size=13,vstride_nr = 4,nodat=0,seed=42)\n",
    "\n",
    "#add class description\n",
    "gdf['desc'] = None\n",
    "for c_code,c_desc in zip(gdf['class'].unique(),['Nw','Wl','Sw','Pw']):\n",
    "    gdf.loc[gdf[gdf['class']==c_code].index,'desc'] = c_desc\n",
    "    \n",
    "#export sample points (raw)\n",
    "gdf.to_file('./data//samples/stratified_random_samples_raw.geojson',driver=\"GeoJSON\")\n",
    "\n",
    "#export image block\n",
    "with rio.open('./data//samples/sub_areas.tif','w',**block_profile) as dst:\n",
    "    dst.write_band(1,block_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Accuracy assessment\n",
    " * Sample points created in previous step were used to evaluate the map accuracies of S2-DWM and JRC-GSW-S\n",
    " * Note that the sample points were relocated because several points were located ambiguously\n",
    " * Labelling was done using AcATaMa QGIS plugin and Sentinel Hub EO Browser\n",
    " * A confidence rate was included for each sample point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S2-DWM and JRC-GSW-S\n",
    "dwm_file =  os.path.join(results_dir,'dwm.tif')\n",
    "jrc_file = os.path.join(results_dir,'misc','JRC_GSW_S_2017masked.tif')\n",
    "\n",
    "#sample points (relocated and labelled)\n",
    "sample_points = gpd.read_file(glob(f\"./data/samples/*classified.geojson\")[0])\n",
    "\n",
    "#sample_points\n",
    "with rio.open(dwm_file) as src_dwm,rio.open(jrc_file) as src_jrc:\n",
    "    coords = list((zip(sample_points['geometry'].centroid.x,sample_points['geometry'].centroid.y)))\n",
    "    sample_points['dwm_label'] = [val[0] for val in src_dwm.sample(coords)]\n",
    "    sample_points['gsw_label'] = [val[0]+1 for val in src_jrc.sample(coords)]\n",
    "\n",
    "    \n",
    "# S2-DWM all classes\n",
    "acc_df,con_mat = calc_acc(sample_points['true_label'],sample_points['dwm_label'])\n",
    "# plot_acc(acc_df,con_mat,sample_points['true_name'].unique(),0.73,'(a.) S2-DWM four classes')\n",
    "pd.concat([acc_df,con_mat],1).to_csv('./data/samples/acc_conmat/s2_dwm_4classes.csv')\n",
    "\n",
    "#s2-DWM nw, sw (+wetland) and pw\n",
    "acc_df,con_mat = calc_acc(sample_points['true_label'].replace(2,3),sample_points['dwm_label'].replace(2,3))\n",
    "# plot_acc(acc_df,con_mat,sample_points['true_name'].unique()[[0,2,3]],0.85,'(b.) S2-DWM three classes')\n",
    "pd.concat([acc_df,con_mat],1).to_csv('./data/samples/acc_conmat/s2_dwm_3classes.csv')\n",
    "\n",
    "#JRC-GSW-S nw , sw and pw\n",
    "acc_df,con_mat = calc_acc(sample_points['true_label'].replace(2,1),sample_points['gsw_label'].replace(2,1))\n",
    "# plot_acc(acc_df,con_mat,sample_points['true_name'].unique()[[0,2,3]],0.85,'(c.) JRC-GSW-S three classes')\n",
    "pd.concat([acc_df,con_mat],1).to_csv('./data/samples/acc_conmat/jrc_gsw_s_3classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F. Computing latitudinal and longitudinal surface water areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute lat lon surface water area\n",
    "\n",
    "dwm_file =  os.path.join(results_dir,'dwm.tif')\n",
    "jrc_file = os.path.join(results_dir,'misc','JRC_GSW_S_2017masked.tif')\n",
    "\n",
    "with rio.open(dwm_file) as src_dwm, rio.open(jrc_file) as src_jrc:\n",
    "    dwm_jrc = np.array([src_dwm.read(1) ,src_jrc.read(1)])\n",
    "    height = dwm_jrc.shape[1]\n",
    "    width = dwm_jrc.shape[2]\n",
    "    \n",
    "    steps = 10\n",
    "    \n",
    "    water_lat = {}\n",
    "    lat_steps = range(0,height,steps)\n",
    "    for lat in lat_steps:\n",
    "        water_lat[f\"lat_dwm_{lat}\"] = dwm_jrc[0,lat,:]\n",
    "        water_lat[f\"lat_jrc_{lat}\"] = dwm_jrc[1,lat,:]\n",
    "    water_lat_df = pd.DataFrame(water_lat)\n",
    "    water_lat_sum_dwm = pd.DataFrame(((water_lat_df.filter(regex=(\"dwm\"))==4)*1).sum(0)/100,columns=['Lat. S2-DWM (Pw)']).reset_index(drop=True)\n",
    "    water_lat_sum_jrc = pd.DataFrame(((water_lat_df.filter(regex=(\"jrc\"))==3)*1).sum(0)/100,columns=['Lat. JRC-GSW-S (Pw)']).reset_index(drop=True)\n",
    "    water_lat_sums_pw = pd.concat([water_lat_sum_dwm,water_lat_sum_jrc],1)\n",
    "    water_lat_sums_pw.index = np.array(lat_steps)/100\n",
    "    water_lat_sums_pw['km'] = water_lat_sums_pw.index\n",
    "    water_lat_sums_pw.to_csv('./data/water_lat_lon/water_lat_sums_pw.csv')\n",
    "    \n",
    "    water_lon = {}\n",
    "    lon_steps = range(0,width,steps)\n",
    "    for lon in lon_steps:\n",
    "        water_lon[f\"lon_dwm_{lon}\"] = dwm_jrc[0,:,lon]\n",
    "        water_lon[f\"lon_jrc_{lon}\"] = dwm_jrc[1,:,lon]\n",
    "    water_lon_df = pd.DataFrame(water_lon)\n",
    "    water_lon_sum_dwm = pd.DataFrame(((water_lon_df.filter(regex=(\"dwm\"))==4)*1).sum(0)/100,columns=['Lon. S2-DWM (Pw)']).reset_index(drop=True)\n",
    "    water_lon_sum_jrc = pd.DataFrame(((water_lon_df.filter(regex=(\"jrc\"))==3)*1).sum(0)/100,columns=['Lon. JRC-GSW-S (Pw)']).reset_index(drop=True)\n",
    "    water_lon_sums_pw = pd.concat([water_lon_sum_dwm,water_lon_sum_jrc],1)\n",
    "    water_lon_sums_pw.index = np.array(lon_steps)/100\n",
    "    water_lon_sums_pw['km'] = water_lon_sums_pw.index\n",
    "    water_lon_sums_pw.to_csv('./data/water_lat_lon/water_lon_sums_pw.csv')\n",
    "    \n",
    "    water_lat = {}\n",
    "    lat_steps = range(0,height,steps)\n",
    "    for lat in lat_steps:\n",
    "        water_lat[f\"lat_dwm_{lat}\"] = dwm_jrc[0,lat,:]\n",
    "        water_lat[f\"lat_jrc_{lat}\"] = dwm_jrc[1,lat,:]\n",
    "    water_lat_df = pd.DataFrame(water_lat)\n",
    "    water_lat_sum_dwm = pd.DataFrame(((water_lat_df.filter(regex=(\"dwm\"))==3)*1).sum(0)/100,columns=['Lat. S2-DWM (Sw)']).reset_index(drop=True)\n",
    "    water_lat_sum_dwm_wl = pd.DataFrame(((water_lat_df.filter(regex=(\"dwm\")).isin([2,3])*1).sum(0)/100),columns=['Lat. S2-DWM (Sw + Wl)']).reset_index(drop=True)\n",
    "    water_lat_sum_jrc = pd.DataFrame(((water_lat_df.filter(regex=(\"jrc\"))==2)*1).sum(0)/100,columns=['Lat. JRC-GSW-S (Sw)']).reset_index(drop=True)\n",
    "    water_lat_sums_sw = pd.concat([water_lat_sum_dwm,water_lat_sum_dwm_wl,water_lat_sum_jrc],1)\n",
    "    water_lat_sums_sw.index = np.array(lat_steps)/100\n",
    "    water_lat_sums_sw['km'] = water_lat_sums_sw.index\n",
    "    water_lat_sums_sw.to_csv('./data/water_lat_lon/water_lat_sums_sw.csv')\n",
    "    \n",
    "    water_lon = {}\n",
    "    lon_steps = range(0,width,steps)\n",
    "    for lon in lon_steps:\n",
    "        water_lon[f\"lon_dwm_{lon}\"] = dwm_jrc[0,:,lon]\n",
    "        water_lon[f\"lon_jrc_{lon}\"] = dwm_jrc[1,:,lon]\n",
    "    water_lon_df = pd.DataFrame(water_lon)\n",
    "    water_lon_sum_dwm = pd.DataFrame(((water_lon_df.filter(regex=(\"dwm\"))==3)*1).sum(0)/100,columns=['Lon. S2-DWM (Sw)']).reset_index(drop=True)\n",
    "    water_lon_sum_dwm_wl = pd.DataFrame(((water_lon_df.filter(regex=(\"dwm\")).isin([2,3])*1).sum(0)/100),columns=['Lon. S2-DWM (Sw + Wl)']).reset_index(drop=True)\n",
    "    water_lon_sum_jrc = pd.DataFrame(((water_lon_df.filter(regex=(\"jrc\"))==2)*1).sum(0)/100,columns=['Lon. JRC-GSW-S (Sw)']).reset_index(drop=True)\n",
    "    water_lon_sums_sw = pd.concat([water_lon_sum_dwm,water_lon_sum_dwm_wl,water_lon_sum_jrc],1)\n",
    "    water_lon_sums_sw.index = np.array(lon_steps)/100\n",
    "    water_lon_sums_sw['km'] = water_lon_sums_sw.index\n",
    "    water_lon_sums_sw.to_csv('./data/water_lat_lon/water_lon_sums_sw.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize lat lon water area\n",
    "\n",
    "sns.set(font_scale=1.8)\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "fig, axs = plt.subplots(2,2,figsize=(20,10),sharey=True)\n",
    "axs=axs.ravel()\n",
    "sns.lineplot(data=water_lat_sums_pw,dashes=False,ax=axs[0],palette=['blue','orange'])\n",
    "sns.lineplot(data=water_lon_sums_pw,dashes=False,ax=axs[1],palette=['blue','orange'])\n",
    "sns.lineplot(data=water_lat_sums_sw,dashes=False,ax=axs[2],palette=['blue','green','orange'])\n",
    "sns.lineplot(data=water_lon_sums_sw,dashes=False,ax=axs[3],palette=['blue','green','orange'])\n",
    "axs[2].set_xlabel('Distance from north to south (km)')\n",
    "axs[3].set_xlabel('Distance from west to east (km)')\n",
    "fig.text(0, 0.5, 'Surface water area (ha)', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "for i in range(len(axs)):\n",
    "    axs[i].margins(x=0)\n",
    "    if i<2:\n",
    "        axs[i].set_xticklabels([])\n",
    "        \n",
    "rmse_lat_pw = \"%.2f\" % np.sqrt(water_lat_sums_pw.iloc[:,1].sub(water_lat_sums_pw.iloc[:,0]).pow(2).mean())\n",
    "axs[0].text(0.59,0.65, f\"RMSE: {rmse_lat_pw}\", ha=\"left\", transform=axs[0].transAxes)\n",
    "\n",
    "rmse_lon_pw =\"%.2f\" % np.sqrt(water_lon_sums_pw.iloc[:,1].sub(water_lon_sums_pw.iloc[:,0]).pow(2).mean())\n",
    "axs[1].text(0.59,0.65, f\"RMSE: {rmse_lon_pw}\", ha=\"left\", transform=axs[1].transAxes)\n",
    "\n",
    "rmse_lat_sw = \"%.2f\" % np.sqrt(water_lat_sums_sw.iloc[:,2].sub(water_lat_sums_sw.iloc[:,0]).pow(2).mean())\n",
    "rmse_lat_sw_wl = \"%.2f\" % np.sqrt(water_lat_sums_sw.iloc[:,2].sub(water_lat_sums_sw.iloc[:,1]).pow(2).mean())\n",
    "axs[2].text(0.57,0.5, f\"RMSE (Sw): {rmse_lat_sw}\\nRMSE (Sw+Wl): {rmse_lat_sw_wl}\", ha=\"left\", transform=axs[2].transAxes)\n",
    "\n",
    "rmse_lon_sw =\"%.2f\" % np.sqrt(water_lon_sums_sw.iloc[:,2].sub(water_lon_sums_sw.iloc[:,0]).pow(2).mean())\n",
    "rmse_lon_sw_wl =\"%.2f\" % np.sqrt(water_lon_sums_sw.iloc[:,2].sub(water_lon_sums_sw.iloc[:,1]).pow(2).mean())\n",
    "axs[3].text(0.57,0.5, f\"RMSE (Sw): {rmse_lon_sw}\\nRMSE (Sw+Wl): {rmse_lon_sw_wl}\", ha=\"left\", transform=axs[3].transAxes)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#### G. Computing MNWS boxplot and spectral signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#extract MNWS and spectral pixel values\n",
    "\n",
    "long_names = ['Water','Settlement','Dark soil',' Bright soil','Vegetation','Agriculture','Cloud','Cloud shadow']\n",
    "labels = dict(zip(list(range(1,len(long_names)+1)),long_names))\n",
    "\n",
    "sample_files = glob('./data/samples/sample*.geojson')\n",
    "dates = list(map(lambda x:re.findall(r\"(\\d{8})\", x)[0],sample_files))\n",
    "mosaics = glob(f'{parent_dir}/images/*.tif')\n",
    "mosaics = [img for date in dates for img in mosaics if date in img]\n",
    "\n",
    "mnws_files = glob(f'{parent_dir}/results/mnws_images/rws_mnw*.tif')\n",
    "\n",
    "bands = ['B2','B3','B4','B5','B6','B7','B8','B8A','B11','B12']\n",
    "nm = ['490','560','665','705','750','783','842','865','1910','2190']\n",
    "band_names = [f'{a}\\n{b} nm' for a,b in zip(bands,nm)]\n",
    "\n",
    "all_band_data = []\n",
    "all_mnws_data = []\n",
    "for f in sample_files:\n",
    "    date = re.findall(r\"(\\d{8})\", f)[0]\n",
    "\n",
    "    gdf = gpd.read_file(f)\n",
    "    gdf = gdf.sort_values('code')\n",
    "    geom_code = list((zip(gdf ['geometry'].tolist(), gdf['code'].tolist() )))\n",
    "    \n",
    "    fmnws = f'{results_dir}/mnws_images/rws_mnws_{date}.tif'\n",
    "    fmos = f'{parent_dir}/images/mosaic_{date}.tif'\n",
    "        \n",
    "    with rio.open(fmos) as src, rio.open(fmnws) as src_mnws:\n",
    "    \n",
    "        img = src.read()\n",
    "        img = np.where(img<0,0,img)\n",
    "        img = img[[0,1,2,3,4,5,6,7,9,10]]\n",
    "        img_mnws = src_mnws.read()\n",
    "        sample_mask = rasterize(shapes=geom_code, out_shape=src.shape, transform=src.transform)\n",
    "        \n",
    "        #mnws stats\n",
    "        mnws_data = pd.concat([pd.DataFrame(img_mnws[:,sample_mask==code]).T for code in gdf['code'].unique()],axis=1)\n",
    "        mnws_data.columns = list(labels.values())\n",
    "        all_mnws_data.append(mnws_data)\n",
    "        \n",
    "        band_data = []\n",
    "        for code in gdf['code'].unique():\n",
    "            band_df = pd.DataFrame(img[:,sample_mask==code]).T.describe().loc[['mean','std']]/10000\n",
    "            band_df.columns = band_names\n",
    "            band_df['lc'] = labels[code]\n",
    "            band_data.append(band_df)\n",
    "            \n",
    "        band_data = pd.concat(band_data)\n",
    "        all_band_data.append(band_data)\n",
    "        \n",
    "#export data\n",
    "mnws_df = pd.concat(all_mnws_data).reset_index(drop=True)\n",
    "mnws_df.to_csv('./data/mnws_boxplot.csv')\n",
    "\n",
    "band_df = pd.concat(all_band_data)\n",
    "band_df.to_csv('./data/spectral_signature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot box\n",
    "mnws_df = pd.read_csv('./data/mnws_boxplot.csv')\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "flierprops = dict(marker='o',markerfacecolor='red', markersize=5,markeredgecolor='white')\n",
    "colors=['blue','orange','brown','yellow','green','purple','red','black']\n",
    "sns.boxplot(data=mnws_data,flierprops=flierprops,whis=[5, 95],orient='h',palette=colors,linewidth=1)\n",
    "plt.xlabel('MNWS',fontsize=16)\n",
    "plt.xticks(range(0, int(mnws_data.max().max()), 5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot spectral signature\n",
    "all_agg_mean = pd.read_csv('./data/spectral_signature.csv',index_col=0).loc['mean'].groupby('lc').mean().T[list(labels.values())]\n",
    "all_agg_std = pd.concat(all_band_data).loc['std'].groupby('lc').mean().T[list(labels.values())]\n",
    "lo_bound = all_agg_mean[['Water','Cloud shadow']]-all_agg_std[['Water','Cloud shadow']]\n",
    "hi_bound = all_agg_mean[['Water','Cloud shadow']]+all_agg_std[['Water','Cloud shadow']]\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "plt.figure(figsize=(15,10))\n",
    "colors=['blue','orange','brown','yellow','green','purple','red','black']\n",
    "lines = sns.lineplot(data=all_agg_mean,dashes=False,sort=False,palette=colors,legend=False)\n",
    "lines.lines[0].set_linestyle(\"--\")\n",
    "plt.legend(all_agg_mean.columns)\n",
    "plt.ylabel('Surface Reflectance')\n",
    "plt.fill_between(band_names,lo_bound['Water'], hi_bound['Water'], alpha=.3)\n",
    "plt.fill_between(band_names,lo_bound['Cloud shadow'], hi_bound['Cloud shadow'], alpha=.3,color=colors[-1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
