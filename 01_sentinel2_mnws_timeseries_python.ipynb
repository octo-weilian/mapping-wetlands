{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from rasterio.plot import reshape_as_image,reshape_as_raster\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from rasterio.mask import mask\n",
    "from rasterio.features import sieve\n",
    "\n",
    "from python.misc import compute_index\n",
    "\n",
    "import seaborn as sns\n",
    "from rasterio.features import rasterize\n",
    "import matplotlib.pyplot as plt\n",
    "from affine import Affine\n",
    "\n",
    "#setup I/O directories\n",
    "parent_dir = os.path.join(os.path.abspath('..'),'image_data')\n",
    "results_dir = os.path.join(parent_dir,'results')\n",
    "mosaics = glob(f'{parent_dir}/images/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat_rand_sampling(file,size,vstride_nr,nodat=0,seed=None):\n",
    "    #set seed for numpy random \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    data = []\n",
    "    with rio.open(file) as src:\n",
    "        \n",
    "        #translate rows, cols to xy coordinates\n",
    "        T0 = src.transform\n",
    "        T1 = T0 * Affine.translation(0.5, 0.5)\n",
    "        rc2xy = lambda r, c: T1 * (c, r) \n",
    "\n",
    "        img = src.read(1)\n",
    "        profile = src.profile.copy()\n",
    "        block_img = img.copy()\n",
    "        \n",
    "        vstride = int(block_img.shape[0]/vstride_nr)\n",
    "        \n",
    "        for i in range(0,block_img.shape[0],vstride):\n",
    "            random_label = int((i+vstride)/100)\n",
    "            if i+vstride<block_img.shape[0]:\n",
    "                block_img[i:i+vstride,:][block_img[i:i+vstride,:]>=0] = random_label\n",
    "            else:\n",
    "                block_img[i:,:][block_img[i:,:]>=0] = random_label\n",
    "            \n",
    "        stack_img = np.where(img>0,block_img,nodat).astype(rio.uint16)\n",
    "        \n",
    "        strata = np.unique(stack_img)[np.unique(stack_img)!=nodat]\n",
    "        classes = np.unique(img)[np.unique(img)!=nodat]\n",
    "        \n",
    "        for grid in strata: \n",
    "            for c in classes:\n",
    "                rows,cols = np.where((img==c)&(stack_img==grid))\n",
    "        \n",
    "                if len(rows)!=0:\n",
    "                    idx = np.random.choice(range(len(cols)), size, replace=False)\n",
    "                    stratified_samples = np.array([rc2xy(x, y) for x,y in zip(rows[idx],cols[idx]) ])\n",
    "                    x,y = stratified_samples[:,0],stratified_samples[:,1]\n",
    "                    gdf = gpd.GeoDataFrame(crs=str(src.crs), geometry=gpd.points_from_xy(x,y))\n",
    "                    gdf['class'] = c\n",
    "                    data.append(gdf)\n",
    "        \n",
    "        profile.update(nodata=0,dtype=stack_img.dtype)\n",
    "        data_cat = pd.concat(data,ignore_index=True)\n",
    "        return data_cat,stack_img.astype(rio.uint8),profile\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "def calc_acc(y_true,y_pred):\n",
    "    \n",
    "    observed = y_true.rename('Observed')\n",
    "    classified = y_pred.rename('Classified')\n",
    "    con_mat = pd.crosstab(classified,observed)\n",
    "    \n",
    "    row_sum = con_mat.sum(axis=1)\n",
    "    col_sum = con_mat.sum(axis=0)\n",
    "    omitted = np.setdiff1d(col_sum.index,row_sum.index)\n",
    "    col_sum = col_sum.drop(omitted)\n",
    "    \n",
    "    ua = np.diag(con_mat)/row_sum\n",
    "    pa = np.diag(con_mat)/col_sum\n",
    "    f1 = (2 * pa*ua) /(pa+ua)\n",
    "    \n",
    "    acc_df = round(pd.DataFrame({'Label':col_sum.index,'PA':pa.values,'UA':ua.values,'F1-score':f1.values}),2).fillna(0)\n",
    "    acc_df.set_index('Label',inplace=True)\n",
    "    \n",
    "    \n",
    "    return acc_df,con_mat\n",
    "\n",
    "\n",
    "def plot_acc(acc_df,con_mat,labels,oa_alt=None,fig_text=None):\n",
    "    \n",
    "    acc_df = acc_df.copy()\n",
    "    con_mat = con_mat.copy()\n",
    "    \n",
    "    oa =np.diag(con_mat).sum()/con_mat.sum().sum()  \n",
    "\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': '0'})\n",
    "\n",
    "    fig, axs = plt.subplots(1,2,figsize=(12,5))\n",
    "\n",
    "    con_mat.columns = [f'{b}\\n{a}' for a,b in zip(labels,con_mat.sum(0))]\n",
    "    con_mat.index = [f'{a}\\n{b}' for a,b in zip(labels,con_mat.sum(1))]\n",
    "    \n",
    "    con_mat_plot = sns.heatmap(con_mat,annot=True,cbar=False,ax=axs[0],cmap='Blues')\n",
    "    axs[0].set_xlabel('Observed')\n",
    "    axs[0].set_ylabel('Classified')\n",
    "    for _, spine in con_mat_plot.spines.items(): \n",
    "        spine.set_visible(True)\n",
    "    \n",
    "    acc_df.index = labels\n",
    "    sns.lineplot(data=acc_df,ax=axs[1],dashes=False,sort=False)\n",
    "    sns.scatterplot(data = acc_df,ax=axs[1])\n",
    "    plt.ylim(0.35, 1)\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].set_xlabel('Label')\n",
    "    \n",
    "    leg = axs[1].legend(acc_df.columns.tolist()+[f'OA: { \"%.2f\" % oa} ({oa_alt}*)'],loc='best')\n",
    "    leg.get_lines()[-1].set_visible(False)\n",
    "    axs[0].text(-0.90,1.05,fig_text,horizontalalignment='center',verticalalignment='center',transform=axs[1].transAxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#cloud masks computation monthly best reference image\n",
    "\n",
    "#mosaics\n",
    "mosaics = glob(f'{os.path.abspath(\"..\")}images/*.tif')\n",
    "dates = [re.findall(r\"(\\d{8})\", file)[0] for file in mosaics]\n",
    "\n",
    "#reference mosaics\n",
    "ref_dates = [20170119,20170119,20170327,20170327,20170615,20170615,20170720,20170824,20171008,20171008,20171117,20171117]\n",
    "ref_mosaics = [mos for date in ref_dates for mos in mosaics if str(date) in mos ]\n",
    "months = pd.to_datetime(dates).strftime('%Y%m').unique().tolist()\n",
    "ref_dict = dict(zip(months,ref_mosaics))\n",
    "\n",
    "data_mask_file = f'{os.path.abspath(\"..\")}results/data_mask.tif'\n",
    "\n",
    "with rio.open(data_mask_file) as src_data_mask:\n",
    "    data_mask = src_data_mask.read()\n",
    "\n",
    "    for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "        file = mosaics[i]\n",
    "        outf = f'{ os.path.abspath(\"..\") }results/invalid_masks_min400_ndvi03/invalid_{dates[i]}.tif'\n",
    "\n",
    "        ref_file = [ref_dict[key] for key in list(ref_dict.keys()) if key in file][0]\n",
    "\n",
    "        with rio.open(file) as src,rio.open(ref_file) as src_ref:\n",
    "            profile = src.profile.copy()\n",
    "            src_img = np.where(src.read()<0,0,src.read()).astype(rio.int16)\n",
    "            src_img = np.where(data_mask==1,src_img ,src.nodata).astype(rio.int16)\n",
    "            \n",
    "            src_ref_img = np.where(src_ref.read()<0,0,src_ref.read()).astype(rio.int16)\n",
    "            src_ref_img = np.where(data_mask==1,src_ref_img ,src.nodata).astype(rio.int16)\n",
    "            \n",
    "            _,rws = compute_rws(src_img,'MNDWI','otsu')\n",
    "            cl_masks = multitemp_clmasks(src_img,src_ref_img).astype(rio.int8)\n",
    "            cl_masks = np.where((src_img[0]!=src.nodata)&(rws!=1),cl_masks,0).astype(rio.int8)\n",
    "            \n",
    "            #write to new geotiff\n",
    "            profile.update({'dtype':cl_masks.dtype,'nodata':0,'count':1})\n",
    "            with rio.open(outf ,'w',**profile) as dst:\n",
    "                dst.write_band(1, cl_masks)\n",
    "                dst.set_band_description(1, f'invalid_{dates[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#mnws computation\n",
    "mosaics = glob(f'{os.path.abspath(\"..\")}images/*.tif')\n",
    "\n",
    "data_mask_file = f'{os.path.abspath(\"..\")}results/misc/data_mask.tif'\n",
    "\n",
    "with rio.open(data_mask_file) as src_data_mask:\n",
    "\n",
    "    data_mask = src_data_mask.read()\n",
    "\n",
    "    for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "        file = mosaics[i]\n",
    "\n",
    "        outf = f'{os.path.abspath(\"..\")}results/rws_mnws_mndwi_otsu/{os.path.basename(file)}'.replace('mosaic','rws_mnws_test')\n",
    "\n",
    "        with rio.open(file) as src:\n",
    "            profile = src.profile.copy()\n",
    "            img = src.read()\n",
    "            \n",
    "            #set negative values to 0 and apply data mask (based on Sentinel-2 missing data strips)\n",
    "            img = np.where(img<0,0,img)\n",
    "            img = np.where(data_mask==1,img,src.nodata).astype(rio.int16)\n",
    "\n",
    "            #compute water sample clusters\n",
    "            mndwi_img = compute_index(img[1],img[9],'MNDWI')\n",
    "            mgrn_img = (img[[1,2,7]].astype(np.float32)/10000).min(0)\n",
    "            rws_region = compute_rws(mndwi_img,mgrn_img,thr='otsu')\n",
    "            rws_img = np.where(rws_region==1,img,0)\n",
    "            cluster_img = compute_cluster(rws_img[[0,1,2]],k=8)\n",
    "\n",
    "            #compute MNWS image\n",
    "            mnws_img = compute_mnws(img[[0, 1, 2, 7, 9, 10]],cluster_img)\n",
    "            mnws_img = np.where(img[0]==src.nodata,src.nodata,mnws_img).astype(rio.float32)\n",
    "\n",
    "            #export MNWS image\n",
    "            profile.update(nodata=src.nodata,count=1,dtype=mnws_img.dtype)\n",
    "            with rio.open(outf,'w',**profile) as dst:\n",
    "                dst.write_band(1,mnws_img)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# #compute water coverage frequency map\n",
    "mnws_files = glob(f\"{os.path.abspath('..')}results/rws_mnws_mndwi_otsu/rws*.tif\")\n",
    "cl_mask_files = glob(f\"{os.path.abspath('..')}results/invalid_masks_min400_ndvi05/invalid*.tif\")\n",
    "upland_file = f\"{os.path.abspath('..')}results/misc/upland_gte30.tif\"\n",
    "\n",
    "wf_rws,water_sum,profile = wcf(mnws_files,cl_mask_files,upland_file,thr=3,dec=2)\n",
    "\n",
    "#reclassify to water body types\n",
    "data_mask_file = f'{os.path.abspath(\"..\")}results/misc/data_mask.tif'\n",
    "\n",
    "with rio.open(data_mask_file) as src_data_mask:\n",
    "    \n",
    "    #used to assign non-water pixels (class value = 0)\n",
    "    data_mask = src_data_mask.read(1)\n",
    "    \n",
    "    #reclassification of WF image\n",
    "    dwm = wf_rws.copy()\n",
    "    wetland = ((dwm >0)&(dwm <3))*2     #wetland\n",
    "    sw = ((dwm >=3)&(dwm <=9))*3        #seasonal water\n",
    "    pw = (dwm>9)*4                      #permanent water\n",
    "    \n",
    "    dwm_sum = np.array([wetland,sw,pw]).sum(0)\n",
    "    dwm_out = np.where(dwm_sum>0,dwm_sum,data_mask).astype(rio.uint8)\n",
    "\n",
    "    #sieve data\n",
    "    dwm_out_sieved = sieve(dwm_out,size=30,connectivity=8)\n",
    "    \n",
    "    #export rasters\n",
    "    out_wf = f\"{os.path.abspath('..')}results/wf_rws.tif\"\n",
    "    profile.update({'dtype':wf_rws.dtype,'nodata':0,'count':1})\n",
    "    with rio.open(out_wf,'w',**profile) as dst: dst.write_band(1,wf_rws)\n",
    "\n",
    "    out_water_sum = f\"{os.path.abspath('..')}results/watersum.tif\"\n",
    "    profile.update({'dtype':rio.uint8,'nodata':0,'count':1})\n",
    "    with rio.open(out_water_sum,'w',**profile) as dst: dst.write_band(1,water_sum.astype(rio.uint8))\n",
    "\n",
    "    out_dwm = f\"{os.path.abspath('..')}results/dwm.tif\"\n",
    "    profile.update({'dtype':rio.uint8,'nodata':0,'count':1})\n",
    "    with rio.open(out_dwm ,'w',**profile) as dst: dst.write_band(1,dwm_out_sieved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-(14/55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dwm_file =  f\"{os.path.abspath('..')}results/dwm.tif\"\n",
    "jrc_file= f\"{os.path.abspath('..')}ancillary_data/YearlyHistory_2017_masked.tif\"\n",
    "sample_points = gpd.read_file(glob(f\"./data/sample/accuracy_assesment/*classified.geojson\")[0])\n",
    "# sample_points = sample_points[sample_points.rating=='high']\n",
    "with rio.open(dwm_file) as src_dwm,rio.open(jrc_file) as src_jrc:\n",
    "    coords = list((zip(sample_points['geometry'].centroid.x,sample_points['geometry'].centroid.y)))\n",
    "    sample_points['dwm_label'] = [val[0] for val in src_dwm.sample(coords)]\n",
    "    sample_points['gsw_label'] = [val[0]+1 for val in src_jrc.sample(coords)]\n",
    "\n",
    "# sample_points = sample_points[sample_points['rating']=='high']\n",
    "# S2-DWM all classes\n",
    "acc_df,con_mat = calc_acc(sample_points['true_label'],sample_points['dwm_label'])\n",
    "plot_acc(acc_df,con_mat,sample_points['true_name'].unique(),0.73,'(a.) S2-DWM four classes')\n",
    "print(acc_df)\n",
    "#s2-DWM nw, sw (+wetland) and pw\n",
    "acc_df,con_mat = calc_acc(sample_points['true_label'].replace(2,3),sample_points['dwm_label'].replace(2,3))\n",
    "plot_acc(acc_df,con_mat,sample_points['true_name'].unique()[[0,2,3]],0.85,'(b.) S2-DWM three classes')\n",
    "print(acc_df)\n",
    "# #JRC-GSW-S nw, wl (original nw), sw and nw\n",
    "# acc_df,con_mat = calc_acc(sample_points['true_label'],sample_points['gsw_label'])\n",
    "# plot_acc(acc_df,con_mat,sample_points['true_name'].unique(),0.82,'(c.) JRC-GSW-S four classes')\n",
    "# print(acc_df)\n",
    "\n",
    "#JRC-GSW-S nw (original nw and all not pixels not classified), sw and pw\n",
    "acc_df,con_mat = calc_acc(sample_points['true_label'].replace(2,1),sample_points['gsw_label'].replace(2,1))\n",
    "plot_acc(acc_df,con_mat,sample_points['true_name'].unique()[[0,2,3]],0.85,'(c.) JRC-GSW-S three classes')\n",
    "print(acc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lat lon surface water area\n",
    "\n",
    "dwm_file =  f\"{os.path.abspath('..')}results/dwm.tif\"\n",
    "jrc_file= f\"{os.path.abspath('..')}ancillary_data/YearlyHistory_2017_masked.tif\"\n",
    "\n",
    "with rio.open(dwm_file) as src_dwm, rio.open(jrc_file) as src_jrc:\n",
    "    water_maps = np.array([src_dwm.read(1) ,src_jrc.read(1)])\n",
    "    height = water_maps.shape[1]\n",
    "    width = water_maps.shape[2]\n",
    "    \n",
    "    steps = 10\n",
    "    \n",
    "    water_lat = {}\n",
    "    lat_steps = range(0,height,steps)\n",
    "    for lat in lat_steps:\n",
    "        water_lat[f\"lat_dwm_{lat}\"] = dwm_jrc[0,lat,:]\n",
    "        water_lat[f\"lat_jrc_{lat}\"] = dwm_jrc[1,lat,:]\n",
    "    water_lat_df = pd.DataFrame(water_lat)\n",
    "    water_lat_sum_dwm = pd.DataFrame(((water_lat_df.filter(regex=(\"dwm\"))==4)*1).sum(0)/100,columns=['Lat. S2-DWM (Pw)']).reset_index(drop=True)\n",
    "    water_lat_sum_jrc = pd.DataFrame(((water_lat_df.filter(regex=(\"jrc\"))==3)*1).sum(0)/100,columns=['Lat. JRC-GSW-S (Pw)']).reset_index(drop=True)\n",
    "    water_lat_sums_pw = pd.concat([water_lat_sum_dwm,water_lat_sum_jrc],1)\n",
    "    water_lat_sums_pw.index = np.array(lat_steps)/100\n",
    "    \n",
    "    water_lon = {}\n",
    "    lon_steps = range(0,width,steps)\n",
    "    for lon in lon_steps:\n",
    "        water_lon[f\"lon_dwm_{lon}\"] = dwm_jrc[0,:,lon]\n",
    "        water_lon[f\"lon_jrc_{lon}\"] = dwm_jrc[1,:,lon]\n",
    "    water_lon_df = pd.DataFrame(water_lon)\n",
    "    water_lon_sum_dwm = pd.DataFrame(((water_lon_df.filter(regex=(\"dwm\"))==4)*1).sum(0)/100,columns=['Lon. S2-DWM (Pw)']).reset_index(drop=True)\n",
    "    water_lon_sum_jrc = pd.DataFrame(((water_lon_df.filter(regex=(\"jrc\"))==3)*1).sum(0)/100,columns=['Lon. JRC-GSW-S (Pw)']).reset_index(drop=True)\n",
    "    water_lon_sums_pw = pd.concat([water_lon_sum_dwm,water_lon_sum_jrc],1)\n",
    "    water_lon_sums_pw.index = np.array(lon_steps)/100\n",
    "    \n",
    "    water_lat = {}\n",
    "    lat_steps = range(0,height,steps)\n",
    "    for lat in lat_steps:\n",
    "        water_lat[f\"lat_dwm_{lat}\"] = dwm_jrc[0,lat,:]\n",
    "        water_lat[f\"lat_jrc_{lat}\"] = dwm_jrc[1,lat,:]\n",
    "    water_lat_df = pd.DataFrame(water_lat)\n",
    "    water_lat_sum_dwm = pd.DataFrame(((water_lat_df.filter(regex=(\"dwm\"))==3)*1).sum(0)/100,columns=['Lat. S2-DWM (Sw)']).reset_index(drop=True)\n",
    "    water_lat_sum_dwm_wl = pd.DataFrame(((water_lat_df.filter(regex=(\"dwm\")).isin([2,3])*1).sum(0)/100),columns=['Lat. S2-DWM (Sw + Wl)']).reset_index(drop=True)\n",
    "    water_lat_sum_jrc = pd.DataFrame(((water_lat_df.filter(regex=(\"jrc\"))==2)*1).sum(0)/100,columns=['Lat. JRC-GSW-S (Sw)']).reset_index(drop=True)\n",
    "    water_lat_sums_sw = pd.concat([water_lat_sum_dwm,water_lat_sum_dwm_wl,water_lat_sum_jrc],1)\n",
    "    water_lat_sums_sw.index = np.array(lat_steps)/100\n",
    "    \n",
    "    water_lon = {}\n",
    "    lon_steps = range(0,width,steps)\n",
    "    for lon in lon_steps:\n",
    "        water_lon[f\"lon_dwm_{lon}\"] = dwm_jrc[0,:,lon]\n",
    "        water_lon[f\"lon_jrc_{lon}\"] = dwm_jrc[1,:,lon]\n",
    "    water_lon_df = pd.DataFrame(water_lon)\n",
    "    water_lon_sum_dwm = pd.DataFrame(((water_lon_df.filter(regex=(\"dwm\"))==3)*1).sum(0)/100,columns=['Lon. S2-DWM (Sw)']).reset_index(drop=True)\n",
    "    water_lon_sum_dwm_wl = pd.DataFrame(((water_lon_df.filter(regex=(\"dwm\")).isin([2,3])*1).sum(0)/100),columns=['Lon. S2-DWM (Sw + Wl)']).reset_index(drop=True)\n",
    "    water_lon_sum_jrc = pd.DataFrame(((water_lon_df.filter(regex=(\"jrc\"))==2)*1).sum(0)/100,columns=['Lon. JRC-GSW-S (Sw)']).reset_index(drop=True)\n",
    "    water_lon_sums_sw = pd.concat([water_lon_sum_dwm,water_lon_sum_dwm_wl,water_lon_sum_jrc],1)\n",
    "    water_lon_sums_sw.index = np.array(lon_steps)/100\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.8)\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "fig, axs = plt.subplots(2,2,figsize=(20,10),sharey=True)\n",
    "axs=axs.ravel()\n",
    "sns.lineplot(data=water_lat_sums_pw,dashes=False,ax=axs[0],palette=['blue','orange'])\n",
    "sns.lineplot(data=water_lon_sums_pw,dashes=False,ax=axs[1],palette=['blue','orange'])\n",
    "sns.lineplot(data=water_lat_sums_sw,dashes=False,ax=axs[2],palette=['blue','green','orange'])\n",
    "sns.lineplot(data=water_lon_sums_sw,dashes=False,ax=axs[3],palette=['blue','green','orange'])\n",
    "axs[2].set_xlabel('Distance from north to south (km)')\n",
    "axs[3].set_xlabel('Distance from west to east (km)')\n",
    "fig.text(0, 0.5, 'Surface water area (ha)', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "for i in range(len(axs)):\n",
    "    axs[i].margins(x=0)\n",
    "    if i<2:\n",
    "        axs[i].set_xticklabels([])\n",
    "        \n",
    "rmse_lat_pw = \"%.2f\" % np.sqrt(water_lat_sums_pw.iloc[:,1].sub(water_lat_sums_pw.iloc[:,0]).pow(2).mean())\n",
    "axs[0].text(0.59,0.65, f\"RMSE: {rmse_lat_pw}\", ha=\"left\", transform=axs[0].transAxes)\n",
    "\n",
    "rmse_lon_pw =\"%.2f\" % np.sqrt(water_lon_sums_pw.iloc[:,1].sub(water_lon_sums_pw.iloc[:,0]).pow(2).mean())\n",
    "axs[1].text(0.59,0.65, f\"RMSE: {rmse_lon_pw}\", ha=\"left\", transform=axs[1].transAxes)\n",
    "\n",
    "rmse_lat_sw = \"%.2f\" % np.sqrt(water_lat_sums_sw.iloc[:,2].sub(water_lat_sums_sw.iloc[:,0]).pow(2).mean())\n",
    "rmse_lat_sw_wl = \"%.2f\" % np.sqrt(water_lat_sums_sw.iloc[:,2].sub(water_lat_sums_sw.iloc[:,1]).pow(2).mean())\n",
    "axs[2].text(0.57,0.5, f\"RMSE (Sw): {rmse_lat_sw}\\nRMSE (Sw+Wl): {rmse_lat_sw_wl}\", ha=\"left\", transform=axs[2].transAxes)\n",
    "\n",
    "rmse_lon_sw =\"%.2f\" % np.sqrt(water_lon_sums_sw.iloc[:,2].sub(water_lon_sums_sw.iloc[:,0]).pow(2).mean())\n",
    "rmse_lon_sw_wl =\"%.2f\" % np.sqrt(water_lon_sums_sw.iloc[:,2].sub(water_lon_sums_sw.iloc[:,1]).pow(2).mean())\n",
    "axs[3].text(0.57,0.5, f\"RMSE (Sw): {rmse_lon_sw}\\nRMSE (Sw+Wl): {rmse_lon_sw_wl}\", ha=\"left\", transform=axs[3].transAxes)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#time-series analysis\n",
    "\n",
    "dwm_file = f\"{os.path.abspath('..')}results/dwm.tif\"\n",
    "mnws_files = glob(f\"{os.path.abspath('..')}results/rws_mnws_mndwi_otsu/rws*.tif\")\n",
    "cl_mask_files = glob(f\"{os.path.abspath('..')}results/invalid_masks_min400_ndvi05/invalid*.tif\")\n",
    "mosaics = glob(f'{os.path.abspath(\"..\")}images/*.tif')\n",
    "dates = [re.findall(r\"(\\d{8})\", file)[0] for file in mosaics]\n",
    "\n",
    "wetland_file = \"./data/boundaries/high_vegetated.geojson\"\n",
    "wetland_geo = gpd.read_file(wetland_file)\n",
    "\n",
    "with rio.open(dwm_file) as src_dwm:\n",
    "    \n",
    "    dwm,_ = mask(src_dwm, wetland_geo.geometry, crop=True)\n",
    "    dwm = np.where(dwm==2,3,dwm)[0]\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "\n",
    "        with rio.open(mosaics[i]) as src, rio.open(mnws_files[i]) as src_mnws,rio.open(cl_mask_files[i]) as src_clm:\n",
    "\n",
    "            img,_ = mask(src, wetland_geo.geometry, crop=True)\n",
    "            clm,_ = mask(src_clm, wetland_geo.geometry, crop=True)\n",
    "            mnws,_ = mask(src_mnws, wetland_geo.geometry, crop=True)\n",
    "            \n",
    "            img = np.where(img<0,0,img)\n",
    "            ndvi = compute_index(img,'NDVI')\n",
    "            mndwi = compute_index(img,'MNDWI')\n",
    "            \n",
    "            wi_arr = np.array([ndvi,mndwi,mnws[0]])\n",
    "            wi_arr = np.where(clm>0,9999,wi_arr)\n",
    "            \n",
    "            values = []\n",
    "            for i in [1,3,4]:\n",
    "                val_arr = np.where(wi_arr[:,dwm==i]!=9999,wi_arr[:,dwm==i],np.nan)\n",
    "                values += np.nanmedian(val_arr,1).tolist()\n",
    "            data.append(values)\n",
    "    df = pd.DataFrame(np.array(data))\n",
    "    df.columns = ['NDVI_NW','MNDWI_NW','MNWS_NW','NDVI_SW','MNDWI_SW','MNWS_SW','NDVI_PW','MNDWI_PW','MNWS_PW']\n",
    "    df = df.set_index(pd.to_datetime(dates))\n",
    "    df.to_csv('./data/dwm_median_values_aoi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "\n",
    "df = pd.read_csv('./data/dwm_median_values_aoi.csv',index_col=[0])\n",
    "df.columns = ['NDVI (Nw)','MNDWI (Nw)','MNWS (Nw)','NDVI (Sw)','MNDWI (Sw)','MNWS (Sw)','NDVI (Pw)','MNDWI (Pw)','MNWS (Pw)']\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.resample('D').interpolate(method='linear')\n",
    "df.index = df.index.strftime('%d-%b')\n",
    "\n",
    "fig, axs = plt.subplots(3,2,figsize=(15,10),sharex=True)\n",
    "axs = axs.ravel()\n",
    "\n",
    "colors=['green','blue']\n",
    "for i,d in enumerate(df.iloc[:,:2].columns):\n",
    "    axs[0].plot(df.iloc[:,:2][d],color=colors[i])\n",
    "axs[1].plot(df.iloc[:,2:3],color='red')\n",
    "axs[1].axhline(3, 8,0,ls='--',color='black',lw=2)\n",
    "axs[0].legend(['NDVI','MNDWI'])\n",
    "axs[1].legend(['MNWS']);\n",
    "\n",
    "for i,d in enumerate(df.iloc[:,3:5].columns):\n",
    "    axs[2].plot(df.iloc[:,3:5][d],color=colors[i])\n",
    "axs[3].plot(df.iloc[:,5:6],color='red')\n",
    "axs[3].axhline(3, 8,0,ls='--',color='black',lw=2)\n",
    "\n",
    "\n",
    "for i,d in enumerate(df.iloc[:,6:8].columns):\n",
    "    axs[4].plot(df.iloc[:,6:8][d],color=colors[i])\n",
    "\n",
    "axs[5].plot(df.iloc[:,8:],color='red')\n",
    "axs[5].axhline(3, 8,0,ls='--',color='black',lw=2)\n",
    "\n",
    "\n",
    "\n",
    "fig.text(0.01, 0.5, 'Value', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "axs[0].text(0.05,1.1,'(a.) Non-water',horizontalalignment='center',verticalalignment='center',transform=axs[0].transAxes)\n",
    "axs[2].text(0.05,1.1,'(b.) Seasonal water',horizontalalignment='center',verticalalignment='center',transform=axs[2].transAxes)\n",
    "axs[4].text(0.05,1.1,'(c.) Permanent water',horizontalalignment='center',verticalalignment='center',transform=axs[4].transAxes)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.margins(x=0)\n",
    "\n",
    "    ax.xaxis.set_ticks(np.arange(0, len(df),31))\n",
    "    ax.set_xticklabels(df.index[::31].str.split('-').str[-1])\n",
    "    ax.axvline(np.where(df.index=='25-Feb')[0][0],0,.05,ls='--',color='blue',lw=5)\n",
    "    ax.axvline(np.where(df.index=='19-May')[0][0],0,.05,ls='--',color='blue',lw=5)\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "data= []\n",
    "for c in df.columns:\n",
    "    summary = round(df[c].describe(),1)\n",
    "    summary['var'] = df[c].var()\n",
    "    summary['median'] = df[c].median()\n",
    "    data.append(summary)\n",
    "data_df = pd.concat(data,1).T[['std','var','min','median','max']].T\n",
    "sns.heatmap(data_df.T,annot=True,cbar=False,cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rain_df.sort_values('mm',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create stratified random samples\n",
    "file = glob(f'{os.path.abspath(\"..\")}results/dwm*.tif')[0]\n",
    "\n",
    "seed = 42\n",
    "\n",
    "gdf,block_img,block_profile = strat_rand_sampling(file=file,size=13,vstride_nr = 4,nodat=0,seed=seed)\n",
    "\n",
    "\n",
    "print(gdf.groupby('class').count())\n",
    "\n",
    "#drop class with sample points larger than 50\n",
    "# indices2drop = gdf[gdf['class']==1].sample(n=5,random_state = seed).index\n",
    "# gdf = gdf.drop(indices2drop).reset_index(drop=True)\n",
    "\n",
    "#add class description\n",
    "gdf['desc'] = None\n",
    "for c_code,c_desc in zip(gdf['class'].unique(),['Nw','Wl','Sw','Pw']):\n",
    "    gdf.loc[gdf[gdf['class']==c_code].index,'desc'] = c_desc\n",
    "    \n",
    "print(gdf.groupby('class').count())\n",
    "\n",
    "#xport sample points\n",
    "gdf_file = './data//sample/stratified_random_52samples_segmented.geojson'\n",
    "gdf.to_file(gdf_file,driver=\"GeoJSON\")\n",
    "\n",
    "#xport image block\n",
    "with rio.open('./data//sample/blocks.tif','w',**profile) as dst:\n",
    "    dst.write_band(1,block_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = glob(f'{os.path.abspath(\"..\")}results/dwm*.tif')[0]\n",
    "file_jrc = glob(f'{os.path.abspath(\"..\")}ancillary_data/YearlyHistory_2017_masked.tif')[0]\n",
    "\n",
    "data_mask_file = f'{os.path.abspath(\"..\")}results/misc/data_mask.tif'\n",
    "\n",
    "with rio.open(file) as src, rio.open(file_jrc) as src_jrc,rio.open(data_mask_file) as src_datamask:\n",
    "    s2_img = src.read()\n",
    "    jrc_img = src_jrc.read()\n",
    "    datamask_img = src_datamask.read()\n",
    "    jrc_img = np.where(datamask_img==1,jrc_img,9999)\n",
    "    \n",
    "    s2_count = pd.DataFrame(np.unique(s2_img[s2_img!=0],return_counts=True)[1]).T\n",
    "    jrc_count = pd.DataFrame(np.unique(jrc_img[jrc_img!=9999],return_counts=True)[1]).T\n",
    "    count_df = pd.concat([s2_count,jrc_count],0).reset_index(drop=True)*0.01\n",
    "    count_df.columns = ['Non-water','Wetland','Seasonal water','Permanent water']\n",
    "    count_df.index = ['S2-DWM','JRC-GSW-S']\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnws_boxplot(data):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "    flierprops = dict(marker='o',markerfacecolor='red', markersize=5,markeredgecolor='white')\n",
    "    colors=['blue','orange','brown','yellow','green','purple','black']\n",
    "    sns.boxplot(data=data,flierprops=flierprops,whis=[5, 95],orient='h',palette=colors,linewidth=1)\n",
    "    plt.xlabel('MNWS',fontsize=16)\n",
    "    plt.xticks(range(0, int(data.max().max()), 5))\n",
    "#     plt.axvline(3, 8,0,ls='--',color='black',lw=2)\n",
    "    plt.show()\n",
    "\n",
    "def plot_spectral(band_data):\n",
    "    sns.set(font_scale=1.5)\n",
    "    colors=['blue','orange','brown','yellow','green','purple','red','black']\n",
    "    lo_bound = band_data.loc['mean'].set_index('lc').T[['Water','Cloud shadow']]-band_data.loc['std'].set_index('lc').T[['Water','Cloud shadow']]\n",
    "    hi_bound = band_data.loc['mean'].set_index('lc').T[['Water','Cloud shadow']]+band_data.loc['std'].set_index('lc').T[['Water','Cloud shadow']]\n",
    "    plt.figure(figsize=(15,10))\n",
    "    lines  = sns.lineplot(data=band_data.loc['mean'].set_index('lc').T,dashes=False,sort=False,palette=colors)\n",
    "    lines.lines[0].set_linestyle(\"--\")\n",
    "    plt.ylabel('Surface Reflectance')\n",
    "    plt.fill_between(band_names,lo_bound['Water'], hi_bound['Water'], alpha=.3)\n",
    "    plt.fill_between(band_names,lo_bound['Cloud shadow'], hi_bound['Cloud shadow'], alpha=.3,color=colors[-1])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_names = ['Water','Settlement','Dark soil',' Bright soil','Vegetation','Agriculture','Cloud','Cloud shadow']\n",
    "labels = dict(zip(list(range(1,len(long_names)+1)),long_names))\n",
    "\n",
    "sample_files = glob('./data/sample/sample*.geojson')\n",
    "dates = list(map(lambda x:re.findall(r\"(\\d{8})\", x)[0],sample_files))\n",
    "mosaics = glob(f'{os.path.abspath(\"..\")}images/*.tif')\n",
    "mosaics = [img for date in dates for img in mosaics if date in img]\n",
    "\n",
    "bands = ['B2','B3','B4','B5','B6','B7','B8','B8A','B11','B12']\n",
    "nm = ['490','560','665','705','750','783','842','865','1910','2190']\n",
    "band_names = [f'{a}\\n{b} nm' for a,b in zip(bands,nm)]\n",
    "\n",
    "\n",
    "all_band_data = []\n",
    "all_mnws_data = []\n",
    "for f in sample_files:\n",
    "    date = re.findall(r\"(\\d{8})\", f)[0]\n",
    "\n",
    "    gdf = gpd.read_file(f)\n",
    "    gdf = gdf.sort_values('code')\n",
    "    geom_code = list((zip(gdf ['geometry'].tolist(), gdf['code'].tolist() )))\n",
    "    \n",
    "    fmnws = f'{os.path.abspath(\"..\")}results/rws_mnws_mndwi_otsu/rws_mnws_{date}.tif'\n",
    "    fmos = f'{os.path.abspath(\"..\")}images/mosaic_{date}.tif'\n",
    "        \n",
    "    with rio.open(fmos) as src, rio.open(fmnws) as src_mnws:\n",
    "    \n",
    "        img = src.read()\n",
    "        img = np.where(img<0,0,img)\n",
    "        img = img[get_arr(bands)]\n",
    "        img_mnws = src_mnws.read()\n",
    "        sample_mask = rasterize(shapes=geom_code, out_shape=src.shape, transform=src.transform)\n",
    "        \n",
    "        #mnws stats\n",
    "        mnws_data = pd.concat([pd.DataFrame(img_mnws[:,sample_mask==code]).T for code in gdf['code'].unique()],axis=1)\n",
    "        mnws_data.columns = list(labels.values())\n",
    "        all_mnws_data.append(mnws_data)\n",
    "        \n",
    "        band_data = []\n",
    "        for code in gdf['code'].unique():\n",
    "            band_df = pd.DataFrame(img[:,sample_mask==code]).T.describe().loc[['mean','std']]/10000\n",
    "            band_df.columns = band_names\n",
    "            band_df['lc'] = labels[code]\n",
    "            band_data.append(band_df)\n",
    "            \n",
    "        band_data = pd.concat(band_data)\n",
    "        all_band_data.append(band_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnws_boxplot(pd.concat(all_mnws_data).reset_index(drop=True).drop('Cloud',1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agg_mean = pd.concat(all_band_data).loc['mean'].groupby('lc').mean().T[list(labels.values())]\n",
    "all_agg_std = pd.concat(all_band_data).loc['std'].groupby('lc').mean().T[list(labels.values())]\n",
    "lo_bound = all_agg_mean[['Water','Cloud shadow']]-all_agg_std[['Water','Cloud shadow']]\n",
    "hi_bound = all_agg_mean[['Water','Cloud shadow']]+all_agg_std[['Water','Cloud shadow']]\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "plt.figure(figsize=(15,10))\n",
    "colors=['blue','orange','brown','yellow','green','purple','red','black']\n",
    "lines = sns.lineplot(data=all_agg_mean,dashes=False,sort=False,palette=colors,legend=False)\n",
    "lines.lines[0].set_linestyle(\"--\")\n",
    "plt.legend(all_agg_mean.columns)\n",
    "plt.ylabel('Surface Reflectance')\n",
    "plt.fill_between(band_names,lo_bound['Water'], hi_bound['Water'], alpha=.3)\n",
    "plt.fill_between(band_names,lo_bound['Cloud shadow'], hi_bound['Cloud shadow'], alpha=.3,color=colors[-1])\n",
    "plt.margins(x=0)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# MNWS and band stats example 25 Feb 2017\n",
    "gdf = gpd.read_file(glob('./data/sample/sample*.geojson')[0])\n",
    "\n",
    "long_names = ['Water','Settlement','Dark soil',' Bright soil','Vegetation','Agriculture','Cloud','Cloud shadow']\n",
    "\n",
    "labels = dict(zip(gdf ['code'].unique(),long_names))\n",
    "geom_code = list((zip(gdf ['geometry'].tolist(), gdf ['code'].tolist() )))\n",
    "\n",
    "mosaic = [f for f in glob(f'{os.path.abspath(\"..\")}images/*.tif') if '20170225' in f][0]\n",
    "mnws = [f for f in glob(f\"{os.path.abspath('..')}results/rws_mnws_mndwi_otsu/*.tif\") if '20170225' in f][0]\n",
    "\n",
    "bands = ['B2','B3','B4','B5','B6','B7','B8','B8A','B11','B12']\n",
    "nm = ['490','560','665','705','750','783','842','865','1910','2190']\n",
    "band_names = [f'{a}\\n{b} nm' for a,b in zip(bands,nm)]\n",
    "\n",
    "with rio.open(mosaic) as src,rio.open(mnws) as src_mnws:\n",
    "    \n",
    "    img = src.read()\n",
    "    img = np.where(img<0,0,img)\n",
    "    img = img[get_arr(bands)]\n",
    "    img_mnws = src_mnws.read()\n",
    "    \n",
    "    sample_mask = rasterize(shapes=geom_code, out_shape=src.shape, transform=src.transform)\n",
    "    labels.pop(7)\n",
    "    \n",
    "    #band stats\n",
    "    band_data = pd.concat([pd.DataFrame(img[:,sample_mask==code].mean(1),columns=[desc]) for code,desc in labels.items()],axis=1).T\n",
    "    band_data.columns = band_names\n",
    "    band_data_std = pd.concat([pd.DataFrame(img[:,sample_mask==code].std(1),columns=[desc]) for code,desc in labels.items()],axis=1).T\n",
    "    band_data_std.columns = band_names\n",
    "    \n",
    "    #mnws stats\n",
    "    mnws_data = pd.concat([pd.DataFrame(img_mnws[:,sample_mask==code]).T for code in list(labels.keys())],axis=1)\n",
    "    mnws_data.columns = list(labels.values())\n",
    "\n",
    "    #mnws stats\n",
    "    img_mndwi = compute_index(img,'MNDWI')\n",
    "    mndwi_data = pd.concat([pd.DataFrame(img_mndwi[sample_mask==code]) for code in list(labels.keys())],axis=1)\n",
    "    mndwi_data.columns = list(labels.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "flierprops = dict(marker='o',markerfacecolor='red', markersize=5,markeredgecolor='white')\n",
    "colors = ['blue','orange','brown','yellow','green','purple','black']\n",
    "\n",
    "sns.boxplot(data=mndwi_data.dropna(),order=mndwi_data.columns,flierprops=flierprops,whis=[5, 95],orient='h',linewidth=1,palette=colors)\n",
    "plt.xlabel('MNDWI value',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "flierprops = dict(marker='o',markerfacecolor='red', markersize=5,markeredgecolor='white')\n",
    "colors = ['blue','orange','brown','yellow','green','purple','black']\n",
    "\n",
    "sns.boxplot(data=mnws_data.dropna(),order=mnws_data.columns,flierprops=flierprops,whis=[5, 95],orient='h',linewidth=1,palette=colors)\n",
    "plt.xlabel('MNWS value',fontsize=16)\n",
    "plt.xticks(range(0, int(mnws_data.max().max()+5), 3))\n",
    "plt.axvline(3, 8,0,ls='--',color='black',lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "flierprops = dict(marker='o',markerfacecolor='red', markersize=5,markeredgecolor='white')\n",
    "colors = ['blue','orange','brown','yellow','green','purple','black']\n",
    "\n",
    "sns.boxplot(data=mnws_data,order=mnws_data.columns,flierprops=flierprops,whis=[5, 95],orient='h',linewidth=1,palette=colors)\n",
    "plt.xlabel('MNDWI value',fontsize=16)\n",
    "plt.xticks(range(0, int(mnws_data.max().max()+5), 3))\n",
    "plt.axvline(3, 8,0,ls='--',color='black',lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #compute  MNWS time-series\n",
    "# mosaics= glob(f\"{os.path.abspath('..')}results/rws_mnws_mndwi_otsu/*.tif\")\n",
    "# ts_sample = glob('./data/sample/ts_sample*.geojson')[0]\n",
    "# geo_ts_sample = gpd.read_file(ts_sample)\n",
    "# geo_ts_sample.loc[:,['desc']] = geo_ts_sample.loc[:,['desc']].replace('Pw','Permanent water')\n",
    "# geo_ts_sample.loc[:,['desc']] = geo_ts_sample.loc[:,['desc']].replace('Sw','Seasonal water')\n",
    "# geo_ts_sample.loc[:,['desc']] = geo_ts_sample.loc[:,['desc']].replace('Nw','Non-water')\n",
    "# coords = list((zip(geo_ts_sample['geometry'].centroid.x,geo_ts_sample['geometry'].centroid.y)))\n",
    "\n",
    "# dates=[]\n",
    "\n",
    "# for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "#     file = mosaics[i]\n",
    "#     date = re.findall(r\"(\\d{8})\", file)[0]\n",
    "    \n",
    "#     if date !='20171120':\n",
    "#         dates.append(date)\n",
    "#         col_name = str(pd.to_datetime(date).date())\n",
    "\n",
    "#         with rio.open(file) as src:\n",
    "#             #sample mnws time-series\n",
    "#             geo_ts_sample[col_name] = [val[0] for val in src.sample(coords)]\n",
    "            \n",
    "# geo_ts_sample.iloc[:,4:] = geo_ts_sample.iloc[:,4:].round(3)\n",
    "\n",
    "# plt.figure(figsize=(15,8))\n",
    "# sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "# ax = sns.lineplot(data=geo_ts_sample.groupby(['desc']).median().T.iloc[2:,:],palette=['red','blue','orange'])\n",
    "# [ax.lines[i].set_linestyle(\"-\") for i in range(3)]\n",
    "# plt.legend(geo_ts_sample.groupby(['desc']).median().T.iloc[2:,:].columns[0:],loc='upper left',fontsize=16)\n",
    "# ax.set_xticklabels(pd.to_datetime(pd.Series(dates)).dt.strftime('%d-%b'))\n",
    "# ax.get_xticklabels()[4].set_color(\"red\")\n",
    "# ax.get_xticklabels()[12].set_color(\"red\")\n",
    "# plt.axhline(3, 8,0,ls='--',color='black',lw=2)\n",
    "\n",
    "# plt.xticks(rotation=45,fontsize=14)\n",
    "# plt.yticks(fontsize=16)\n",
    "# plt.ylabel('MNWS Value',fontsize=16)\n",
    "\n",
    "\n",
    "#rain data\n",
    "\n",
    "sns.set(font_scale=1.6)\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "rain_df = pd.read_csv('./data/rain_data.csv',index_col=[0])\n",
    "rain_df['mm'] = rain_df['mm'].astype(float)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.lineplot(data=rain_df,x='Date',y='mm')\n",
    "plt.xticks(np.arange(0, len(rain_df),31),labels=pd.to_datetime(rain_df['Date']).dt.strftime('%b')[::31] )\n",
    "\n",
    "plt.axvline(np.where(df.index=='25-Feb')[0][0],0,.05,ls='--',color='blue',lw=5)\n",
    "plt.axvline(np.where(df.index=='19-May')[0][0],0,.05,ls='--',color='blue',lw=5)\n",
    "\n",
    "plt.ylabel('Precipitation (mm)',fontsize=16)\n",
    "plt.margins(x=0)\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open sun and atmospheric data\n",
    "sun_data_df = pd.read_csv('./data/sun_data.csv', index_col=0)\n",
    "sun_data_df['Date'] = pd.to_datetime(sun_data_df['Date'])\n",
    "\n",
    "sun_data_df['Date_format'] = sun_data_df['Date'].dt.strftime('%d-%b')\n",
    "sun_data_df = sun_data_df.set_index('Date_format')\n",
    "sun_data_df['Months'] = pd.to_datetime(sun_data_df['Date']).dt.strftime('%b')\n",
    "sun_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "fig, axs = plt.subplots(3,1,figsize=(15,10),sharex=True)\n",
    "\n",
    "angles = sun_data_df.columns[1:5]\n",
    "\n",
    "fsize = 16\n",
    "col = ['red','green','blue','orange']\n",
    "for i in range(len(angles)):\n",
    "    if 'SOLAR' in angles[i]:\n",
    "        axs[0].plot(sun_data_df[angles[i]],color=col[i])\n",
    "        axs[0].margins(x=0)\n",
    "        axs[0].legend(labels= angles[0:2],fontsize=fsize)\n",
    "        axs[0].tick_params(axis='both', labelsize=fsize )\n",
    "    else:\n",
    "        axs[i-1].plot(sun_data_df[angles[i]],color=col[i])\n",
    "        axs[i-1].tick_params(axis='both', labelsize=fsize )\n",
    "        axs[i-1].tick_params(axis=\"x\", labelrotation=45)\n",
    "        axs[i-1].legend(labels= [angles[i]],fontsize=fsize,handlelength=0, handletextpad=0)\n",
    "fig.text(0, 0.5, 'Degree (°)',fontsize=fsize , ha='center', va='center', rotation='vertical')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = [l for l in sun_data_df.columns if 'IRRADIANCE' in l]\n",
    "\n",
    "fig, axs = plt.subplots(5,2,figsize=(20,10),sharex=True)\n",
    "axs = axs.ravel()\n",
    "fsize = 20\n",
    "for i in range(len(labels)):\n",
    "    axs[i].plot(sun_data_df[labels [i]].astype(int))\n",
    "    axs[i].tick_params(axis='both', labelsize=fsize)\n",
    "    axs[i].tick_params(axis=\"x\", labelrotation=45)\n",
    "    axs[i].legend(labels= [labels[i].split('_')[-1]],loc='upper left',fontsize=fsize,handlelength=0, handletextpad=0)\n",
    "    axs[i].margins(x=0)\n",
    "\n",
    "fig.text(0, 0.5, 'Solar irradiance (W/m2)',fontsize=fsize, ha='center', va='center', rotation='vertical')\n",
    "plt.xticks(np.arange(0, len(sun_data_df),8),labels=sun_data_df['Months'][::8],fontsize=fsize)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = sun_data_df.columns[-4:-1]\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(25,5),sharex=True)\n",
    "axs = axs.ravel()\n",
    "fsize = 20\n",
    "units = [' (g/cm2)',' (DU)',' (unitless)']\n",
    "for i in range(len(labels)):\n",
    "    axs[i].plot(sun_data_df[labels [i]])\n",
    "    axs[i].tick_params(axis='both', labelsize=fsize)\n",
    "    axs[i].tick_params(axis=\"x\", labelrotation=45)\n",
    "    axs[i].legend(labels= [labels[i].upper()+ units[i] ],loc='upper left',fontsize=fsize,handlelength=0, handletextpad=0)\n",
    "    axs[i].margins(x=0)\n",
    "    \n",
    "plt.xticks(np.arange(0, len(sun_data_df),8),labels=sun_data_df['Months'][::8],fontsize=fsize)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import math\n",
    "sun_data_df = pd.read_csv('./data/sun_data.csv', index_col=0)\n",
    "sun_data_df['Date'] = pd.to_datetime(sun_data_df['Date'])\n",
    "\n",
    "d_df = {'doy':[],'date':[],'distance':[]}\n",
    "\n",
    "for date in sun_data_df['Date']:\n",
    "    \n",
    "    doy = date.timetuple().tm_yday\n",
    "    d = 1 - 0.01672 * math.cos(0.9856 * (doy-4))\n",
    "    d_df['doy'].append(doy)\n",
    "    d_df['date'].append(date.date())\n",
    "    d_df['distance'].append(round(d,3))\n",
    "d_df  = pd.DataFrame(d_df)\n",
    "d_df['date'] = pd.to_datetime(d_df['date']).dt.strftime('%d-%b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 14\n",
    "xticks = [' '.join(x) for x in zip(d_df['date'].astype(str),'(' +d_df['doy'].astype(str)+ ')')]\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(d_df['distance'])\n",
    "plt.xticks(np.arange(0, len(xticks)),labels=xticks,rotation=45,fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.ylabel('Earth-Sun distance (AU)',fontsize=fsize)\n",
    "plt.margins(x=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
