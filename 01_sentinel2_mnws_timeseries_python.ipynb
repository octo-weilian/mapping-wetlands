{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from rasterio.plot import reshape_as_image,reshape_as_raster\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from rasterio.mask import mask\n",
    "\n",
    "import seaborn as sns\n",
    "from rasterio.features import rasterize\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from rasterio.features import sieve\n",
    "from rasterio.plot import reshape_as_image\n",
    "from affine import Affine\n",
    "from skimage.filters import threshold_multiotsu,threshold_otsu,threshold_yen,threshold_triangle\n",
    "\n",
    "def strat_rand_sampling(file,outf,size,nodat=0,seed=None):\n",
    "    #set seed for numpy random \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    data = []\n",
    "    with rio.open(file) as src:\n",
    "        \n",
    "        #translate rows, cols to xy coordinates\n",
    "        T0 = src.transform\n",
    "        T1 = T0 * Affine.translation(0.5, 0.5)\n",
    "        rc2xy = lambda r, c: T1 * (c, r) \n",
    "\n",
    "        img = src.read(1)\n",
    "        strata = np.unique(img)[np.unique(img)!=nodat]\n",
    "        \n",
    "        #sample each stratum to a geopanda dataframe\n",
    "        for stratum in strata: \n",
    "            \n",
    "            rows,cols = np.where(img==stratum)\n",
    "            idx = np.random.choice(np.arange(len(rows)), size, replace=False)\n",
    "            stratified_samples = np.array([rc2xy(x, y) for x,y in zip(rows[idx],cols[idx]) ])\n",
    "            x,y = stratified_samples[:,0],stratified_samples[:,1]\n",
    "            gdf = gpd.GeoDataFrame(crs=str(src.crs), geometry=gpd.points_from_xy(x,y))\n",
    "            gdf['class'] = stratum\n",
    "            data.append(gdf)\n",
    "    \n",
    "    data_cat = pd.concat(data,ignore_index=True)\n",
    "    data_cat.to_file(outf,driver=\"GeoJSON\")\n",
    "    print(f'Exported as: {outf}')\n",
    "    \n",
    "        \n",
    "def compute_cluster(rws_rgb_img,k=4):\n",
    "    rws_rgb_img = rws_rgb_img.astype(np.float32)/10000\n",
    "    samples = reshape_as_image(rws_rgb_img).reshape(-1,rws_rgb_img.shape[0])\n",
    "    kmeans_pred = MiniBatchKMeans(n_clusters=k+1, random_state=42,max_iter=10,batch_size=10000,reassignment_ratio=0).fit(samples)\n",
    "    kmeans_pred_img = kmeans_pred.labels_.reshape(rws_rgb_img.shape[1], rws_rgb_img.shape[2]).astype(rio.uint16)\n",
    "    return kmeans_pred_img\n",
    "\n",
    "def compute_mnws(img,cluster_img,bands=['B2','B3','B4','B8a','B11','B12']):\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    band_pos = get_arr(bands)\n",
    "    \n",
    "    raw_img = img[band_pos]\n",
    "\n",
    "    mnws = []\n",
    "    \n",
    "    max_i = np.argmax(np.unique(cluster_img,return_counts=True)[1])\n",
    "    all_labels = list(range(0,cluster_img.max()+1))\n",
    "    labels = list(set(all_labels)-set([all_labels[max_i]]))\n",
    "\n",
    "    for label in labels:\n",
    "        \n",
    "        #calculate band stats\n",
    "        region_img = np.where(cluster_img==label,raw_img,0)\n",
    "        band_means = np.array(list(map(lambda x:np.mean(region_img[x][region_img[x]!=0],dtype=np.float32),\n",
    "                                       range(len(band_pos))))).reshape(len(band_pos),-1)\n",
    "        band_std = np.array(list(map(lambda x:np.std(region_img[x][region_img[x]!=0],dtype=np.float32),\n",
    "                                     range(len(band_pos))))).reshape(len(band_pos),-1)\n",
    "        \n",
    "        #calculate nws \n",
    "        reshaped_raw_img = raw_img.reshape(len(band_pos),-1)\n",
    "        nws = (((( abs(reshaped_raw_img-band_means) /band_std)**2).sum(0)/len(band_pos))**0.5).reshape(img.shape[1],img.shape[2])\n",
    "        mnws.append(nws)\n",
    "        \n",
    "    mnws_img = np.array(mnws).min(0)\n",
    "\n",
    "    return mnws_img\n",
    "\n",
    "def multitemp_clmasks(target_img,reference_img):\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    #cloud shadow = 1 and thick cloud = 2\n",
    "    db8a = target_img[get_arr('b8a')]-reference_img[get_arr('b8a')]\n",
    "    db11 = target_img[get_arr('b11')]-reference_img[get_arr('b11')]\n",
    "    db2 = target_img[get_arr('b2')]-reference_img[get_arr('b2')]\n",
    "    db3 = target_img[get_arr('b3')]-reference_img[get_arr('b3')]\n",
    "    db4 = target_img[get_arr('b4')]-reference_img[get_arr('b4')]\n",
    "\n",
    "    ndvi = compute_index(target_img,'NDVI')\n",
    "    \n",
    "    cl_shadow = np.where( (db8a<-400) & ( db11<-400 ),1,0)\n",
    "    cl_thick = np.where( ((db2 > 800) & (db3 >800) & (db4 >800)),2,0)\n",
    "    forest_sh = np.where(ndvi>0.5,3,0)\n",
    "   \n",
    "    cl_masks = np.array([cl_shadow,cl_thick,forest_sh])\n",
    "    cl_masks = np.amax(cl_masks,axis=0)\n",
    "    \n",
    "    return cl_masks\n",
    "        \n",
    "def wcf_mnws(mnws_files,invalid_files,thr=3,dec=2):\n",
    "    \n",
    "    water_rws_detected = []\n",
    "    invalid_pixels = []    \n",
    "\n",
    "    for i in tqdm(range(len(mnws_files)),position=0, leave=True):\n",
    "        mnws_file = mnws_files[i]\n",
    "        cl_mask_file = invalid_files[i]\n",
    "\n",
    "        with rio.open(mnws_file) as src_mnws,rio.open(cl_mask_file ) as src_mask:\n",
    "            profile = src_mnws.profile.copy()\n",
    "            mnws_img = src_mnws.read(1)\n",
    "            mnws_img[np.isnan(mnws_img)]=9999\n",
    "            \n",
    "            cl_mask = src_mask.read(1)\n",
    "\n",
    "            invalid = np.where(cl_mask==2,1,0)\n",
    "            invalid_pixels.append(invalid)\n",
    "            \n",
    "            if thr=='otsu':\n",
    "                thr = threshold_otsu(mnws_img[(mnws_img<8)&(mnws_img>1)])\n",
    "            \n",
    "            water_rws = np.where(mnws_img<=thr,1,0)\n",
    "            \n",
    "            water_rws = np.where( (cl_mask==1) | (cl_mask==3),0,water_rws)\n",
    "            water_rws_detected.append(water_rws)\n",
    "\n",
    "    water_rws_detected_sum = np.array(water_rws_detected).sum(0)\n",
    "    invalid_pixels_sum = np.array(invalid_pixels).sum(0)\n",
    "    diff_invalid = len(mnws_files)-invalid_pixels_sum\n",
    "\n",
    "    water_freq_img = np.true_divide(water_rws_detected_sum , diff_invalid, where=(diff_invalid!=0),dtype=np.float32)*12\n",
    "    water_freq_img_r = np.round(water_freq_img,dec)\n",
    "    \n",
    "    return water_freq_img_r,water_rws_detected_sum,profile\n",
    "\n",
    "\n",
    "def get_arr(bands):\n",
    "    band_names = ['B2','B3','B4','B5','B6','B7','B8','B8A','B10','B11','B12']\n",
    "    if isinstance(bands,list):\n",
    "        return [band_names.index(band.upper()) for band in bands]\n",
    "    else:\n",
    "        return band_names.index(bands.upper())\n",
    "    \n",
    "def compute_index(arr,name):\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    if name == 'MNDWI':\n",
    "        b3= arr[get_arr('b3')].astype(np.float32)\n",
    "        b11 = arr[get_arr('b11')].astype(np.float32)\n",
    "        index = (b3-b11)/(b3+b11)\n",
    "        \n",
    "    elif name == 'MNDWI2':\n",
    "        b3= arr[get_arr('b3')].astype(np.float32)\n",
    "        b12 = arr[get_arr('b12')].astype(np.float32)\n",
    "        index = (b3-b12)/(b3+b12)\n",
    "        \n",
    "    elif name == 'MNDVI':\n",
    "        b5= arr[get_arr('b5')].astype(np.float32)\n",
    "        b7= arr[get_arr('b7')].astype(np.float32)\n",
    "        index = (b7-b5)/(b7+b5)\n",
    "        \n",
    "    elif name =='NDVI':\n",
    "        b8a= arr[get_arr('b8a')].astype(np.float32)\n",
    "        b4= arr[get_arr('b4')].astype(np.float32)\n",
    "        index = (b8a-b4)/(b8a+b4)\n",
    "        \n",
    "    elif name =='MGRN':\n",
    "        index = (arr[get_arr(['b3','b4','b8a'])].astype(np.float32)/10000).min(0)\n",
    "    \n",
    "    elif name =='AWEI_NSH':\n",
    "        b3 = arr[get_arr('b3')].astype(np.float32)\n",
    "        b11 = arr[get_arr('b11')].astype(np.float32)\n",
    "        b12 = arr[get_arr('b12')].astype(np.float32)\n",
    "        b8a = arr[get_arr('b8a')].astype(np.float32)\n",
    "        index = (4*(b3-b11)) -( (0.25*b8a) +(2.75*b12) )\n",
    "        \n",
    "    elif name =='AWEI_SH':\n",
    "        b2 = arr[get_arr('b2')].astype(np.float32)\n",
    "        b3 = arr[get_arr('b3')].astype(np.float32)\n",
    "        b11 = arr[get_arr('b11')].astype(np.float32)\n",
    "        b12 = arr[get_arr('b12')].astype(np.float32)\n",
    "        b8a = arr[get_arr('b8a')].astype(np.float32)\n",
    "        index = b2+(2.5*b3)-(1.5*(b8a+b11))-(0.25*b12)\n",
    "    elif name =='NDMI':\n",
    "        b8 = arr[get_arr('b8')].astype(np.float32)\n",
    "        b11 = arr[get_arr('b11')].astype(np.float32)\n",
    "        index = (b8-b11)/(b8+b11)\n",
    "    \n",
    "    return index\n",
    "\n",
    "def compute_wiw(arr):\n",
    "    b8a = arr[get_arr('b8a')].astype(np.float32)/10000\n",
    "    b12 = arr[get_arr('b12')].astype(np.float32)/10000\n",
    "    return np.where( ((b8a<=0.1804)) & ((b12<=0.1131)), 1, 0)\n",
    "\n",
    "def compute_rws(arr,index_type='MNDWI'):\n",
    "    mndwi = compute_index(arr,index_type)\n",
    "    mgrn = compute_index(arr,'MGRN')\n",
    "    \n",
    "    rws = np.where( (mndwi>=threshold_otsu(mndwi[mndwi>=0])) &((mgrn>0) & (mgrn<0.15)),1,0)\n",
    "    rws_img = np.where(rws==1,arr,0)\n",
    "    \n",
    "    return rws_img,rws\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#data mask computation\n",
    "mosaics = glob(f'{os.path.abspath(\"..\")}images/*.tif')\n",
    "\n",
    "nodata_list = []\n",
    "\n",
    "for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "    file = mosaics[i]\n",
    "\n",
    "    with rio.open(file) as src:\n",
    "        profile = src.profile.copy()\n",
    "\n",
    "        img = src.read()\n",
    "        img = np.where(img<0,0,img)\n",
    "        \n",
    "        nodata_img_sum = np.where(img==src.nodata,1,0).sum(0).astype(rio.uint8)\n",
    "        nodata_img_mask = np.where(nodata_img_sum!=0,1,0).astype(rio.uint8)\n",
    "        nodata_list.append(nodata_img_mask)\n",
    "        \n",
    "#inverse nodata mask        \n",
    "nodata_list_sum = np.array(nodata_list).sum(0).astype(rio.uint8)\n",
    "data_list_mask = np.where(nodata_list_sum!=0,0,1).astype(rio.uint8)\n",
    "\n",
    "#sieve data to ommit isolated pixels\n",
    "data_list_mask_sieved = sieve(data_list_mask,100)\n",
    "\n",
    "outf =  f'{os.path.abspath(\"..\")}results/data_mask.tif'\n",
    "\n",
    "profile.update(nodata=0,count=1,dtype=data_list_mask_sieved.dtype)\n",
    "with rio.open(outf,'w',**profile) as dst:\n",
    "    dst.write_band(1,data_list_mask_sieved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#cloud masks computation alternative monthly best image\n",
    "\n",
    "#mosaics\n",
    "mosaics = glob(f'{os.path.abspath(\"..\")}images/*.tif')\n",
    "dates = [re.findall(r\"(\\d{8})\", file)[0] for file in mosaics]\n",
    "\n",
    "#reference mosaics\n",
    "ref_dates = [20170119,20170119,20170327,20170327,20170615,20170615,20170720,20170824,20171008,20171008,20171117,20171117]\n",
    "ref_mosaics = [mos for date in ref_dates for mos in mosaics if str(date) in mos ]\n",
    "months = pd.to_datetime(dates).strftime('%Y%m').unique().tolist()\n",
    "ref_dict = dict(zip(months,ref_mosaics))\n",
    "\n",
    "data_mask_file = f'{os.path.abspath(\"..\")}results/data_mask.tif'\n",
    "\n",
    "with rio.open(data_mask_file) as src_data_mask:\n",
    "    data_mask = src_data_mask.read()\n",
    "\n",
    "    for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "        file = mosaics[i]\n",
    "        outf = f'{ os.path.abspath(\"..\") }results/invalid_masks_x/invalid_{dates[i]}.tif'\n",
    "\n",
    "        ref_file = [ref_dict[key] for key in list(ref_dict.keys()) if key in file][0]\n",
    "\n",
    "        with rio.open(file) as src,rio.open(ref_file) as src_ref:\n",
    "            profile = src.profile.copy()\n",
    "            src_img = np.where(src.read()<0,0,src.read()).astype(rio.int16)\n",
    "            src_img = np.where(data_mask==1,src_img ,src.nodata).astype(rio.int16)\n",
    "            \n",
    "            src_ref_img = np.where(src_ref.read()<0,0,src_ref.read()).astype(rio.int16)\n",
    "            src_ref_img = np.where(data_mask==1,src_ref_img ,src.nodata).astype(rio.int16)\n",
    "            \n",
    "            _,rws = compute_rws(src_img)\n",
    "            cl_masks = multitemp_clmasks(src_img,src_ref_img).astype(rio.int8)\n",
    "            cl_masks = np.where((img[0]!=src.nodata)&(rws!=1),cl_masks,0).astype(rio.int8)\n",
    "            \n",
    "            #write to new geotiff\n",
    "            profile.update({'dtype':cl_masks.dtype,'nodata':0,'count':1})\n",
    "            with rio.open(outf ,'w',**profile) as dst:\n",
    "                dst.write_band(1, cl_masks)\n",
    "                dst.set_band_description(1, f'invalid_{dates[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#mnws computation\n",
    "mosaics = glob(f'{os.path.abspath(\"..\")}images/*.tif')\n",
    "\n",
    "data_mask_file = f'{os.path.abspath(\"..\")}results/data_mask.tif'\n",
    "\n",
    "with rio.open(data_mask_file) as src_data_mask:\n",
    "\n",
    "    data_mask = src_data_mask.read()\n",
    "\n",
    "    for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "        file = mosaics[i]\n",
    "\n",
    "        outf = f'{os.path.abspath(\"..\")}results/rws_mnws_mndwi_otsu/{os.path.basename(file)}'.replace('mosaic','rws_mnws')\n",
    "\n",
    "        with rio.open(file) as src:\n",
    "            profile = src.profile.copy()\n",
    "\n",
    "            img = src.read()\n",
    "            img = np.where(img<0,0,img)\n",
    "            img = np.where(data_mask==1,img,src.nodata).astype(rio.int16)\n",
    "\n",
    "            #compute RWS region\n",
    "            rws_img,_ = compute_rws(img)\n",
    "\n",
    "            #cluster and compute MNWS\n",
    "            cluster_img = compute_cluster(rws_img[get_arr(['B2','B3','B4'])],8)\n",
    "            \n",
    "            mnws = compute_mnws(img,cluster_img,bands=['B2','B3','B4','B8A','B11','B12'])\n",
    "            mnws = np.where(img[0]==src.nodata,src.nodata,mnws).astype(rio.float32)\n",
    "\n",
    "            profile.update(nodata=src.nodata,count=1,dtype=mnws.dtype)\n",
    "            with rio.open(outf,'w',**profile) as dst:\n",
    "                dst.write_band(1,mnws)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# #compute water coverage frequency\n",
    "\n",
    "mnws_files = glob(f\"{os.path.abspath('..')}results/rws_mnws_mndwi_otsu/rws*.tif\")\n",
    "cl_mask_files = glob(f\"{os.path.abspath('..')}results/invalid_masks_min400/invalid*.tif\")\n",
    "\n",
    "# water rws frequency  \n",
    "wf_rws,water_sum,profile = wcf_mnws(mnws_files,cl_mask_files,thr=3,dec=2)\n",
    "\n",
    "#reclassify to water body types\n",
    "dwm = wf_rws.copy()\n",
    "dwm[(dwm >0.5)&(dwm <11)] = 2\n",
    "dwm[dwm>=11] = 3\n",
    "dwm[(dwm <=0.5)&(dwm !=0)] = 1\n",
    "\n",
    "#sieve data\n",
    "dwm = sieve(dwm.astype(rio.uint8),10)\n",
    "\n",
    "#export rasters\n",
    "out_wf = f\"{os.path.abspath('..')}results/wf_rws.tif\"\n",
    "profile.update({'dtype':wf_rws.dtype,'nodata':0,'count':1})\n",
    "with rio.open(out_wf,'w',**profile) as dst: dst.write_band(1,wf_rws)\n",
    "    \n",
    "out_water_sum = f\"{os.path.abspath('..')}results/watersum_rws.tif\"\n",
    "profile.update({'dtype':rio.uint8,'nodata':0,'count':1})\n",
    "with rio.open(out_water_sum,'w',**profile) as dst: dst.write_band(1,water_sum.astype(rio.uint8))\n",
    "    \n",
    "out_dwm = f\"{os.path.abspath('..')}results/dwm.tif\"\n",
    "profile.update({'dtype':rio.uint8,'nodata':0,'count':1})\n",
    "with rio.open(out_dwm ,'w',**profile) as dst: dst.write_band(1,dwm.astype(rio.uint8))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to use multiotsu threshold again class =4 --> first thr\n",
    "# keep -try thr for cloud shadow mask\n",
    "#perform post classification on the non-water pixels based on MNDWI, NDVI and MNWS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dates = [re.findall(r\"(\\d{8})\", file)[0] for file in mnws_files]\n",
    "# #open profile to copy\n",
    "# with rio.open(mnws_files[0]) as src_0:\n",
    "#     profile = src_0.profile.copy()\n",
    "#     profile.update(nodata=0,count=len(mnws_files),dtype=rio.uint16)\n",
    "\n",
    "#     #write all detected water to single geotiff\n",
    "#     outf = f\"{os.path.abspath('..')}results/water_stack.tif\"\n",
    "#     with rio.open(outf,'w',**profile) as dst:\n",
    "#         for i in tqdm(range(len(mnws_files)),position=0, leave=True):\n",
    "#             with rio.open(mnws_files[i]) as src:\n",
    "#                 mnws_img = src.read(1)\n",
    "#                 mnws_img[np.isnan(mnws_img)]=9999\n",
    "#                 thr = threshold_otsu(mnws_img[(mnws_img<8)&(mnws_img>1)])\n",
    "#                 water = np.where((mnws_img<thr),1,0).astype(rio.uint16)\n",
    "#                 dst.write_band(i+1, water)\n",
    "#                 dst.set_band_description(i+1, f'water_{dates[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QGIS expression :\n",
    "((\"wf_rws@1\"<=(2/3.5)) AND (\"wf_rws@1\">0))*1 + ((\"wf_rws@1\">(2/3.5)) AND (\"wf_rws@1\"<(40/3.5)))*2  + ((\"wf_rws@1\">=(40/3.5)) AND (\"wf_rws@1\"<=12))*3 + ((\"wf_rws@1\">12))*4   \n",
    "\n",
    "((\"wf_rws@1\"<=0.5) AND (\"wf_rws@1\">0))*1 + ((\"wf_rws@1\">0.5) AND (\"wf_rws@1\"<11.5))*2  + ((\"wf_rws@1\">=11.5) AND (\"wf_rws@1\"<=12))*3 + ((\"wf_rws@1\">12))*4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compute non-water pixels from MNWS time-series\n",
    "#if a pixel satisfy sum(MNWS<3)=0 than its classified as a potential water pixel\n",
    "#else its a potential non-water pixel\n",
    "\n",
    "mnws_dir = f'{os.path.abspath(\"..\")}results/rws_mnws_mndwi_otsu/'\n",
    "mosaics = glob(mnws_dir+\"/*mnws*.tif\")\n",
    "\n",
    "mnws_sum = []\n",
    "for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "    file = mosaics[i]\n",
    "    \n",
    "    try:\n",
    "        with rio.open(file) as src:\n",
    "            profile = src.profile.copy()\n",
    "            mnws_img = src.read(1)\n",
    "            mnws_img[np.isnan(mnws_img)]=9999\n",
    "            thr = threshold_otsu(mnws_img[(mnws_img<8)&(mnws_img>1)])\n",
    "            mnws_img_thr = np.where(mnws_img<thr,1,0)\n",
    "            mnws_sum.append(mnws_img_thr)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    \n",
    "mnws_sum = np.array(mnws_sum).sum(0)\n",
    "mnws_sum = np.where((mnws_sum==0)&(mnws_img!=src.nodata),1,0) \n",
    "\n",
    "# #export as geotiff\n",
    "outf = f'{os.path.abspath(\"..\")}results/nonwater_img.tif'\n",
    "profile.update({'dtype':mnws_sum.dtype,'nodata':0,'count':1})\n",
    "with rio.open(outf,'w',**profile) as dst:\n",
    "    dst.write_band(1,mnws_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create stratified random samples\n",
    "file = f'{os.path.abspath(\"..\")}results/dwm.tif'\n",
    "strat_rand_sampling(file=file,outf='./data//sample/stratified_random_samples.geojson',size=100,nodat=0,seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnws_boxplot(data):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "    flierprops = dict(marker='o',markerfacecolor='red', markersize=5,markeredgecolor='white')\n",
    "    sns.boxplot(data=data,order=['Wa','Sh','Ds','Ve','Ag','Se','Bs','Cl'],flierprops=flierprops,whis=[5, 95],orient='h',palette='husl',linewidth=1)\n",
    "    plt.xlabel('MNWS',fontsize=16)\n",
    "    plt.ylabel('Land cover',fontsize=16)\n",
    "    plt.title('MNWS land cover types 25 Feb 2017 ',fontsize=20)\n",
    "    plt.xticks(range(0, int(data['Cl'].max()), 5))\n",
    "    plt.axvline(3, 8,0,ls='--',color='black',lw=2)\n",
    "    plt.show()\n",
    "\n",
    "def plot_bands(band_data_mean,band_data_std):\n",
    "    sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "    plt.figure(figsize=(12,9))\n",
    "    colors=['blue','orange','brown','yellow','green','purple','red','black']\n",
    "    axs = [sns.lineplot(data=band_data.loc[band_data.index[i]]/10000,sort=False,color=colors[i]) for i in range(len(band_data.index))]\n",
    "    axs[0].lines[0].set_linestyle(\"--\")\n",
    "    plt.legend(band_data.index,loc='upper left',fontsize=16)\n",
    "    plt.xlabel('Band',fontsize=16)\n",
    "    plt.ylabel('Surface Reflectance',fontsize=16)\n",
    "    plt.title('Spectral signature land cover types 25 Feb 2017 ',fontsize=20)\n",
    "\n",
    "\n",
    "    plt.fill_between(band_names,(band_data.iloc[0]/10000)-(band_data_std.iloc[0]/10000), (band_data.iloc[0]/10000)+(band_data_std.iloc[0]/10000), alpha=.3)\n",
    "    plt.fill_between(band_names,(band_data.iloc[-1]/10000)-(band_data_std.iloc[-1]/10000), (band_data.iloc[-1]/10000)+(band_data_std.iloc[-1]/10000), alpha=.3,color=colors[-1])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# MNWS and band stats example 25 Feb 2017\n",
    "gdf = gpd.read_file(glob('./data/sample/sample*.geojson')[0])\n",
    "labels = dict(zip(gdf ['code'].unique(),gdf ['desc'].unique()))\n",
    "geom_code = list((zip(gdf ['geometry'].tolist(), gdf ['code'].tolist() )))\n",
    "\n",
    "mosaic = [f for f in glob(f'{os.path.abspath(\"..\")}images/*.tif') if '20170225' in f][0]\n",
    "mnws = [f for f in glob(f\"{os.path.abspath('..')}results/rws_mnws_mndwi_otsu/*.tif\") if '20170225' in f][0]\n",
    "\n",
    "band_names = ['B2','B3','B4','B5','B6','B7','B8','B8A','B11','B12']\n",
    "\n",
    "with rio.open(mosaic) as src,rio.open(mnws) as src_mnws:\n",
    "\n",
    "    img = src.read()\n",
    "    img = img[get_arr(band_names)]\n",
    "    img_mnws = src_mnws.read()\n",
    "    \n",
    "    sample_mask = rasterize(shapes=geom_code, out_shape=src.shape, transform=src.transform)\n",
    "    \n",
    "    #band stats\n",
    "    band_data = pd.concat([pd.DataFrame(img[:,sample_mask==code].mean(1),columns=[desc]) for code,desc in labels.items()],axis=1).T\n",
    "    band_data.columns = band_names\n",
    "    band_data_std = pd.concat([pd.DataFrame(img[:,sample_mask==code].std(1),columns=[desc]) for code,desc in labels.items()],axis=1).T\n",
    "    band_data_std.columns = band_names\n",
    "    \n",
    "    #mnws stats\n",
    "    mnws_data = pd.concat([pd.DataFrame(img_mnws[:,sample_mask==code]).T for code in list(labels.keys())],axis=1)\n",
    "    mnws_data.columns = list(labels.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bands(band_data,band_data_std)\n",
    "mnws_boxplot(mnws_data)\n",
    "round(mnws_data.describe(),3).loc[['mean','std','min','max']].T.sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#compute  MNWS time-series\n",
    "mosaics= glob(f\"{os.path.abspath('..')}results/rws_mnws_mndwi_otsu/*.tif\")\n",
    "ts_sample = glob('./data/sample/ts_sample*.geojson')[0]\n",
    "geo_ts_sample = gpd.read_file(ts_sample)\n",
    "coords = list((zip(geo_ts_sample['geometry'].centroid.x,geo_ts_sample['geometry'].centroid.y)))\n",
    "\n",
    "dates=[]\n",
    "\n",
    "for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "    file = mosaics[i]\n",
    "    date = re.findall(r\"(\\d{8})\", file)[0]\n",
    "    \n",
    "    if date !='20171120':\n",
    "        dates.append(date)\n",
    "        col_name = str(pd.to_datetime(date).date())\n",
    "\n",
    "        with rio.open(file) as src:\n",
    "            #sample mnws time-series\n",
    "            geo_ts_sample[col_name] = [val[0] for val in src.sample(coords)]\n",
    "            \n",
    "geo_ts_sample.iloc[:,4:] = geo_ts_sample.iloc[:,4:].round(3)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "ax = sns.lineplot(data=geo_ts_sample.groupby(['desc']).median().T.iloc[2:,:],palette=['red','blue','orange'])\n",
    "[ax.lines[i].set_linestyle(\"-\") for i in range(3)]\n",
    "plt.legend(geo_ts_sample.groupby(['desc']).median().T.iloc[2:,:].columns[0:],loc='upper right',fontsize=16)\n",
    "ax.set_xticklabels(pd.to_datetime(pd.Series(dates)).dt.strftime('%d-%b'))\n",
    "plt.axhline(3, 8,0,ls='--',color='black',lw=2)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Date',fontsize=16)\n",
    "plt.ylabel('Value',fontsize=16)\n",
    "plt.title('MNWS time-series 2017',fontsize=20)\n",
    "\n",
    "#rain data\n",
    "rain_df = pd.read_csv('./data/rain_data.csv',index_col=[0])\n",
    "rain_df['mm'] = rain_df['mm'].astype(float)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.lineplot(data=rain_df,x='Date',y='mm')\n",
    "plt.xticks(np.arange(0, len(rain_df),31),labels=pd.to_datetime(rain_df['Date']).dt.strftime('%b')[::31] )\n",
    "\n",
    "plt.xlabel('Month',fontsize=16)\n",
    "plt.ylabel('Precipitation (mm)',fontsize=16)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
