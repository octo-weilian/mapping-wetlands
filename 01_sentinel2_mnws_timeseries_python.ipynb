{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from rasterio.plot import reshape_as_image,reshape_as_raster\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from rasterio.mask import mask\n",
    "\n",
    "import seaborn as sns\n",
    "from rasterio.features import rasterize\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from rasterio.features import sieve\n",
    "from rasterio.plot import reshape_as_image\n",
    "from affine import Affine\n",
    "from skimage.filters import threshold_multiotsu,threshold_otsu,threshold_yen,threshold_triangle,threshold_local,threshold_li\n",
    "\n",
    "def strat_rand_sampling(file,outf,size,nodat=0,seed=None):\n",
    "    #set seed for numpy random \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    data = []\n",
    "    with rio.open(file) as src:\n",
    "        \n",
    "        #translate rows, cols to xy coordinates\n",
    "        T0 = src.transform\n",
    "        T1 = T0 * Affine.translation(0.5, 0.5)\n",
    "        rc2xy = lambda r, c: T1 * (c, r) \n",
    "\n",
    "        img = src.read(1)\n",
    "        strata = np.unique(img)[np.unique(img)!=nodat]\n",
    "        \n",
    "        #sample each stratum to a geopanda dataframe\n",
    "        for stratum in strata: \n",
    "            \n",
    "            rows,cols = np.where(img==stratum)\n",
    "            idx = np.random.choice(np.arange(len(rows)), size, replace=False)\n",
    "            stratified_samples = np.array([rc2xy(x, y) for x,y in zip(rows[idx],cols[idx]) ])\n",
    "            x,y = stratified_samples[:,0],stratified_samples[:,1]\n",
    "            gdf = gpd.GeoDataFrame(crs=str(src.crs), geometry=gpd.points_from_xy(x,y))\n",
    "            gdf['class'] = stratum\n",
    "            data.append(gdf)\n",
    "    \n",
    "    data_cat = pd.concat(data,ignore_index=True)\n",
    "    data_cat.to_file(outf,driver=\"GeoJSON\")\n",
    "    print(f'Exported as: {outf}')\n",
    "    \n",
    "        \n",
    "def compute_cluster(rws_rgb_img,k=4):\n",
    "    rws_rgb_img = rws_rgb_img.astype(np.float32)/10000\n",
    "    samples = reshape_as_image(rws_rgb_img).reshape(-1,rws_rgb_img.shape[0])\n",
    "    kmeans_pred = MiniBatchKMeans(n_clusters=k+1, random_state=42,max_iter=10,batch_size=10000,reassignment_ratio=0).fit(samples)\n",
    "    kmeans_pred_img = kmeans_pred.labels_.reshape(rws_rgb_img.shape[1], rws_rgb_img.shape[2]).astype(rio.uint16)\n",
    "    return kmeans_pred_img\n",
    "\n",
    "def compute_mnws(img,cluster_img,bands=['B2','B3','B4','B8a','B11','B12']):\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    band_pos = get_arr(bands)\n",
    "    \n",
    "    raw_img = img[band_pos]\n",
    "\n",
    "    mnws = []\n",
    "    \n",
    "    max_i = np.argmax(np.unique(cluster_img,return_counts=True)[1])\n",
    "    all_labels = list(range(0,cluster_img.max()+1))\n",
    "    labels = list(set(all_labels)-set([all_labels[max_i]]))\n",
    "\n",
    "    for label in labels:\n",
    "        \n",
    "        #calculate band stats\n",
    "        region_img = np.where(cluster_img==label,raw_img,0)\n",
    "        band_means = np.array(list(map(lambda x:np.mean(region_img[x][region_img[x]!=0],dtype=np.float32),\n",
    "                                       range(len(band_pos))))).reshape(len(band_pos),-1)\n",
    "        band_std = np.array(list(map(lambda x:np.std(region_img[x][region_img[x]!=0],dtype=np.float32),\n",
    "                                     range(len(band_pos))))).reshape(len(band_pos),-1)\n",
    "        \n",
    "        #calculate nws \n",
    "        reshaped_raw_img = raw_img.reshape(len(band_pos),-1)\n",
    "        nws = (((( abs(reshaped_raw_img-band_means) /band_std)**2).sum(0)/len(band_pos))**0.5).reshape(img.shape[1],img.shape[2])\n",
    "        mnws.append(nws)\n",
    "        \n",
    "    mnws_img = np.array(mnws).min(0)\n",
    "\n",
    "    return mnws_img\n",
    "\n",
    "def multitemp_clmasks(target_img,reference_img):\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    #cloud shadow = 1 and thick cloud = 2\n",
    "    db8a = target_img[get_arr('b8a')]-reference_img[get_arr('b8a')]\n",
    "    db11 = target_img[get_arr('b11')]-reference_img[get_arr('b11')]\n",
    "    db2 = target_img[get_arr('b2')]-reference_img[get_arr('b2')]\n",
    "    db3 = target_img[get_arr('b3')]-reference_img[get_arr('b3')]\n",
    "    db4 = target_img[get_arr('b4')]-reference_img[get_arr('b4')]\n",
    "\n",
    "    ndvi = compute_index(target_img,'NDVI')\n",
    "    \n",
    "    cl_shadow = np.where( (db8a<-400) & ( db11<-400 ),1,0)\n",
    "    cl_thick = np.where( ((db2 > 800) & (db3 >800) & (db4 >800)),2,0)\n",
    "    forest_sh = np.where(ndvi>0.5,3,0)\n",
    "       \n",
    "    cl_masks = np.array([cl_shadow,cl_thick,forest_sh])\n",
    "    cl_masks = np.amax(cl_masks,axis=0)\n",
    "    \n",
    "    return cl_masks\n",
    "        \n",
    "def wcf_mnws(mnws_files,invalid_files,upland_file,thr=3,dec=2):\n",
    "    \n",
    "    with rio.open(upland_file) as src_upland:\n",
    "        upland_mask = src_upland.read(1)\n",
    "    \n",
    "        water_rws_detected = []\n",
    "        invalid_pixels = []    \n",
    "\n",
    "        for i in tqdm(range(len(mnws_files)),position=0, leave=True):\n",
    "            mnws_file = mnws_files[i]\n",
    "            cl_mask_file = invalid_files[i]\n",
    "\n",
    "            with rio.open(mnws_file) as src_mnws,rio.open(cl_mask_file ) as src_mask:\n",
    "                profile = src_mnws.profile.copy()\n",
    "                mnws_img = src_mnws.read(1)\n",
    "                mnws_img[np.isnan(mnws_img)]=9999\n",
    "\n",
    "                cl_mask = src_mask.read(1)\n",
    "\n",
    "                invalid = np.where(cl_mask==2,1,0)\n",
    "                invalid_pixels.append(invalid)\n",
    "\n",
    "                water_rws = np.where(mnws_img<=thr,1,0)\n",
    "\n",
    "                water_rws = np.where( cl_mask>0,0,water_rws)\n",
    "                water_rws_detected.append(water_rws)\n",
    "\n",
    "        water_rws_detected_sum = np.where(upland_mask==1,0,np.array(water_rws_detected).sum(0))\n",
    "        invalid_pixels_sum = np.array(invalid_pixels).sum(0)\n",
    "        diff_invalid = len(mnws_files)-invalid_pixels_sum\n",
    "\n",
    "        water_freq_img = np.true_divide(water_rws_detected_sum , diff_invalid, where=(diff_invalid!=0),dtype=np.float32)*12\n",
    "        water_freq_img_r = np.round(water_freq_img,dec)\n",
    "\n",
    "        return water_freq_img_r,water_rws_detected_sum,profile\n",
    "\n",
    "\n",
    "def get_arr(bands):\n",
    "    band_names = ['B2','B3','B4','B5','B6','B7','B8','B8A','B10','B11','B12']\n",
    "    if isinstance(bands,list):\n",
    "        return [band_names.index(band.upper()) for band in bands]\n",
    "    else:\n",
    "        return band_names.index(bands.upper())\n",
    "    \n",
    "def compute_index(arr,name):\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    if name == 'MNDWI':\n",
    "        b3= arr[get_arr('b3')].astype(np.float32)\n",
    "        b11 = arr[get_arr('b11')].astype(np.float32)\n",
    "        index = (b3-b11)/(b3+b11)\n",
    "        \n",
    "    elif name == 'MNDWI2':\n",
    "        b3= arr[get_arr('b3')].astype(np.float32)\n",
    "        b12 = arr[get_arr('b12')].astype(np.float32)\n",
    "        index = (b3-b12)/(b3+b12)\n",
    "        \n",
    "    elif name == 'MNDVI':\n",
    "        b5= arr[get_arr('b5')].astype(np.float32)\n",
    "        b7= arr[get_arr('b7')].astype(np.float32)\n",
    "        index = (b7-b5)/(b7+b5)\n",
    "        \n",
    "    elif name =='NDVI':\n",
    "        b8a= arr[get_arr('b8a')].astype(np.float32)\n",
    "        b4= arr[get_arr('b4')].astype(np.float32)\n",
    "        index = (b8a-b4)/(b8a+b4)\n",
    "        \n",
    "    elif name =='MGRN':\n",
    "        index = (arr[get_arr(['b3','b4','b8a'])].astype(np.float32)/10000).min(0)\n",
    "    \n",
    "    elif name =='AWEI_NSH':\n",
    "        b3 = arr[get_arr('b3')].astype(np.float32)\n",
    "        b11 = arr[get_arr('b11')].astype(np.float32)\n",
    "        b12 = arr[get_arr('b12')].astype(np.float32)\n",
    "        b8a = arr[get_arr('b8a')].astype(np.float32)\n",
    "        index = (4*(b3-b11)) -( (0.25*b8a) +(2.75*b12) )\n",
    "        \n",
    "    elif name =='AWEI_SH':\n",
    "        b2 = arr[get_arr('b2')].astype(np.float32)\n",
    "        b3 = arr[get_arr('b3')].astype(np.float32)\n",
    "        b11 = arr[get_arr('b11')].astype(np.float32)\n",
    "        b12 = arr[get_arr('b12')].astype(np.float32)\n",
    "        b8a = arr[get_arr('b8a')].astype(np.float32)\n",
    "        index = b2+2.5*b3-1.5*(b8a+b11)-0.25*b12\n",
    "\n",
    "    return index\n",
    "\n",
    "def compute_wiw(arr):\n",
    "    b8a = arr[get_arr('b8a')].astype(np.float32)/10000\n",
    "    b12 = arr[get_arr('b12')].astype(np.float32)/10000\n",
    "    return np.where( ((b8a<=0.1804)) & ((b12<=0.1131)), 1, 0)\n",
    "\n",
    "def compute_rws(arr,index_type='MNDWI',method='otsu'):\n",
    "    water_index = compute_index(arr,index_type)\n",
    "    mgrn = compute_index(arr,'MGRN')\n",
    "    \n",
    "    if method == 'otsu':\n",
    "        thr = threshold_otsu(water_index[water_index>=0])\n",
    "    elif method == 'li':\n",
    "        thr = threshold_li(water_index[water_index>=0],initial_guess=0.3)\n",
    "    \n",
    "    rws = np.where( (water_index>=thr) &((mgrn>0) & (mgrn<0.15)),1,0)\n",
    "    rws_img = np.where(rws==1,arr,0)\n",
    "    return rws_img,rws\n",
    "\n",
    "def wd_count(mnws_files,invalid_files,upland_file,thr=3):\n",
    "    \n",
    "    wd = {}\n",
    "   \n",
    "    with rio.open(upland_file) as src_upland:\n",
    "        upland_mask = src_upland.read(1)\n",
    "    \n",
    "        for i in tqdm(range(len(mnws_files)),position=0, leave=True):\n",
    "            mnws_file = mnws_files[i]\n",
    "            date = re.findall(r\"(\\d{8})\", mnws_file)[0]\n",
    "            cl_mask_file = invalid_files[i]\n",
    "\n",
    "            with rio.open(mnws_file) as src_mnws,rio.open(cl_mask_file ) as src_mask:\n",
    "                profile = src_mnws.profile.copy()\n",
    "                mnws_img = src_mnws.read(1)\n",
    "                mnws_img[np.isnan(mnws_img)]=9999\n",
    "\n",
    "                cl_mask = src_mask.read(1)\n",
    "\n",
    "                if thr=='otsu':\n",
    "                    thr = threshold_otsu(mnws_img[(mnws_img<8)&(mnws_img>1)])\n",
    "\n",
    "                water_rws = np.where( (mnws_img<=thr)&(upland_mask!=1),1,0)\n",
    "                \n",
    "                water_rws = np.where( (cl_mask==1) | (cl_mask==3),0,water_rws)\n",
    "\n",
    "                wd[date] = np.count_nonzero(water_rws)\n",
    "    df = pd.DataFrame(wd,index=[0]).T\n",
    "    df.columns = ['pixel_count']\n",
    "    return  df\n",
    "\n",
    "def calc_acc(y_true,y_pred):\n",
    "    \n",
    "    observed = y_true.rename('Observed')\n",
    "    classified = y_pred.rename('Classified')\n",
    "    con_mat = pd.crosstab(classified,observed)\n",
    "    \n",
    "    row_sum = con_mat.sum(axis=1)\n",
    "    col_sum = con_mat.sum(axis=0)\n",
    "    omitted = np.setdiff1d(col_sum.index,row_sum.index)\n",
    "    col_sum = col_sum.drop(omitted)\n",
    "    \n",
    "    ua = np.diag(con_mat)/row_sum\n",
    "    pa = np.diag(con_mat)/col_sum\n",
    "    f1 = (2 * pa*ua) /(pa+ua)\n",
    "    \n",
    "    acc_df = round(pd.DataFrame({'Label':col_sum.index,'PA':pa.values,'UA':ua.values,'F1-score':f1.values}),2).fillna(0)\n",
    "    acc_df.set_index('Label',inplace=True)\n",
    "    \n",
    "    \n",
    "    return acc_df,con_mat\n",
    "\n",
    "\n",
    "def plot_acc(acc_df,con_mat,labels,fig_text='fig'):\n",
    "    \n",
    "    acc_df = acc_df.copy()\n",
    "    con_mat = con_mat.copy()\n",
    "    \n",
    "    oa =np.diag(con_mat).sum()/con_mat.sum().sum()  \n",
    "    \n",
    "    sns.set(font_scale=1.6)\n",
    "    sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': '0'})\n",
    "\n",
    "    fig, axs = plt.subplots(1,2,figsize=(12,5))\n",
    "\n",
    "    con_mat.columns = [f'{b}\\n{a}' for a,b in zip(labels,con_mat.sum(0))]\n",
    "    con_mat.index = [f'{a}\\n{b}' for a,b in zip(labels,con_mat.sum(1))]\n",
    "    \n",
    "    con_mat_plot = sns.heatmap(con_mat,annot=True,cbar=False,ax=axs[0],cmap='Blues')\n",
    "    axs[0].set_xlabel('Observed')\n",
    "    axs[0].set_ylabel('Classified')\n",
    "    for _, spine in con_mat_plot.spines.items(): \n",
    "        spine.set_visible(True)\n",
    "    \n",
    "    acc_df.index = labels\n",
    "    sns.lineplot(data=acc_df,ax=axs[1],dashes=False,sort=False)\n",
    "    sns.scatterplot(data = acc_df,ax=axs[1])\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].set_xlabel('Label')\n",
    "    \n",
    "    leg = axs[1].legend(acc_df.columns.tolist()+[f'OA: { \"%.2f\" % oa}'],loc='best')\n",
    "    leg.get_lines()[-1].set_visible(False)\n",
    "    axs[0].text(-0.90,1.05,fig_text,horizontalalignment='center',verticalalignment='center',transform=axs[1].transAxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#data mask computation\n",
    "mosaics = glob(f'{os.path.abspath(\"..\")}images/*.tif')\n",
    "\n",
    "nodata_list = []\n",
    "\n",
    "for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "    file = mosaics[i]\n",
    "\n",
    "    with rio.open(file) as src:\n",
    "        profile = src.profile.copy()\n",
    "\n",
    "        img = src.read()\n",
    "        img = np.where(img<0,0,img)\n",
    "        \n",
    "        nodata_img_sum = np.where(img==src.nodata,1,0).sum(0).astype(rio.uint8)\n",
    "        nodata_img_mask = np.where(nodata_img_sum!=0,1,0).astype(rio.uint8)\n",
    "        nodata_list.append(nodata_img_mask)\n",
    "        \n",
    "#inverse nodata mask        \n",
    "nodata_list_sum = np.array(nodata_list).sum(0).astype(rio.uint8)\n",
    "data_list_mask = np.where(nodata_list_sum!=0,0,1).astype(rio.uint8)\n",
    "\n",
    "#sieve data to ommit isolated pixels\n",
    "data_list_mask_sieved = sieve(data_list_mask,100)\n",
    "\n",
    "outf =  f'{os.path.abspath(\"..\")}results/data_mask.tif'\n",
    "\n",
    "profile.update(nodata=0,count=1,dtype=data_list_mask_sieved.dtype)\n",
    "with rio.open(outf,'w',**profile) as dst:\n",
    "    dst.write_band(1,data_list_mask_sieved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#cloud masks computation monthly best reference image\n",
    "\n",
    "#mosaics\n",
    "mosaics = glob(f'{os.path.abspath(\"..\")}images/*.tif')\n",
    "dates = [re.findall(r\"(\\d{8})\", file)[0] for file in mosaics]\n",
    "\n",
    "#reference mosaics\n",
    "ref_dates = [20170119,20170119,20170327,20170327,20170615,20170615,20170720,20170824,20171008,20171008,20171117,20171117]\n",
    "ref_mosaics = [mos for date in ref_dates for mos in mosaics if str(date) in mos ]\n",
    "months = pd.to_datetime(dates).strftime('%Y%m').unique().tolist()\n",
    "ref_dict = dict(zip(months,ref_mosaics))\n",
    "\n",
    "data_mask_file = f'{os.path.abspath(\"..\")}results/data_mask.tif'\n",
    "\n",
    "with rio.open(data_mask_file) as src_data_mask:\n",
    "    data_mask = src_data_mask.read()\n",
    "\n",
    "    for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "        file = mosaics[i]\n",
    "        outf = f'{ os.path.abspath(\"..\") }results/invalid_masks_min400_ndvi03/invalid_{dates[i]}.tif'\n",
    "\n",
    "        ref_file = [ref_dict[key] for key in list(ref_dict.keys()) if key in file][0]\n",
    "\n",
    "        with rio.open(file) as src,rio.open(ref_file) as src_ref:\n",
    "            profile = src.profile.copy()\n",
    "            src_img = np.where(src.read()<0,0,src.read()).astype(rio.int16)\n",
    "            src_img = np.where(data_mask==1,src_img ,src.nodata).astype(rio.int16)\n",
    "            \n",
    "            src_ref_img = np.where(src_ref.read()<0,0,src_ref.read()).astype(rio.int16)\n",
    "            src_ref_img = np.where(data_mask==1,src_ref_img ,src.nodata).astype(rio.int16)\n",
    "            \n",
    "            _,rws = compute_rws(src_img,'MNDWI','otsu')\n",
    "            cl_masks = multitemp_clmasks(src_img,src_ref_img).astype(rio.int8)\n",
    "            cl_masks = np.where((src_img[0]!=src.nodata)&(rws!=1),cl_masks,0).astype(rio.int8)\n",
    "            \n",
    "            #write to new geotiff\n",
    "            profile.update({'dtype':cl_masks.dtype,'nodata':0,'count':1})\n",
    "            with rio.open(outf ,'w',**profile) as dst:\n",
    "                dst.write_band(1, cl_masks)\n",
    "                dst.set_band_description(1, f'invalid_{dates[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaics = glob(f'{os.path.abspath(\"..\")}images/*.tif')\n",
    "mnws_files = glob(f\"{os.path.abspath('..')}results/rws_mnws_mndwi_otsu/rws*.tif\")\n",
    "data_mask_file = f'{os.path.abspath(\"..\")}results/misc/data_mask.tif'\n",
    "\n",
    "thr_dict = {}\n",
    "\n",
    "with rio.open(data_mask_file) as src_data_mask:\n",
    "\n",
    "    data_mask = src_data_mask.read()\n",
    "    profile = src_data_mask.profile.copy()\n",
    "    \n",
    "    for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "        file = mosaics[i]\n",
    "        mnws_file = mnws_files[i]\n",
    "        date = str(pd.to_datetime(re.findall(r\"(\\d{8})\", file)[0]).date())\n",
    "        outf = f'{os.path.abspath(\"..\")}results/wd_rws/{os.path.basename(file)}'.replace('mosaic','wd_rws')\n",
    "\n",
    "        with rio.open(file) as src, rio.open(mnws_file) as src_mnws:\n",
    "            img = src.read()\n",
    "            img = np.where(img<0,0,img)\n",
    "            img = np.where(data_mask==1,img,src.nodata).astype(rio.int16)\n",
    "            \n",
    "            mnws_img = np.where(src_mnws.read(1)<=3,2,0)\n",
    "            rws_img,rws = compute_rws(img,'MNDWI','otsu')\n",
    "            \n",
    "            wd_rws = np.array([mnws_img,rws]).sum(0).astype(rio.uint16)\n",
    "            \n",
    "            profile.update(nodata=0,count=1,dtype=rio.uint16)\n",
    "            with rio.open(outf,'w',**profile) as dst:\n",
    "                dst.write_band(1,wd_rws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#mnws computation\n",
    "mosaics = glob(f'{os.path.abspath(\"..\")}images/*.tif')\n",
    "\n",
    "data_mask_file = f'{os.path.abspath(\"..\")}results/misc/data_mask.tif'\n",
    "\n",
    "with rio.open(data_mask_file) as src_data_mask:\n",
    "\n",
    "    data_mask = src_data_mask.read()\n",
    "\n",
    "    for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "        file = mosaics[i]\n",
    "\n",
    "        outf = f'{os.path.abspath(\"..\")}results/rws_mnws_mndwi_otsu/{os.path.basename(file)}'.replace('mosaic','rws_mnws')\n",
    "\n",
    "        with rio.open(file) as src:\n",
    "            profile = src.profile.copy()\n",
    "\n",
    "            img = src.read()\n",
    "            img = np.where(img<0,0,img)\n",
    "            img = np.where(data_mask==1,img,src.nodata).astype(rio.int16)\n",
    "\n",
    "            #compute RWS region\n",
    "            rws_img,_ = compute_rws(img,'MNDWI','otsu')\n",
    "\n",
    "            #cluster and compute MNWS\n",
    "            cluster_img = compute_cluster(rws_img[get_arr(['B2','B3','B4'])],8) \n",
    "            \n",
    "            mnws = compute_mnws(img,cluster_img,bands=['B2','B3','B4','B8A','B11','B12'])\n",
    "            mnws = np.where(img[0]==src.nodata,src.nodata,mnws).astype(rio.float32)\n",
    "\n",
    "            profile.update(nodata=src.nodata,count=1,dtype=mnws.dtype)\n",
    "            with rio.open(outf,'w',**profile) as dst:\n",
    "                dst.write_band(1,mnws)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# #compute water coverage frequency map\n",
    "mnws_files = glob(f\"{os.path.abspath('..')}results/rws_mnws_mndwi_otsu/rws*.tif\")\n",
    "cl_mask_files = glob(f\"{os.path.abspath('..')}results/invalid_masks_min400_ndvi05/invalid*.tif\")\n",
    "upland_file = f\"{os.path.abspath('..')}results/misc/upland_gte30.tif\"\n",
    "\n",
    "wf_rws,water_sum,profile = wcf_mnws(mnws_files,cl_mask_files,upland_file,thr=3,dec=2)\n",
    "\n",
    "#reclassify to water body types\n",
    "data_mask_file = f'{os.path.abspath(\"..\")}results/misc/data_mask.tif'\n",
    "\n",
    "with rio.open(data_mask_file) as src_data_mask:\n",
    "    \n",
    "    #used to assign non-water pixels (class value = 0)\n",
    "    data_mask = src_data_mask.read(1)\n",
    "    \n",
    "    #reclassification of WF image\n",
    "    dwm = wf_rws.copy()\n",
    "    wetland = ((dwm >0)&(dwm <3))*2     #wetland\n",
    "    sw = ((dwm >=3)&(dwm <=9))*3        #seasonal water\n",
    "    pw = (dwm>9)*4                      #permanent water\n",
    "    \n",
    "    dwm_sum = np.array([wetland,sw,pw]).sum(0)\n",
    "    dwm_out = np.where(dwm_sum>0,dwm_sum,data_mask).astype(rio.uint8)\n",
    "\n",
    "    #sieve data\n",
    "    dwm_out_sieved = sieve(dwm_out,size=30,connectivity=8)\n",
    "    \n",
    "    #export rasters\n",
    "    out_wf = f\"{os.path.abspath('..')}results/wf_rws.tif\"\n",
    "    profile.update({'dtype':wf_rws.dtype,'nodata':0,'count':1})\n",
    "    with rio.open(out_wf,'w',**profile) as dst: dst.write_band(1,wf_rws)\n",
    "\n",
    "    out_water_sum = f\"{os.path.abspath('..')}results/watersum.tif\"\n",
    "    profile.update({'dtype':rio.uint8,'nodata':0,'count':1})\n",
    "    with rio.open(out_water_sum,'w',**profile) as dst: dst.write_band(1,water_sum.astype(rio.uint8))\n",
    "\n",
    "    out_dwm = f\"{os.path.abspath('..')}results/dwm.tif\"\n",
    "    profile.update({'dtype':rio.uint8,'nodata':0,'count':1})\n",
    "    with rio.open(out_dwm ,'w',**profile) as dst: dst.write_band(1,dwm_out_sieved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dwm_file =  f\"{os.path.abspath('..')}results/dwm.tif\"\n",
    "jrc_file= f\"{os.path.abspath('..')}ancillary_data/YearlyHistory_2017_masked.tif\"\n",
    "sample_points = gpd.read_file(glob(f\"./data/sample/accuracy_assesment/*classified.geojson\")[0])\n",
    "\n",
    "with rio.open(dwm_file) as src_dwm,rio.open(jrc_file) as src_jrc:\n",
    "    coords = list((zip(sample_points['geometry'].centroid.x,sample_points['geometry'].centroid.y)))\n",
    "    sample_points['dwm_label'] = [val[0] for val in src_dwm.sample(coords)]\n",
    "    sample_points['gsw_label'] = [val[0]+1 for val in src_jrc.sample(coords)]\n",
    "\n",
    "# sample_points = sample_points[sample_points['rating']=='high']\n",
    "# S2-DWM all classes\n",
    "acc_df,con_mat = calc_acc(sample_points['true_label'],sample_points['dwm_label'])\n",
    "plot_acc(acc_df,con_mat,sample_points['true_name'].unique(),'(a.) S2-DWM four classes')\n",
    "\n",
    "#s2-DWM nw, sw (+wetland) and pw\n",
    "acc_df,con_mat = calc_acc(sample_points['true_label'].replace(2,3),sample_points['dwm_label'].replace(2,3))\n",
    "plot_acc(acc_df,con_mat,sample_points['true_name'].unique()[[0,2,3]],'(b.) S2-DWM three classes')\n",
    "\n",
    "#JRC-GSW-S nw, wl (original nw), sw and nw\n",
    "acc_df,con_mat = calc_acc(sample_points['true_label'],sample_points['gsw_label'])\n",
    "plot_acc(acc_df,con_mat,sample_points['true_name'].unique(),'(c.) JRC-GSW-S four classes')\n",
    "\n",
    "#JRC-GSW-S nw (original nw and all not pixels not classified), sw and pw\n",
    "acc_df,con_mat = calc_acc(sample_points['true_label'].replace(2,1),sample_points['gsw_label'].replace(2,1))\n",
    "plot_acc(acc_df,con_mat,sample_points['true_name'].unique()[[0,2,3]],'(d.) JRC-GSW-S three classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#time-series analysis\n",
    "\n",
    "dwm_file = f\"{os.path.abspath('..')}results/dwm.tif\"\n",
    "mnws_files = glob(f\"{os.path.abspath('..')}results/rws_mnws_mndwi_otsu/rws*.tif\")\n",
    "cl_mask_files = glob(f\"{os.path.abspath('..')}results/invalid_masks_min400_ndvi05/invalid*.tif\")\n",
    "mosaics = glob(f'{os.path.abspath(\"..\")}images/*.tif')\n",
    "dates = [re.findall(r\"(\\d{8})\", file)[0] for file in mosaics]\n",
    "\n",
    "wetland_file = \"./data/boundaries/high_vegetated.geojson\"\n",
    "wetland_geo = gpd.read_file(wetland_file)\n",
    "\n",
    "with rio.open(dwm_file) as src_dwm:\n",
    "    \n",
    "    dwm,_ = mask(src_dwm, wetland_geo.geometry, crop=True)\n",
    "    dwm = np.where(dwm==2,3,dwm)[0]\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "\n",
    "        with rio.open(mosaics[i]) as src, rio.open(mnws_files[i]) as src_mnws,rio.open(cl_mask_files[i]) as src_clm:\n",
    "\n",
    "            img,_ = mask(src, wetland_geo.geometry, crop=True)\n",
    "            clm,_ = mask(src_clm, wetland_geo.geometry, crop=True)\n",
    "            mnws,_ = mask(src_mnws, wetland_geo.geometry, crop=True)\n",
    "            \n",
    "            img = np.where(img<0,0,img)\n",
    "            ndvi = compute_index(img,'NDVI')\n",
    "            mndwi = compute_index(img,'MNDWI')\n",
    "            \n",
    "            wi_arr = np.array([ndvi,mndwi,mnws[0]])\n",
    "            wi_arr = np.where(clm>0,9999,wi_arr)\n",
    "            \n",
    "            values = []\n",
    "            for i in [1,3,4]:\n",
    "                val_arr = np.where(wi_arr[:,dwm==i]!=9999,wi_arr[:,dwm==i],np.nan)\n",
    "                values += np.nanmedian(val_arr,1).tolist()\n",
    "            data.append(values)\n",
    "    df = pd.DataFrame(np.array(data))\n",
    "    df.columns = ['NDVI_NW','MNDWI_NW','MNWS_NW','NDVI_SW','MNDWI_SW','MNWS_SW','NDVI_PW','MNDWI_PW','MNWS_PW']\n",
    "    df = df.set_index(pd.to_datetime(dates))\n",
    "    df.to_csv('./data/dwm_median_values_aoi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "\n",
    "df = pd.read_csv('./data/dwm_median_values_aoi.csv',index_col=[0])\n",
    "df.columns = ['NDVI (Nw)','MNDWI (Nw)','MNWS (Nw)','NDVI (Sw)','MNDWI (Sw)','MNWS (Sw)','NDVI (Pw)','MNDWI (Pw)','MNWS (Pw)']\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.resample('D').interpolate(method='linear')\n",
    "df.index = df.index.strftime('%d-%b')\n",
    "\n",
    "fig, axs = plt.subplots(3,2,figsize=(15,10),sharex=True)\n",
    "axs = axs.ravel()\n",
    "\n",
    "colors=['green','blue']\n",
    "for i,d in enumerate(df.iloc[:,:2].columns):\n",
    "    axs[0].plot(df.iloc[:,:2][d],color=colors[i])\n",
    "axs[1].plot(df.iloc[:,2:3],color='red')\n",
    "axs[1].axhline(3, 8,0,ls='--',color='black',lw=2)\n",
    "axs[0].legend(['NDVI','MNDWI'])\n",
    "axs[1].legend(['MNWS']);\n",
    "\n",
    "for i,d in enumerate(df.iloc[:,3:5].columns):\n",
    "    axs[2].plot(df.iloc[:,3:5][d],color=colors[i])\n",
    "axs[3].plot(df.iloc[:,5:6],color='red')\n",
    "axs[3].axhline(3, 8,0,ls='--',color='black',lw=2)\n",
    "\n",
    "\n",
    "for i,d in enumerate(df.iloc[:,6:8].columns):\n",
    "    axs[4].plot(df.iloc[:,6:8][d],color=colors[i])\n",
    "\n",
    "axs[5].plot(df.iloc[:,8:],color='red')\n",
    "axs[5].axhline(3, 8,0,ls='--',color='black',lw=2)\n",
    "\n",
    "\n",
    "\n",
    "fig.text(0.01, 0.5, 'Value', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "axs[0].text(0.05,1.1,'(a.) Non-water',horizontalalignment='center',verticalalignment='center',transform=axs[0].transAxes)\n",
    "axs[2].text(0.05,1.1,'(b.) Seasonal water',horizontalalignment='center',verticalalignment='center',transform=axs[2].transAxes)\n",
    "axs[4].text(0.05,1.1,'(c.) Permanent water',horizontalalignment='center',verticalalignment='center',transform=axs[4].transAxes)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.margins(x=0)\n",
    "\n",
    "    ax.xaxis.set_ticks(np.arange(0, len(df),31))\n",
    "    ax.set_xticklabels(df.index[::31].str.split('-').str[-1])\n",
    "    ax.axvline(np.where(df.index=='25-Feb')[0][0],0,.05,ls='--',color='blue',lw=5)\n",
    "    ax.axvline(np.where(df.index=='19-May')[0][0],0,.05,ls='--',color='blue',lw=5)\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "data= []\n",
    "for c in df.columns:\n",
    "    summary = round(df[c].describe(),1)\n",
    "    summary['var'] = df[c].var()\n",
    "    summary['median'] = df[c].median()\n",
    "    data.append(summary)\n",
    "data_df = pd.concat(data,1).T[['std','var','min','median','max']].T\n",
    "sns.heatmap(data_df.T,annot=True,cbar=False,cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rain_df.sort_values('mm',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat_rand_sampling(file,size,vstride_nr,nodat=0,seed=None):\n",
    "    #set seed for numpy random \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    data = []\n",
    "    with rio.open(file) as src:\n",
    "        \n",
    "        #translate rows, cols to xy coordinates\n",
    "        T0 = src.transform\n",
    "        T1 = T0 * Affine.translation(0.5, 0.5)\n",
    "        rc2xy = lambda r, c: T1 * (c, r) \n",
    "\n",
    "        img = src.read(1)\n",
    "        profile = src.profile.copy()\n",
    "        block_img = img.copy()\n",
    "        \n",
    "        vstride = int(block_img.shape[0]/vstride_nr)\n",
    "        \n",
    "        for i in range(0,block_img.shape[0],vstride):\n",
    "            random_label = int((i+vstride)/100)\n",
    "            if i+vstride<block_img.shape[0]:\n",
    "                block_img[i:i+vstride,:][block_img[i:i+vstride,:]>=0] = random_label\n",
    "            else:\n",
    "                block_img[i:,:][block_img[i:,:]>=0] = random_label\n",
    "            \n",
    "        stack_img = np.where(img>0,block_img,nodat).astype(rio.uint16)\n",
    "        \n",
    "        strata = np.unique(stack_img)[np.unique(stack_img)!=nodat]\n",
    "        classes = np.unique(img)[np.unique(img)!=nodat]\n",
    "        \n",
    "        for grid in strata: \n",
    "            for c in classes:\n",
    "                rows,cols = np.where((img==c)&(stack_img==grid))\n",
    "        \n",
    "                if len(rows)!=0:\n",
    "                    idx = np.random.choice(range(len(cols)), size, replace=False)\n",
    "                    stratified_samples = np.array([rc2xy(x, y) for x,y in zip(rows[idx],cols[idx]) ])\n",
    "                    x,y = stratified_samples[:,0],stratified_samples[:,1]\n",
    "                    gdf = gpd.GeoDataFrame(crs=str(src.crs), geometry=gpd.points_from_xy(x,y))\n",
    "                    gdf['class'] = c\n",
    "                    data.append(gdf)\n",
    "        \n",
    "        profile.update(nodata=0,dtype=stack_img.dtype)\n",
    "        data_cat = pd.concat(data,ignore_index=True)\n",
    "        return data_cat,stack_img.astype(rio.uint8),profile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create stratified random samples\n",
    "file = glob(f'{os.path.abspath(\"..\")}results/dwm*.tif')[0]\n",
    "\n",
    "seed = 42\n",
    "\n",
    "gdf,block_img,block_profile = strat_rand_sampling(file=file,size=13,vstride_nr = 4,nodat=0,seed=seed)\n",
    "\n",
    "\n",
    "print(gdf.groupby('class').count())\n",
    "\n",
    "#drop class with sample points larger than 50\n",
    "# indices2drop = gdf[gdf['class']==1].sample(n=5,random_state = seed).index\n",
    "# gdf = gdf.drop(indices2drop).reset_index(drop=True)\n",
    "\n",
    "#add class description\n",
    "gdf['desc'] = None\n",
    "for c_code,c_desc in zip(gdf['class'].unique(),['Nw','Wl','Sw','Pw']):\n",
    "    gdf.loc[gdf[gdf['class']==c_code].index,'desc'] = c_desc\n",
    "    \n",
    "print(gdf.groupby('class').count())\n",
    "\n",
    "#xport sample points\n",
    "gdf_file = './data//sample/stratified_random_52samples_segmented.geojson'\n",
    "gdf.to_file(gdf_file,driver=\"GeoJSON\")\n",
    "\n",
    "#xport image block\n",
    "with rio.open('./data//sample/blocks.tif','w',**profile) as dst:\n",
    "    dst.write_band(1,block_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = glob(f'{os.path.abspath(\"..\")}results/dwm*.tif')[0]\n",
    "file_jrc = glob(f'{os.path.abspath(\"..\")}ancillary_data/YearlyHistory_2017_masked.tif')[0]\n",
    "\n",
    "data_mask_file = f'{os.path.abspath(\"..\")}results/misc/data_mask.tif'\n",
    "\n",
    "with rio.open(file) as src, rio.open(file_jrc) as src_jrc,rio.open(data_mask_file) as src_datamask:\n",
    "    s2_img = src.read()\n",
    "    jrc_img = src_jrc.read()\n",
    "    datamask_img = src_datamask.read()\n",
    "    jrc_img = np.where(datamask_img==1,jrc_img,9999)\n",
    "    \n",
    "    s2_count = pd.DataFrame(np.unique(s2_img[s2_img!=0],return_counts=True)[1]).T\n",
    "    jrc_count = pd.DataFrame(np.unique(jrc_img[jrc_img!=9999],return_counts=True)[1]).T\n",
    "    count_df = pd.concat([s2_count,jrc_count],0).reset_index(drop=True)*0.01\n",
    "    count_df.columns = ['Non-water','Wetland','Seasonal water','Permanent water']\n",
    "    count_df.index = ['S2-DWM','JRC-GSW-S']\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnws_boxplot(data):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "    flierprops = dict(marker='o',markerfacecolor='red', markersize=5,markeredgecolor='white')\n",
    "    sns.boxplot(data=data,order=['Wa','Sh','Ds','Ve','Ag','Se','Bs','Cl'],flierprops=flierprops,whis=[5, 95],orient='h',palette='husl',linewidth=1)\n",
    "    plt.xlabel('MNWS',fontsize=16)\n",
    "    plt.ylabel('Land cover',fontsize=16)\n",
    "    plt.title('MNWS land cover types 25 Feb 2017 ',fontsize=20)\n",
    "    plt.xticks(range(0, int(data['Cl'].max()), 5))\n",
    "    plt.axvline(3, 8,0,ls='--',color='black',lw=2)\n",
    "    plt.show()\n",
    "\n",
    "def plot_bands(band_data_mean,band_data_std):\n",
    "    fsize = 16\n",
    "    sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "    plt.figure(figsize=(15,10))\n",
    "    colors=['blue','orange','brown','yellow','green','purple','red','black']\n",
    "    axs = [sns.lineplot(data=band_data.loc[band_data_mean.index[i]]/10000,sort=False,color=colors[i]) for i in range(len(band_data_mean.index))]\n",
    "    axs[0].lines[0].set_linestyle(\"--\")\n",
    "    plt.legend(band_data_mean.index,loc='upper left',fontsize=fsize)\n",
    "    plt.ylabel('Surface Reflectance',fontsize=fsize)\n",
    "    \n",
    "    plt.xticks(fontsize=fsize)\n",
    "    plt.yticks(fontsize=fsize)\n",
    "    plt.fill_between(band_data.columns.tolist(),(band_data_mean.iloc[0]/10000)-(band_data_std.iloc[0]/10000), (band_data_mean.iloc[0]/10000)+(band_data_std.iloc[0]/10000), alpha=.3)\n",
    "    plt.fill_between(band_data.columns.tolist(),(band_data_mean.iloc[-1]/10000)-(band_data_std.iloc[-1]/10000), (band_data_mean.iloc[-1]/10000)+(band_data_std.iloc[-1]/10000), alpha=.3,color=colors[-1])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# MNWS and band stats example 25 Feb 2017\n",
    "gdf = gpd.read_file(glob('./data/sample/sample*.geojson')[0])\n",
    "\n",
    "long_names = ['Water','Settlement','Dark soil',' Bright soil','Vegetation','Agriculture','Cloud','Cloud shadow']\n",
    "\n",
    "labels = dict(zip(gdf ['code'].unique(),long_names))\n",
    "geom_code = list((zip(gdf ['geometry'].tolist(), gdf ['code'].tolist() )))\n",
    "\n",
    "mosaic = [f for f in glob(f'{os.path.abspath(\"..\")}images/*.tif') if '20170225' in f][0]\n",
    "mnws = [f for f in glob(f\"{os.path.abspath('..')}results/rws_mnws_mndwi_otsu/*.tif\") if '20170225' in f][0]\n",
    "\n",
    "bands = ['B2','B3','B4','B5','B6','B7','B8','B8A','B11','B12']\n",
    "nm = ['490','560','665','705','750','783','842','865','1910','2190']\n",
    "band_names = [f'{a}\\n{b} nm' for a,b in zip(bands,nm)]\n",
    "\n",
    "with rio.open(mosaic) as src,rio.open(mnws) as src_mnws:\n",
    "    \n",
    "    img = src.read()\n",
    "    img = np.where(img<0,0,img)\n",
    "    img = img[get_arr(bands)]\n",
    "    img_mnws = src_mnws.read()\n",
    "    \n",
    "    sample_mask = rasterize(shapes=geom_code, out_shape=src.shape, transform=src.transform)\n",
    "    labels.pop(7)\n",
    "    \n",
    "    #band stats\n",
    "    band_data = pd.concat([pd.DataFrame(img[:,sample_mask==code].mean(1),columns=[desc]) for code,desc in labels.items()],axis=1).T\n",
    "    band_data.columns = band_names\n",
    "    band_data_std = pd.concat([pd.DataFrame(img[:,sample_mask==code].std(1),columns=[desc]) for code,desc in labels.items()],axis=1).T\n",
    "    band_data_std.columns = band_names\n",
    "    \n",
    "    #mnws stats\n",
    "    mnws_data = pd.concat([pd.DataFrame(img_mnws[:,sample_mask==code]).T for code in list(labels.keys())],axis=1)\n",
    "    mnws_data.columns = list(labels.values())\n",
    "\n",
    "    #mnws stats\n",
    "    img_mndwi = compute_index(img,'MNDWI')\n",
    "    mndwi_data = pd.concat([pd.DataFrame(img_mndwi[sample_mask==code]) for code in list(labels.keys())],axis=1)\n",
    "    mndwi_data.columns = list(labels.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "flierprops = dict(marker='o',markerfacecolor='red', markersize=5,markeredgecolor='white')\n",
    "colors = ['blue','orange','brown','yellow','green','purple','black']\n",
    "\n",
    "sns.boxplot(data=mndwi_data.dropna(),order=mndwi_data.columns,flierprops=flierprops,whis=[5, 95],orient='h',linewidth=1,palette=colors)\n",
    "plt.xlabel('MNDWI value',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "flierprops = dict(marker='o',markerfacecolor='red', markersize=5,markeredgecolor='white')\n",
    "colors = ['blue','orange','brown','yellow','green','purple','black']\n",
    "\n",
    "sns.boxplot(data=mnws_data.dropna(),order=mnws_data.columns,flierprops=flierprops,whis=[5, 95],orient='h',linewidth=1,palette=colors)\n",
    "plt.xlabel('MNWS value',fontsize=16)\n",
    "plt.xticks(range(0, int(mnws_data.max().max()+5), 3))\n",
    "plt.axvline(3, 8,0,ls='--',color='black',lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "flierprops = dict(marker='o',markerfacecolor='red', markersize=5,markeredgecolor='white')\n",
    "colors = ['blue','orange','brown','yellow','green','purple','black']\n",
    "\n",
    "sns.boxplot(data=mnws_data,order=mnws_data.columns,flierprops=flierprops,whis=[5, 95],orient='h',linewidth=1,palette=colors)\n",
    "plt.xlabel('MNDWI value',fontsize=16)\n",
    "plt.xticks(range(0, int(mnws_data.max().max()+5), 3))\n",
    "plt.axvline(3, 8,0,ls='--',color='black',lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #compute  MNWS time-series\n",
    "# mosaics= glob(f\"{os.path.abspath('..')}results/rws_mnws_mndwi_otsu/*.tif\")\n",
    "# ts_sample = glob('./data/sample/ts_sample*.geojson')[0]\n",
    "# geo_ts_sample = gpd.read_file(ts_sample)\n",
    "# geo_ts_sample.loc[:,['desc']] = geo_ts_sample.loc[:,['desc']].replace('Pw','Permanent water')\n",
    "# geo_ts_sample.loc[:,['desc']] = geo_ts_sample.loc[:,['desc']].replace('Sw','Seasonal water')\n",
    "# geo_ts_sample.loc[:,['desc']] = geo_ts_sample.loc[:,['desc']].replace('Nw','Non-water')\n",
    "# coords = list((zip(geo_ts_sample['geometry'].centroid.x,geo_ts_sample['geometry'].centroid.y)))\n",
    "\n",
    "# dates=[]\n",
    "\n",
    "# for i in tqdm(range(len(mosaics)),position=0, leave=True):\n",
    "#     file = mosaics[i]\n",
    "#     date = re.findall(r\"(\\d{8})\", file)[0]\n",
    "    \n",
    "#     if date !='20171120':\n",
    "#         dates.append(date)\n",
    "#         col_name = str(pd.to_datetime(date).date())\n",
    "\n",
    "#         with rio.open(file) as src:\n",
    "#             #sample mnws time-series\n",
    "#             geo_ts_sample[col_name] = [val[0] for val in src.sample(coords)]\n",
    "            \n",
    "# geo_ts_sample.iloc[:,4:] = geo_ts_sample.iloc[:,4:].round(3)\n",
    "\n",
    "# plt.figure(figsize=(15,8))\n",
    "# sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "# ax = sns.lineplot(data=geo_ts_sample.groupby(['desc']).median().T.iloc[2:,:],palette=['red','blue','orange'])\n",
    "# [ax.lines[i].set_linestyle(\"-\") for i in range(3)]\n",
    "# plt.legend(geo_ts_sample.groupby(['desc']).median().T.iloc[2:,:].columns[0:],loc='upper left',fontsize=16)\n",
    "# ax.set_xticklabels(pd.to_datetime(pd.Series(dates)).dt.strftime('%d-%b'))\n",
    "# ax.get_xticklabels()[4].set_color(\"red\")\n",
    "# ax.get_xticklabels()[12].set_color(\"red\")\n",
    "# plt.axhline(3, 8,0,ls='--',color='black',lw=2)\n",
    "\n",
    "# plt.xticks(rotation=45,fontsize=14)\n",
    "# plt.yticks(fontsize=16)\n",
    "# plt.ylabel('MNWS Value',fontsize=16)\n",
    "\n",
    "\n",
    "#rain data\n",
    "\n",
    "sns.set(font_scale=1.6)\n",
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "rain_df = pd.read_csv('./data/rain_data.csv',index_col=[0])\n",
    "rain_df['mm'] = rain_df['mm'].astype(float)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.lineplot(data=rain_df,x='Date',y='mm')\n",
    "plt.xticks(np.arange(0, len(rain_df),31),labels=pd.to_datetime(rain_df['Date']).dt.strftime('%b')[::31] )\n",
    "\n",
    "plt.axvline(np.where(df.index=='25-Feb')[0][0],0,.05,ls='--',color='blue',lw=5)\n",
    "plt.axvline(np.where(df.index=='19-May')[0][0],0,.05,ls='--',color='blue',lw=5)\n",
    "\n",
    "plt.ylabel('Precipitation (mm)',fontsize=16)\n",
    "plt.margins(x=0)\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open sun and atmospheric data\n",
    "sun_data_df = pd.read_csv('./data/sun_data.csv', index_col=0)\n",
    "sun_data_df['Date'] = pd.to_datetime(sun_data_df['Date'])\n",
    "\n",
    "sun_data_df['Date_format'] = sun_data_df['Date'].dt.strftime('%d-%b')\n",
    "sun_data_df = sun_data_df.set_index('Date_format')\n",
    "sun_data_df['Months'] = pd.to_datetime(sun_data_df['Date']).dt.strftime('%b')\n",
    "sun_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid',rc={\"xtick.bottom\" : True, \"ytick.left\" : True,'axes.edgecolor': 'black'})\n",
    "fig, axs = plt.subplots(3,1,figsize=(15,10),sharex=True)\n",
    "\n",
    "angles = sun_data_df.columns[1:5]\n",
    "\n",
    "fsize = 16\n",
    "col = ['red','green','blue','orange']\n",
    "for i in range(len(angles)):\n",
    "    if 'SOLAR' in angles[i]:\n",
    "        axs[0].plot(sun_data_df[angles[i]],color=col[i])\n",
    "        axs[0].margins(x=0)\n",
    "        axs[0].legend(labels= angles[0:2],fontsize=fsize)\n",
    "        axs[0].tick_params(axis='both', labelsize=fsize )\n",
    "    else:\n",
    "        axs[i-1].plot(sun_data_df[angles[i]],color=col[i])\n",
    "        axs[i-1].tick_params(axis='both', labelsize=fsize )\n",
    "        axs[i-1].tick_params(axis=\"x\", labelrotation=45)\n",
    "        axs[i-1].legend(labels= [angles[i]],fontsize=fsize,handlelength=0, handletextpad=0)\n",
    "fig.text(0, 0.5, 'Degree (°)',fontsize=fsize , ha='center', va='center', rotation='vertical')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = [l for l in sun_data_df.columns if 'IRRADIANCE' in l]\n",
    "\n",
    "fig, axs = plt.subplots(5,2,figsize=(20,10),sharex=True)\n",
    "axs = axs.ravel()\n",
    "fsize = 20\n",
    "for i in range(len(labels)):\n",
    "    axs[i].plot(sun_data_df[labels [i]].astype(int))\n",
    "    axs[i].tick_params(axis='both', labelsize=fsize)\n",
    "    axs[i].tick_params(axis=\"x\", labelrotation=45)\n",
    "    axs[i].legend(labels= [labels[i].split('_')[-1]],loc='upper left',fontsize=fsize,handlelength=0, handletextpad=0)\n",
    "    axs[i].margins(x=0)\n",
    "\n",
    "fig.text(0, 0.5, 'Solar irradiance (W/m2)',fontsize=fsize, ha='center', va='center', rotation='vertical')\n",
    "plt.xticks(np.arange(0, len(sun_data_df),8),labels=sun_data_df['Months'][::8],fontsize=fsize)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = sun_data_df.columns[-4:-1]\n",
    "\n",
    "fig, axs = plt.subplots(1,3,figsize=(25,5),sharex=True)\n",
    "axs = axs.ravel()\n",
    "fsize = 20\n",
    "units = [' (g/cm2)',' (DU)',' (unitless)']\n",
    "for i in range(len(labels)):\n",
    "    axs[i].plot(sun_data_df[labels [i]])\n",
    "    axs[i].tick_params(axis='both', labelsize=fsize)\n",
    "    axs[i].tick_params(axis=\"x\", labelrotation=45)\n",
    "    axs[i].legend(labels= [labels[i].upper()+ units[i] ],loc='upper left',fontsize=fsize,handlelength=0, handletextpad=0)\n",
    "    axs[i].margins(x=0)\n",
    "    \n",
    "plt.xticks(np.arange(0, len(sun_data_df),8),labels=sun_data_df['Months'][::8],fontsize=fsize)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import math\n",
    "sun_data_df = pd.read_csv('./data/sun_data.csv', index_col=0)\n",
    "sun_data_df['Date'] = pd.to_datetime(sun_data_df['Date'])\n",
    "\n",
    "d_df = {'doy':[],'date':[],'distance':[]}\n",
    "\n",
    "for date in sun_data_df['Date']:\n",
    "    \n",
    "    doy = date.timetuple().tm_yday\n",
    "    d = 1 - 0.01672 * math.cos(0.9856 * (doy-4))\n",
    "    d_df['doy'].append(doy)\n",
    "    d_df['date'].append(date.date())\n",
    "    d_df['distance'].append(round(d,3))\n",
    "d_df  = pd.DataFrame(d_df)\n",
    "d_df['date'] = pd.to_datetime(d_df['date']).dt.strftime('%d-%b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 14\n",
    "xticks = [' '.join(x) for x in zip(d_df['date'].astype(str),'(' +d_df['doy'].astype(str)+ ')')]\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(d_df['distance'])\n",
    "plt.xticks(np.arange(0, len(xticks)),labels=xticks,rotation=45,fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.ylabel('Earth-Sun distance (AU)',fontsize=fsize)\n",
    "plt.margins(x=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
