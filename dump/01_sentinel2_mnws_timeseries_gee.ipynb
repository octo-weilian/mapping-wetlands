{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Atmospheric():\n",
    "    \n",
    "    def round_date(date,xhour):\n",
    "        \"\"\"\n",
    "        rounds a date of to the closest 'x' hours\n",
    "        \"\"\"\n",
    "        y = date.get('year')\n",
    "        m = date.get('month')\n",
    "        d = date.get('day')\n",
    "        H = date.get('hour')\n",
    "        HH = H.divide(xhour).round().multiply(xhour)\n",
    "        return date.fromYMD(y,m,d).advance(HH,'hour')\n",
    "  \n",
    "    def round_month(date):\n",
    "        \"\"\"\n",
    "        round date to closest month\n",
    "        \"\"\"\n",
    "        # start of THIS month\n",
    "        m1 = date.fromYMD(date.get('year'),date.get('month'),ee.Number(1))\n",
    "\n",
    "        # start of NEXT month\n",
    "        m2 = m1.advance(1,'month')\n",
    "\n",
    "        # difference from date\n",
    "        d1 = ee.Number(date.difference(m1,'day')).abs()\n",
    "        d2 = ee.Number(date.difference(m2,'day')).abs()\n",
    "\n",
    "        # return closest start of month\n",
    "        return ee.Date(ee.Algorithms.If(d2.gt(d1),m1,m2))\n",
    "\n",
    "\n",
    "\n",
    "    def water(geom,date):\n",
    "        \"\"\"\n",
    "        Water vapour column above target at time of image aquisition.\n",
    "\n",
    "        (Kalnay et al., 1996, The NCEP/NCAR 40-Year Reanalysis Project. Bull. \n",
    "        Amer. Meteor. Soc., 77, 437-471)\n",
    "        \"\"\"\n",
    "\n",
    "        # Point geometry required\n",
    "        centroid = geom.centroid()\n",
    "\n",
    "        # H2O datetime is in 6 hour intervals\n",
    "        H2O_date = Atmospheric.round_date(date,6)\n",
    "\n",
    "        # filtered water collection\n",
    "        water_ic = ee.ImageCollection('NCEP_RE/surface_wv').filterDate(H2O_date, H2O_date.advance(1,'month'))\n",
    "\n",
    "        # water image\n",
    "        water_img = ee.Image(water_ic.first())\n",
    "\n",
    "        # water_vapour at target\n",
    "        water = water_img.reduceRegion(reducer=ee.Reducer.mean(), geometry=centroid).get('pr_wtr')\n",
    "\n",
    "        # convert to Py6S units (Google = kg/m^2, Py6S = g/cm^2)\n",
    "        water_Py6S_units = ee.Number(water).divide(10)                                   \n",
    "\n",
    "        return water_Py6S_units\n",
    "\n",
    "\n",
    "    def ozone(geom,date):\n",
    "        \"\"\"\n",
    "        returns ozone measurement from merged TOMS/OMI dataset\n",
    "\n",
    "        OR\n",
    "\n",
    "        uses our fill value (which is mean value for that latlon and day-of-year)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Point geometry required\n",
    "        centroid = geom.centroid()\n",
    "\n",
    "        def ozone_measurement(centroid,O3_date):\n",
    "            # filtered ozone collection\n",
    "            ozone_ic = ee.ImageCollection('TOMS/MERGED').filterDate(O3_date, O3_date.advance(1,'month'))\n",
    "\n",
    "            # ozone image\n",
    "            ozone_img = ee.Image(ozone_ic.first())\n",
    "\n",
    "            # ozone value IF TOMS/OMI image exists ELSE use fill value\n",
    "            ozone = ee.Algorithms.If(ozone_img,\\\n",
    "            ozone_img.reduceRegion(reducer=ee.Reducer.mean(), geometry=centroid).get('ozone'),\\\n",
    "            ozone_fill(centroid,O3_date))\n",
    "\n",
    "            return ozone\n",
    "\n",
    "        def ozone_fill(centroid,O3_date):\n",
    "            \"\"\"\n",
    "            Gets our ozone fill value (i.e. mean value for that doy and latlon)\n",
    "\n",
    "            you can see it\n",
    "            1) compared to LEDAPS: https://code.earthengine.google.com/8e62a5a66e4920e701813e43c0ecb83e\n",
    "            2) as a video: https://www.youtube.com/watch?v=rgqwvMRVguI&feature=youtu.be\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            # ozone fills (i.e. one band per doy)\n",
    "            ozone_fills = ee.ImageCollection('users/samsammurphy/public/ozone_fill').toList(366)\n",
    "\n",
    "            # day of year index\n",
    "            jan01 = ee.Date.fromYMD(O3_date.get('year'),1,1)\n",
    "            doy_index = date.difference(jan01,'day').toInt()# (NB. index is one less than doy, so no need to +1)\n",
    "\n",
    "            # day of year image\n",
    "            fill_image = ee.Image(ozone_fills.get(doy_index))\n",
    "\n",
    "            # return scalar fill value\n",
    "            return fill_image.reduceRegion(reducer=ee.Reducer.mean(), geometry=centroid).get('ozone')\n",
    "\n",
    "        # O3 datetime in 24 hour intervals\n",
    "        O3_date = Atmospheric.round_date(date,24)\n",
    "\n",
    "        # TOMS temporal gap\n",
    "        TOMS_gap = ee.DateRange('1994-11-01','1996-08-01')  \n",
    "\n",
    "        # avoid TOMS gap entirely\n",
    "        ozone = ee.Algorithms.If(TOMS_gap.contains(O3_date),ozone_fill(centroid,O3_date),ozone_measurement(centroid,O3_date))\n",
    "\n",
    "        # fix other data gaps (e.g. spatial, missing images, etc..)\n",
    "        ozone = ee.Algorithms.If(ozone,ozone,ozone_fill(centroid,O3_date))\n",
    "\n",
    "        #convert to Py6S units \n",
    "        ozone_Py6S_units = ee.Number(ozone).divide(1000)# (i.e. Dobson units are milli-atm-cm )                             \n",
    "\n",
    "        return ozone_Py6S_units\n",
    "\n",
    "\n",
    "    def aerosol(geom,date):\n",
    "        \"\"\"\n",
    "        Aerosol Optical Thickness.\n",
    "\n",
    "        try:\n",
    "          MODIS Aerosol Product (monthly)\n",
    "        except:\n",
    "          fill value\n",
    "        \"\"\"\n",
    "\n",
    "        def aerosol_fill(date):\n",
    "            \"\"\"\n",
    "            MODIS AOT fill value for this month (i.e. no data gaps)\n",
    "            \"\"\"\n",
    "            return ee.Image('users/samsammurphy/public/AOT_stack')\\\n",
    "                   .select([ee.String('AOT_').cat(date.format('M'))])\\\n",
    "                   .rename(['AOT_550'])\n",
    "\n",
    "\n",
    "        def aerosol_this_month(date):\n",
    "            \"\"\"\n",
    "            MODIS AOT original data product for this month (i.e. some data gaps)\n",
    "            \"\"\"\n",
    "            # image for this month\n",
    "            img =  ee.Image(\\\n",
    "                          ee.ImageCollection('MODIS/006/MOD08_M3')\\\n",
    "                            .filterDate(Atmospheric.round_month(date))\\\n",
    "                            .first()\\\n",
    "                         )\n",
    "\n",
    "            # fill missing month (?)\n",
    "            img = ee.Algorithms.If(img,\\\n",
    "                                   # all good\n",
    "                                   img\\\n",
    "                                   .select(['Aerosol_Optical_Depth_Land_Mean_Mean_550'])\\\n",
    "                                   .divide(1000)\\\n",
    "                                   .rename(['AOT_550']),\\\n",
    "                                  # missing month\n",
    "                                    aerosol_fill(date))\n",
    "\n",
    "            return img    \n",
    "\n",
    "\n",
    "        def get_AOT(AOT_band,geom):\n",
    "            \"\"\"\n",
    "            AOT scalar value for target\n",
    "            \"\"\"  \n",
    "            return ee.Image(AOT_band).reduceRegion(reducer=ee.Reducer.mean(),\\\n",
    "                                     geometry=geom.centroid())\\\n",
    "                                    .get('AOT_550')\n",
    "\n",
    "\n",
    "        after_modis_start = date.difference(ee.Date('2000-03-01'),'month').gt(0)\n",
    "\n",
    "        AOT_band = ee.Algorithms.If(after_modis_start, aerosol_this_month(date), aerosol_fill(date))\n",
    "\n",
    "        AOT = get_AOT(AOT_band,geom)\n",
    "\n",
    "        AOT = ee.Algorithms.If(AOT,AOT,get_AOT(aerosol_fill(date),geom))\n",
    "        # i.e. check reduce region worked (else force fill value)\n",
    "\n",
    "        return AOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geemap\n",
    "import ee\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from geemap import geojson_to_ee, ee_to_geojson\n",
    "from ipyleaflet import GeoJSON\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import urllib.request\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image,ImageDraw,ImageFont\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "#initialize GEE using your Google Account\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "    \n",
    "from Py6S import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wiw(img):\n",
    "    wiw = img.expression(\n",
    "        '((B8A/10000) <= 0.1804) && ((B12/10000) <= 0.1131)',{'B8A':img.select('B8A'),'B12':img.select('B12')}\n",
    "    ).rename('RWS')\n",
    "    return img.addBands(wiw)\n",
    "\n",
    "def add_rws(img):\n",
    "    mndwi = img.normalizedDifference(['B3','B11']).rename('MNDWI')\n",
    "    mgrn = img.select(['B3','B4','B8']).divide(10000).reduce(ee.Reducer.min()).rename('MGRN')\n",
    "    rws = img.expression(\n",
    "        '(MNDWI > 0.3) && (MGRN < 0.15)',{'MNDWI':mndwi,'MGRN':mgrn}\n",
    "    ).rename('RWS')\n",
    "    return img.addBands(rws)\n",
    "\n",
    "def apply_rws(img):\n",
    "    mask = img.select('RWS').eq(1)\n",
    "    masked_img = img.updateMask(mask)\n",
    "    return masked_img\n",
    "\n",
    "def get_labels(img):\n",
    "    cluster =  img.select('cluster')\n",
    "    cluster_vector = cluster.reduceToVectors(reducer = ee.Reducer.countEvery(),geometry=img.geometry(),bestEffort=True,scale=90)\n",
    "    labels = ee.List(cluster_vector.aggregate_array('label')).distinct().sort()\n",
    "    return labels\n",
    "\n",
    "def add_kmeans(img):\n",
    "    rws_mask = img.select('RWS').eq(1)\n",
    "    rgb_img = img.select(['B4', 'B3', 'B2']).updateMask(rws_mask)\n",
    "    \n",
    "    train_samples = rgb_img.sample(scale=10,numPixels=2000,seed=42,tileScale=4,dropNulls=True)\n",
    "    k_means = ee.Clusterer.wekaKMeans(8).train(train_samples)\n",
    "    img_cluster = rgb_img.cluster(k_means).rename('cluster')\n",
    "    return img.addBands(img_cluster)\n",
    "\n",
    "def plot_mask(data,layer_name):\n",
    "    img = data.select(layer_name)\n",
    "    img_mask = img.updateMask(img.eq(1))\n",
    "    Map.addLayer(img_mask, {'palette': 'red'}, f'{layer_name}')\n",
    "    \n",
    "def plot_rgb(img,text,bands = ['B4', 'B3', 'B2']):\n",
    "    viz_rgb = {'bands': bands,'gain': [0.1, 0.1, 0.1],'scale':90}\n",
    "    Map.addLayer(img, viz_rgb, text+' RGB')\n",
    "    \n",
    "def plot_false(img,text):\n",
    "    viz_rgb = {'bands': ['B6', 'B5', 'B2'],'gain': [0.1, 0.1, 0.1],'scale':90}\n",
    "    Map.addLayer(img, viz_rgb, text+' False')\n",
    "    \n",
    "def get_dates(data):\n",
    "    date= ee.Image(data).get('GENERATION_TIME')\n",
    "    return date\n",
    "\n",
    "def add_mnws(img):\n",
    "\n",
    "    band_names = ['B2','B3','B4','B5','B6','B7','B8','B8A','B11','B12']\n",
    "    multiband_img = img.select(band_names)\n",
    "    cluster_img = img.select('cluster')\n",
    "\n",
    "    samples = multiband_img.addBands(cluster_img).stratifiedSample(numPoints=100,classBand='cluster',scale=10,tileScale=4,seed=42,dropNulls=True)\n",
    "\n",
    "    nws_list = []\n",
    "    for label in list(range(0,8)):\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        for band in band_names:\n",
    "            img_band_mu = samples.filter(ee.Filter.eq('cluster',label)).aggregate_mean(band)\n",
    "            img_band_std = samples.filter(ee.Filter.eq('cluster',label)).aggregate_total_sd(band)\n",
    "\n",
    "            img_band_raw = multiband_img.select(band)\n",
    "            img_band_score = img_band_raw.subtract(img_band_mu).divide(img_band_std).pow(2).rename(f'{label} {band}')\n",
    "            \n",
    "            scores.append(img_band_score)\n",
    "\n",
    "        nws = ee.Image.cat(scores).reduce('sum').divide(len(band_names)).sqrt().rename('NWS')\n",
    "        nws_list.append(nws)\n",
    "\n",
    "    mnws = ee.Image.cat(nws_list).reduce('min').rename('MNWS')\n",
    "    return mnws\n",
    "\n",
    "def get_wd(img):\n",
    "    img_mnws = img.select('MNWS')\n",
    "    wd_i = img.expression('MNWS < 3',{'MNWS':img_mnws})\n",
    "    return wd_i\n",
    "\n",
    "def count_water_pixel(img):\n",
    "    count = img.select('RWS').gt(0).reduceRegion(ee.Reducer.sum(),scale=10,maxPixels=1e5,bestEffort=True,tileScale=4).values().get(0)\n",
    "    return img.set({'water_pixel': count})\n",
    "\n",
    "def export_frames(img_col,dir_name,annot_list):\n",
    "    \n",
    "    print(f'Exporting {len(annot_list)} frames...')\n",
    "    args = {'dimensions': 480,'bands': ['B11', 'B8', 'B3'],'gain': [0.08, 0.08, 0.08],'format':'png'}\n",
    "    url = img_col.getFilmstripThumbURL(args)\n",
    "    \n",
    "    os.makedirs(dir_name,exist_ok=True)\n",
    "\n",
    "    saved_strips = urllib.request.urlretrieve(url,f'{dir_name}.png')[0]\n",
    "    \n",
    "    img_arr = np.array(Image.open(saved_strips))\n",
    "    img_stack = img_arr.reshape(len(annot_list),img_arr.shape[0]//len(annot_list),img_arr.shape[1],img_arr.shape[2])\n",
    "    \n",
    "    for i in range(len(annot_list)):\n",
    "        img_pil = Image.fromarray(img_stack[i])\n",
    "        ImageDraw.Draw(img_pil).text((0, 0),annot_list[i],font = ImageFont.truetype(\"arial.ttf\", 20),fill=(0,0,0))\n",
    "        fn = f\"{dir_name}/{dir_name.split('/')[-1]}_{i}.png\"  \n",
    "        img_pil.save(fn)\n",
    "        \n",
    "    os.remove(saved_strips)\n",
    "    print(f'{len(annot_list)} frames exported in {dir_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#set up GEE map canvas (will be updated with every addLayer() method)\n",
    "Map = geemap.Map(center=[-27.93186,32.48897],zoom=9)\n",
    "Map.add_basemap('SATELLITE')\n",
    "# Map.add_basemap('CartoDB.DarkMatter')\n",
    "\n",
    "#study area\n",
    "file_path = './data/boundaries/ramsar_stlucia_bbox.geojson'\n",
    "with open(file_path) as f:\n",
    "    coord = json.load(f)['features'][0]['geometry']['coordinates'][0]\n",
    "    line_geom = ee.Geometry.LineString(coord)\n",
    "    \n",
    "    #polygon used for clipping purposes\n",
    "    poly_geom = ee.Geometry.Polygon(coord)\n",
    "    \n",
    "Map.addLayer(ee_object=line_geom, vis_params={'color':'red'}, name=\"Lesser Isimangaliso Wetland Park\")\n",
    "\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# jrc_gsw_s = ee.ImageCollection(\"JRC/GSW1_1/YearlyHistory\").filter(ee.Filter.eq('year',2017)).first().clip(poly_geom)\n",
    "# Map.addLayer(jrc_gsw_s,{'min': 0, 'max': 3,'palette':['cccccc','ffffff','99d9ea','0000ff']},'JRC GSWS-S 2017')\n",
    "\n",
    "\n",
    "# srtm_30m = ee.Image(\"USGS/SRTMGL1_003\").clip(poly_geom)\n",
    "srtm_30m_slope = ee.Terrain.slope(srtm_30m)\n",
    "# Map.addLayer(srtm_30m,{'min': 0, 'max': 10},'srtm')\n",
    "Map.addLayer(srtm_30m_slope.lte(5),{'min': 0, 'max': 1},'slope')\n",
    "\n",
    "# jrc_gsw_s_m = ee.ImageCollection(\"JRC/GSW1_1/MonthlyHistory\").filter(ee.Filter.eq('year',2017)).filter(ee.Filter.eq('month',1)).first().clip(poly_geom)\n",
    "# Map.addLayer(jrc_gsw_s_m,{'min': 0, 'max': 2,'palette':['cccccc','ffffff','0000ff']},'JRC GSWS-S 2017 January')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Sentinel-2 Level-1C collection for 2017\n",
    "\n",
    "cl_pct = 60\n",
    "\n",
    "s2_col = ee.ImageCollection(\"COPERNICUS/S2\") \\\n",
    "    .filterBounds(poly_geom).filterDate('2017-01-01','2017-12-31') \\\n",
    "    .filter(ee.Filter.inList('MGRS_TILE', ['36JVP','36JVQ'])) \\\n",
    "    .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', cl_pct))\n",
    "\n",
    "# #filter duplicated products \n",
    "s2_col_list = s2_col.toList(s2_col.size())\n",
    "\n",
    "print('Nr. images found: ', s2_col.size().getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique_dates = s2_col_list.map(get_dates).distinct()\n",
    "\n",
    "#iterave over collection and create mosaic based on similar datetime\n",
    "col = []\n",
    "for i in range(unique_dates.size().getInfo()):\n",
    "    unique_date = unique_dates.get(i)\n",
    "    date_day = ee.Date(unique_dates.get(i)).format('yyyy-MM-dd')\n",
    "    date_month = ee.Date(unique_dates.get(i)).format('yyyy-MM')\n",
    "    similar_tiles = s2_col.filter(ee.Filter.eq('GENERATION_TIME', unique_date)).mosaic().clip(poly_geom).set({'DateDay':date_day,'Month':date_month})\n",
    "    col.append(similar_tiles)\n",
    "    \n",
    "s2_mosaic_col_a = ee.ImageCollection(col)\n",
    "\n",
    "#iterate over mosaic again and merge based on similar days\n",
    "date_days = ee.List(s2_mosaic_col_a.aggregate_array('DateDay')).getInfo()\n",
    "days,count = np.unique(date_days, return_counts=True)\n",
    "dups = days[count>1]\n",
    "non_dups = np.setdiff1d(days,dups)\n",
    "\n",
    "dup_mos = ee.ImageCollection([s2_mosaic_col_a.filter(ee.Filter.eq('DateDay',dup)).mosaic().clip(poly_geom).set({'DateDay':dup}) for dup in dups.tolist()])\n",
    "non_dup_mos = s2_mosaic_col_a.filter(ee.Filter.inList('DateDay', non_dups.tolist()))\n",
    "\n",
    "s2_mosaic_col_clean = non_dup_mos.merge(dup_mos).sort('DateDay')\n",
    "\n",
    "print('Nr. mosaics created: ', len(date_days),len(days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #export mosaics as png\n",
    "# dir_name = './data/ts_animation/2019_cl60'\n",
    "# export_frames(s2_mosaic_col_clean,dir_name,days.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select best mosaics \n",
    "cleaned_dir_name = './data/ts_animation/2017_cl60_cleaned_v2'\n",
    "selected_indices = np.sort(np.array(list(map(lambda x:x.split('_')[-1].split('.')[0],os.listdir(cleaned_dir_name)))).astype(int))\n",
    "selected_days = days[selected_indices].tolist()\n",
    "\n",
    "#filter best mosaic from collection\n",
    "s2_mosaic_best = s2_mosaic_col_clean.filter(ee.Filter.inList('DateDay', selected_days))\n",
    "s2_mosaic_best_list = s2_mosaic_best.toList(s2_mosaic_best.size())\n",
    "print(s2_mosaic_best.size().getInfo(),'mosaics selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "band_names = ['B2','B3','B4','B5','B6','B7','B8','B8A','B10','B11','B12']\n",
    "toa = s2_mosaic_best.select(band_names).first().divide(10000)\n",
    "info = s2_col.first().getInfo()['properties']\n",
    "scene_date = datetime.datetime.utcfromtimestamp(info['system:time_start']/1000)\n",
    "solar_z = info['MEAN_SOLAR_ZENITH_ANGLE']\n",
    "\n",
    "date = ee.Date(str(scene_date.date()))\n",
    "geom = ee.Geometry.Point(-27.93186,32.48897)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o = Atmospheric.water(geom,date).getInfo()\n",
    "o3 = Atmospheric.ozone(geom,date).getInfo()\n",
    "aot = Atmospheric.aerosol(geom,date).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRTM = ee.Image(\"USGS/SRTMGL1_003\")# Shuttle Radar Topography mission covers *most* of the Earth\n",
    "alt = SRTM.reduceRegion(reducer = ee.Reducer.mean(),geometry = poly_geom).get('elevation').getInfo()\n",
    "km = alt/1000 # i.e. Py6S uses units of kilometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "s = SixS()\n",
    "\n",
    "# Atmospheric constituents\n",
    "s.atmos_profile = AtmosProfile.UserWaterAndOzone(h2o,o3)\n",
    "s.aero_profile = AeroProfile.Continental\n",
    "s.aot550 = aot\n",
    "\n",
    "# Earth-Sun-satellite geometry\n",
    "s.geometry = Geometry.User()\n",
    "s.geometry.view_z = 0               # always NADIR (I think..)\n",
    "s.geometry.solar_z = solar_z        # solar zenith angle\n",
    "s.geometry.month = scene_date.month # month and day used for Earth-Sun distance\n",
    "s.geometry.day = scene_date.day     # month and day used for Earth-Sun distance\n",
    "s.altitudes.set_sensor_satellite_level()\n",
    "s.altitudes.set_target_custom_altitude(km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectralResponseFunction(bandname):\n",
    "    \"\"\"\n",
    "    Extract spectral response function for given band name\n",
    "    \"\"\"\n",
    "\n",
    "    bandSelect = {\n",
    "        'B1':PredefinedWavelengths.S2A_MSI_01,\n",
    "        'B2':PredefinedWavelengths.S2A_MSI_02,\n",
    "        'B3':PredefinedWavelengths.S2A_MSI_03,\n",
    "        'B4':PredefinedWavelengths.S2A_MSI_04,\n",
    "        'B5':PredefinedWavelengths.S2A_MSI_05,\n",
    "        'B6':PredefinedWavelengths.S2A_MSI_06,\n",
    "        'B7':PredefinedWavelengths.S2A_MSI_07,\n",
    "        'B8':PredefinedWavelengths.S2A_MSI_08,\n",
    "        'B8A':PredefinedWavelengths.S2A_MSI_8A,\n",
    "        'B9':PredefinedWavelengths.S2A_MSI_09,\n",
    "        'B10':PredefinedWavelengths.S2A_MSI_10,\n",
    "        'B11':PredefinedWavelengths.S2A_MSI_11,\n",
    "        'B12':PredefinedWavelengths.S2A_MSI_12,\n",
    "        }\n",
    "    \n",
    "    return Wavelength(bandSelect[bandname])\n",
    "\n",
    "def toa_to_rad(bandname):\n",
    "    \"\"\"\n",
    "    Converts top of atmosphere reflectance to at-sensor radiance\n",
    "    \"\"\"\n",
    "    \n",
    "    # solar exoatmospheric spectral irradiance\n",
    "    ESUN = info['SOLAR_IRRADIANCE_'+bandname]\n",
    "    solar_angle_correction = math.cos(math.radians(solar_z))\n",
    "    \n",
    "    # Earth-Sun distance (from day of year)\n",
    "    doy = scene_date.timetuple().tm_yday\n",
    "    d = 1 - 0.01672 * math.cos(0.9856 * (doy-4))# http://physics.stackexchange.com/questions/177949/earth-sun-distance-on-a-given-day-of-the-year\n",
    "   \n",
    "    # conversion factor\n",
    "    multiplier = ESUN*solar_angle_correction/(math.pi*d**2)\n",
    "\n",
    "    # at-sensor radiance\n",
    "    rad = toa.select(bandname).multiply(multiplier)\n",
    "    \n",
    "    return rad\n",
    "\n",
    "def surface_reflectance(bandname):\n",
    "    \"\"\"\n",
    "    Calculate surface reflectance from at-sensor radiance given waveband name\n",
    "    \"\"\"\n",
    "    \n",
    "    # run 6S for this waveband\n",
    "    s.wavelength = spectralResponseFunction(bandname)\n",
    "    s.run()\n",
    "    \n",
    "    # extract 6S outputs\n",
    "    Edir = s.outputs.direct_solar_irradiance             #direct solar irradiance\n",
    "    Edif = s.outputs.diffuse_solar_irradiance            #diffuse solar irradiance\n",
    "    Lp   = s.outputs.atmospheric_intrinsic_radiance      #path radiance\n",
    "    absorb  = s.outputs.trans['global_gas'].upward       #absorption transmissivity\n",
    "    scatter = s.outputs.trans['total_scattering'].upward #scattering transmissivity\n",
    "    tau2 = absorb*scatter                                #total transmissivity\n",
    "    \n",
    "    # radiance to surface reflectance\n",
    "    rad = toa_to_rad(bandname)\n",
    "    ref = rad.subtract(Lp).multiply(math.pi).divide(tau2*(Edir+Edif))\n",
    "    \n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface reflectance rgb\n",
    "b = surface_reflectance('B2')\n",
    "g = surface_reflectance('B3')\n",
    "r = surface_reflectance('B4')\n",
    "ref = r.addBands(g).addBands(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_dates = s2_col_list.map(get_dates).map(lambda x:ee.Date(x).format('yyyy-MM-dd')).getInfo()\n",
    "sun_ele = s2_col.aggregate_array('MEAN_SOLAR_ZENITH_ANGLE').getInfo()\n",
    "sun_azi = s2_col.aggregate_array('MEAN_SOLAR_AZIMUTH_ANGLE').getInfo()\n",
    "data = np.array( [raw_dates,sun_ele,sun_azi] )\n",
    "\n",
    "sun_data_clean = {}\n",
    "for d in selected_days:\n",
    "    index = np.where(data[0]==d)[0]\n",
    "    sun_ele_mu = data[1][index].astype(float).mean()\n",
    "    sun_azi_mu = data[2][index].astype(float).mean()\n",
    "    sun_info = [sun_ele_mu,sun_azi_mu]\n",
    "    sun_data_clean[d]=sun_info\n",
    "    \n",
    "sun_data_df = pd.DataFrame(sun_data_clean).T\n",
    "sun_data_df.columns = ['mean_sun_zen_angle','mean_sun_azi_angle']\n",
    "sun_data_df.to_csv('./data/sun_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_rgb(toa.multiply(10000),'toa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_rgb(ref.multiply(10000),'sr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create median composite collection\n",
    "band_names = ['B2','B3','B4','B5','B6','B7','B8','B8A','B10','B11','B12']\n",
    "\n",
    "months = [f'2017-{str(i).zfill(2)}' for i in range(1,13)]\n",
    "new_group = []\n",
    "for m in months:\n",
    "    group = []\n",
    "    for d in selected_days:\n",
    "        if m in d:\n",
    "            group.append(d)\n",
    "    new_group.append(group)\n",
    "    \n",
    "monthly_col = []\n",
    "for g in new_group:\n",
    "    if len(g)>1:\n",
    "        s2_mosaic_month = s2_mosaic_best.filter(ee.Filter.inList('DateDay', g)).select(band_names).median()\n",
    "    else:\n",
    "        s2_mosaic_month = s2_mosaic_best.filter(ee.Filter.inList('DateDay', g)).select(band_names).first()\n",
    "    monthly_col.append(s2_mosaic_month)\n",
    "monthly_col = ee.ImageCollection(monthly_col)\n",
    "monthly_col_list = monthly_col.toList(monthly_col.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnws_rws_25feb = add_mnws(add_kmeans(add_rws(s2_mosaic_best.first())))\n",
    "mnws_wiw_25feb = add_mnws(add_kmeans(add_wiw(s2_mosaic_best.first())))\n",
    "file_path = './data/boundaries/landcover_25feb.geojson'\n",
    "with open(file_path) as f:\n",
    "    coords = json.load(f)\n",
    "    features = geojson_to_ee(coords)\n",
    "    labels = features.aggregate_array('type').distinct()\n",
    "    labels_int = ee.List([1,2,3,4,5,6])\n",
    "    features_remapped = features.remap(labels,labels_int,'type')\n",
    "    label_class = dict(zip(labels_int.getInfo(),labels.getInfo()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnws_rws_25feb_samples = mnws_rws_25feb.sampleRegions(collection= features_remapped,properties= ['type'],scale= 10,tileScale=4)\n",
    "mnws_wiw_25feb_samples = mnws_wiw_25feb.sampleRegions(collection= features_remapped,properties= ['type'],scale= 10,tileScale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mnws_values = mnws_rws_25feb_samples.aggregate_array('MNWS').getInfo()\n",
    "labels_values = mnws_rws_25feb_samples.aggregate_array('type').getInfo()\n",
    "\n",
    "data = pd.DataFrame(np.array([mnws_values,labels_values])).T\n",
    "data.columns = ['MNWS','label']\n",
    "data['label'] = data['label'].astype(int)\n",
    "data['label'] = data['label'].map(label_class)\n",
    "data.boxplot(column='MNWS',by='label',grid=False,rot=45, fontsize=20,figsize=(10,5))\n",
    "\n",
    "for lab in data.label.unique():\n",
    "    print(data[data['label']==lab].describe().loc[['min','mean','max','std']].T,lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnws_values = mnws_wiw_25feb_samples.aggregate_array('MNWS').getInfo()\n",
    "labels_values = mnws_wiw_25feb_samples.aggregate_array('type').getInfo()\n",
    "\n",
    "data = pd.DataFrame(np.array([mnws_values,labels_values])).T\n",
    "data.columns = ['MNWS','label']\n",
    "data['label'] = data['label'].astype(int)\n",
    "data['label'] = data['label'].map(label_class)\n",
    "data.boxplot(column='MNWS',by='label',grid=False,rot=45, fontsize=20,figsize=(10,5))\n",
    "\n",
    "for lab in data.label.unique():\n",
    "    print(data[data['label']==lab].describe().loc[['min','mean','max','std']].T,lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map MNWS timeseries with RWS (original)\n",
    "mnws_ts_rws = s2_mosaic_best.map(add_rws).map(add_kmeans).map(add_mnws)\n",
    "\n",
    "#map MNWS timeseries with WIW \n",
    "mnws_ts_wiw = s2_mosaic_best.map(add_wiw).map(add_kmeans).map(add_mnws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate IWF with RWS\n",
    "img_wf_rws = mnws_ts_rws.map(get_wd).reduce(reducer=ee.Reducer.sum(),parallelScale=8).divide(len(selected_days))\n",
    "\n",
    "#calculate IWF with WIW\n",
    "img_wf_wiw = mnws_ts_wiw.map(get_wd).reduce(reducer=ee.Reducer.sum(),parallelScale=8).divide(len(selected_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all bands stack to one geotiff\n",
    "geemap.ee_export_image(img_wf_rws, filename='./data/iwf/iwf_rws_39.tif', scale=90, region=poly_geom, file_per_band=False)\n",
    "geemap.ee_export_image(img_wf_wiw, filename='./data/iwf/iwf_wiw_39.tif', scale=90, region=poly_geom, file_per_band=False)\n",
    "\n",
    "remove_zips = list(map(lambda x:os.remove(x),glob('./data/iwf/*.zip')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export image collection as geotiff \n",
    "# geemap.ee_export_image_collection(mnws_ts, out_dir='./data/mnws_ts_wiw',region=poly_geom,scale=90)\n",
    "# remove_zips = list(map(lambda x:os.remove(x),glob('./data/mnws_ts_wiw/*.zip')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export image to drive\n",
    "band_names = ['B1','B2','B3','B4','B5','B6','B7','B8','B8A','B9','B10','B11','B12']\n",
    "aoi = ee_to_geojson(poly_geom)['coordinates'][0]\n",
    "\n",
    "for i in range(len(selected_days[21:])):\n",
    "\n",
    "    file_name = 'mosaic_'+selected_days[21:][i].replace('-','')\n",
    "    data = ee.Image(s2_mosaic_best_list.get(i)).select(band_names)\n",
    "    task = ee.batch.Export.image.toDrive(data, \n",
    "                                         description='mosaic',\n",
    "                                         folder='GEE_output',\n",
    "                                        fileNamePrefix=file_name,\n",
    "                                        crs='EPSG:32736',\n",
    "                                        scale=10,\n",
    "                                        maxPixels=1e8,\n",
    "                                        fileFormat='GeoTIFF',\n",
    "                                        skipEmptyTiles=True,\n",
    "                                        region=aoi)\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jrc_gsw_s = ee.ImageCollection(\"JRC/GSW1_1/YearlyHistory\").filter(ee.Filter.eq('year',2017)).first().clip(poly_geom)\n",
    "srtm_30m = ee.Image(\"USGS/SRTMGL1_003\").clip(poly_geom)\n",
    "srtm_30m_slope = ee.Terrain.slope(srtm_30m)\n",
    "jrc_gsw_s_m = ee.ImageCollection(\"JRC/GSW1_1/MonthlyHistory\").filter(ee.Filter.eq('year',2017)).map(lambda x:x.clip(poly_geom)).toList(12)\n",
    "jrc_gsw_s_m_list = [ee.Image(jrc_gsw_s_m.get(i)) for i in range(12)]\n",
    "\n",
    "imgs2exp = [jrc_gsw_s,srtm_30m,srtm_30m_slope]+jrc_gsw_s_m_list\n",
    "fnames = ['YearlyHistory_2017','srtm_30m','srtm_30m_slope'] + [f'MonthlyHistory_{i}' for i in list(range(1,13))]\n",
    "\n",
    "aoi = ee_to_geojson(poly_geom)['coordinates'][0]\n",
    "\n",
    "for i in range(len(fnames)):\n",
    "    task = ee.batch.Export.image.toDrive(imgs2exp[i], \n",
    "                                         description='ancillary_data',\n",
    "                                         folder='GEE_output',\n",
    "                                         fileNamePrefix=fnames[i],\n",
    "                                         crs='EPSG:32736',\n",
    "                                         scale=10,\n",
    "                                         maxPixels=1e8,\n",
    "                                         fileFormat='GeoTIFF',\n",
    "                                         skipEmptyTiles=True,\n",
    "                                         region=aoi)\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export image to drive\n",
    "\n",
    "band_names = ['B2','B3','B4','B5','B6','B7','B8','B8A','B10','B11','B12']\n",
    "\n",
    "#export median composite\n",
    "aoi = ee_to_geojson(poly_geom)['coordinates'][0]\n",
    "task = ee.batch.Export.image.toDrive(s2_mosaic_best.select(band_names).median(), \n",
    "                                         description='mosaic_composite',\n",
    "                                         folder='GEE_output',\n",
    "                                         fileNamePrefix='4mosaics_median_composite_june',\n",
    "                                         crs='EPSG:32736',\n",
    "                                         scale=10,\n",
    "                                         maxPixels=1e8,\n",
    "                                         fileFormat='GeoTIFF',\n",
    "                                         skipEmptyTiles=True,\n",
    "                                         region=aoi)\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "task.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
