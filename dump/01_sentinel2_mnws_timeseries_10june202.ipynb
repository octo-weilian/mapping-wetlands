{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import ee\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from geemap import geojson_to_ee, ee_to_geojson\n",
    "from ipyleaflet import GeoJSON\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import urllib.request\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image,ImageDraw,ImageFont\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#initialize GEE using your Google Account\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up GEE map canvas (will be updated with every addLayer() method)\n",
    "Map = geemap.Map(center=[-27.93186,32.48897],zoom=9)\n",
    "# Map.add_basemap('SATELLITE')\n",
    "Map.add_basemap('CartoDB.DarkMatter')\n",
    "\n",
    "#study area\n",
    "file_path = './data/boundaries/ramsar_stlucia_bbox.geojson'\n",
    "with open(file_path) as f:\n",
    "    coord = json.load(f)['features'][0]['geometry']['coordinates'][0][0]\n",
    "    line_geom = ee.Geometry.LineString(coord)\n",
    "    \n",
    "    #polygon used for clipping purposes\n",
    "    poly_geom = ee.Geometry.Polygon(coord)\n",
    "    \n",
    "Map.addLayer(ee_object=line_geom, vis_params={'color':'red'}, name=\"Lesser Isimangaliso Wetland Park\")\n",
    "Map\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_s2(data_info):\n",
    "    prod_id = data_info['properties']['PRODUCT_ID']\n",
    "    date = pd.to_datetime(re.findall(r\"(\\d{8})T\", prod_id)[0]).date()\n",
    "    cl_cover = round(data_info['properties']['CLOUD_COVERAGE_ASSESSMENT'],2)\n",
    "    tile = re.findall(r\"(\\d{2}[A-Z]{3})\", prod_id)[0]\n",
    "    df = pd.DataFrame({'id':prod_id,'date':date,'tile':tile,'cloudcover':cl_cover},index=[0])\n",
    "    return df\n",
    "\n",
    "def filter_duplicates (s2_col_list):\n",
    "    s2_filtered = []\n",
    "    for i in range(s2_col.size().getInfo()):\n",
    "        prod_id =  s2_col_list.get(i).getInfo()['properties']['PRODUCT_ID']\n",
    "        if 'OPER_PRD' not in prod_id:\n",
    "            s2_filtered += [ee.Image(s2_col_list.get(i))]\n",
    "    s2_filtered_col = ee.ImageCollection(s2_filtered)\n",
    "    s2_filtered_list = s2_filtered_col.toList(s2_filtered_col.size())\n",
    "    return s2_filtered_list\n",
    "\n",
    "def add_wiw(img):\n",
    "    wiw = img.expression(\n",
    "        '((B8A/10000) <= 0.1804) && ((B12/10000) <= 0.1131)',{'B8A':img.select('B8A'),'B12':img.select('B12')}\n",
    "    ).rename('RWS')\n",
    "    return img.addBands(wiw)\n",
    "\n",
    "def add_rws(img):\n",
    "    mndwi = img.normalizedDifference(['B3','B11']).rename('MNDWI')\n",
    "    mgrn = img.select(['B3','B4','B5']).divide(10000).reduce(ee.Reducer.min()).rename('MGRN')\n",
    "    rws = img.expression(\n",
    "        '(MNDWI > 0.3) && (MGRN < 0.15)',{'MNDWI':mndwi,'MGRN':mgrn}\n",
    "    ).rename('RWS')\n",
    "    return img.addBands(rws)\n",
    "\n",
    "def apply_rws(img):\n",
    "    mask = img.select('RWS').eq(1)\n",
    "    masked_img = img.updateMask(mask)\n",
    "    return masked_img\n",
    "\n",
    "def get_labels(img):\n",
    "    cluster =  img.select('cluster')\n",
    "    cluster_vector = cluster.reduceToVectors(reducer = ee.Reducer.countEvery(),geometry=img.geometry(),bestEffort=True,scale=90)\n",
    "    labels = ee.List(cluster_vector.aggregate_array('label')).distinct().sort()\n",
    "    return labels\n",
    "\n",
    "def add_kmeans(img):\n",
    "    rws_mask = img.select('RWS').eq(1)\n",
    "    rgb_img = img.select(['B4', 'B3', 'B2']).updateMask(rws_mask)\n",
    "    \n",
    "    train_samples = rgb_img.sample(scale=10,numPixels=2000,seed=42,tileScale=4,dropNulls=True)\n",
    "    k_means = ee.Clusterer.wekaKMeans(8).train(train_samples)\n",
    "    img_cluster = rgb_img.cluster(k_means).rename('cluster')\n",
    "    return img.addBands(img_cluster)\n",
    "\n",
    "def plot_mask(data,layer_name):\n",
    "    img = data.select(layer_name)\n",
    "    img_mask = img.updateMask(img.eq(1))\n",
    "    Map.addLayer(img_mask, {'palette': 'red'}, f'{layer_name}')\n",
    "    \n",
    "def plot_rgb(img,text,bands = ['B4', 'B3', 'B2']):\n",
    "    viz_rgb = {'bands': bands,'gain': [0.1, 0.1, 0.1],'scale':90}\n",
    "    Map.addLayer(img, viz_rgb, text+' RGB')\n",
    "    \n",
    "def plot_false(img,text):\n",
    "    viz_rgb = {'bands': ['B6', 'B5', 'B2'],'gain': [0.1, 0.1, 0.1],'scale':90}\n",
    "    Map.addLayer(img, viz_rgb, text+' False')\n",
    "    \n",
    "def get_dates(data):\n",
    "    date= ee.Image(data).get('GENERATION_TIME')\n",
    "    return date\n",
    "\n",
    "def add_mnws(img):\n",
    "\n",
    "    band_names = ['B2','B3','B4','B5','B6','B7','B8','B8A','B11','B12']\n",
    "    multiband_img = img.select(band_names)\n",
    "    cluster_img = img.select('cluster')\n",
    "\n",
    "    samples = multiband_img.addBands(cluster_img).stratifiedSample(numPoints=100,classBand='cluster',scale=10,tileScale=4,seed=42,dropNulls=True)\n",
    "\n",
    "    nws_list = []\n",
    "    for label in list(range(0,8)):\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        for band in band_names:\n",
    "            img_band_mu = samples.filter(ee.Filter.eq('cluster',label)).aggregate_mean(band)\n",
    "            img_band_std = samples.filter(ee.Filter.eq('cluster',label)).aggregate_total_sd(band)\n",
    "\n",
    "            img_band_raw = multiband_img.select(band)\n",
    "            img_band_score = img_band_raw.subtract(img_band_mu).divide(img_band_std).pow(2).rename(f'{label} {band}')\n",
    "            \n",
    "            scores.append(img_band_score)\n",
    "\n",
    "        nws = ee.Image.cat(scores).reduce('sum').divide(len(band_names)).sqrt().rename('NWS')\n",
    "        nws_list.append(nws)\n",
    "\n",
    "    mnws = ee.Image.cat(nws_list).reduce('min').rename('MNWS')\n",
    "    return mnws\n",
    "\n",
    "def get_wd(img):\n",
    "    img_mnws = img.select('MNWS')\n",
    "    wd_i = img.expression('MNWS < 3',{'MNWS':img_mnws})\n",
    "    return wd_i\n",
    "\n",
    "def count_water_pixel(img):\n",
    "    count = img.select('RWS').gt(0).reduceRegion(ee.Reducer.sum(),scale=10,maxPixels=1e5,bestEffort=True,tileScale=4).values().get(0)\n",
    "    return img.set({'water_pixel': count})\n",
    "\n",
    "def export_frames(img_col,dir_name,annot_list):\n",
    "    \n",
    "    print(f'Exporting {len(annot_list)} frames...')\n",
    "    args = {'dimensions': 480,'bands': ['B11', 'B8', 'B3'],'gain': [0.08, 0.08, 0.08],'format':'png'}\n",
    "    url = img_col.getFilmstripThumbURL(args)\n",
    "    \n",
    "    os.makedirs(dir_name,exist_ok=True)\n",
    "\n",
    "    saved_strips = urllib.request.urlretrieve(url,f'{dir_name}.png')[0]\n",
    "    \n",
    "    img_arr = np.array(Image.open(saved_strips))\n",
    "    img_stack = img_arr.reshape(len(annot_list),img_arr.shape[0]//len(annot_list),img_arr.shape[1],img_arr.shape[2])\n",
    "    \n",
    "    for i in range(len(annot_list)):\n",
    "        img_pil = Image.fromarray(img_stack[i])\n",
    "        ImageDraw.Draw(img_pil).text((0, 0),annot_list[i],font = ImageFont.truetype(\"arial.ttf\", 20),fil=(0,191,255))\n",
    "        fn = f\"{dir_name}/{dir_name.split('/')[-1]}_{i}.png\"  \n",
    "        img_pil.save(fn)\n",
    "        \n",
    "    os.remove(saved_strips)\n",
    "    print(f'{len(annot_list)} frames exported in {dir_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Sentinel-2 Level-1C collection for 2016\n",
    "\n",
    "cl_pct = 40\n",
    "\n",
    "s2_col = ee.ImageCollection(\"COPERNICUS/S2\") \\\n",
    "    .filterBounds(line_geom).filterDate('2017-01-01','2018-12-31') \\\n",
    "    .filter(ee.Filter.inList('MGRS_TILE', ['36JVP','36JVQ'])) \\\n",
    "    .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', cl_pct))\n",
    "\n",
    "# #filter duplicated products \n",
    "s2_col_list = s2_col.toList(s2_col.size())\n",
    "\n",
    "print('Nr. images found: ', s2_col.size().getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique_dates = s2_col_list.map(get_dates).distinct()\n",
    "\n",
    "#iterave over collection and create mosaic based on similar datetime\n",
    "col = []\n",
    "for i in range(unique_dates.size().getInfo()):\n",
    "    unique_date = unique_dates.get(i)\n",
    "    date_day = ee.Date(unique_dates.get(i)).format('yyyy-MM-dd')\n",
    "    date_month = ee.Date(unique_dates.get(i)).format('yyyy-MM')\n",
    "    similar_tiles = s2_col.filter(ee.Filter.eq('GENERATION_TIME', unique_date)).mosaic().clip(poly_geom).set({'DateDay':date_day,'Month':date_month})\n",
    "    col.append(similar_tiles)\n",
    "    \n",
    "s2_mosaic_col_a = ee.ImageCollection(col)\n",
    "\n",
    "#iterate over mosaic again and merge based on similar days\n",
    "date_days = ee.List(s2_mosaic_col_a.aggregate_array('DateDay')).getInfo()\n",
    "days,count = np.unique(date_days, return_counts=True)\n",
    "dups = days[count>1]\n",
    "non_dups = np.setdiff1d(days,dups)\n",
    "\n",
    "dup_mos = ee.ImageCollection([s2_mosaic_col_a.filter(ee.Filter.eq('DateDay',dup)).mosaic().clip(poly_geom).set({'DateDay':dup}) for dup in dups.tolist()])\n",
    "non_dup_mos = s2_mosaic_col_a.filter(ee.Filter.inList('DateDay', non_dups.tolist()))\n",
    "\n",
    "s2_mosaic_col_clean = non_dup_mos.merge(dup_mos).sort('DateDay')\n",
    "\n",
    "print('Nr. mosaics created: ', len(date_days),len(days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter water pixel based on RWS (original)\n",
    "rws_ts = s2_mosaic_col_clean.map(add_rws).map(count_water_pixel).filter(ee.Filter.gt('water_pixel',100))\n",
    "rws_ts_dates = ee.List(rws_ts.aggregate_array('DateDay')).getInfo()\n",
    "wiw_ts = s2_mosaic_col_clean.map(add_wiw).filter(ee.Filter.inList('DateDay', rws_ts_dates))\n",
    "print('Mosaics with RWS area greater than 1ha: ',len(rws_ts_dates ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#export mosaics as png\n",
    "dir_name = './data/ts_animation/2017_cl100'\n",
    "# export_frames(s2_mosaic_col_clean,dir_name,days.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select best mosaics \n",
    "cleaned_dir_name = './data/ts_animation/2017_cl100_selected'\n",
    "selected_indices = np.sort(np.array(list(map(lambda x:x.split('_')[-1].split('.')[0],os.listdir(cleaned_dir_name)))).astype(int))\n",
    "selected_days = days[selected_indices].tolist()\n",
    "print(len(selected_days),'mosaics selected')\n",
    "\n",
    "#filter best mosaic from collection\n",
    "s2_mosaic_best = s2_mosaic_col_clean.filter(ee.Filter.inList('DateDay', selected_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map MNWS timeseries with RWS (original)\n",
    "mnws_ts_rws = rws_ts.map(add_kmeans).map(add_mnws)\n",
    "\n",
    "#map MNWS timeseries with WIW \n",
    "mnws_ts_wiw = wiw_ts.map(add_kmeans).map(add_mnws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate IWF with RWS\n",
    "img_wf_rws = mnws_ts_rws.map(get_wd).reduce(reducer=ee.Reducer.sum(),parallelScale=8).divide(len(rws_ts_dates))\n",
    "\n",
    "#calculate IWF with WIW\n",
    "img_wf_wiw = mnws_ts_wiw.map(get_wd).reduce(reducer=ee.Reducer.sum(),parallelScale=8).divide(len(rws_ts_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all bands stack to one geotiff\n",
    "geemap.ee_export_image(img_wf_rws, filename='./data/iwf/iwf_rws_80.tif', scale=90, region=poly_geom, file_per_band=False)\n",
    "geemap.ee_export_image(img_wf_wiw, filename='./data/iwf/iwf_wiw_80.tif', scale=90, region=poly_geom, file_per_band=False)\n",
    "\n",
    "remove_zips = list(map(lambda x:os.remove(x),glob('./data/iwf/*.zip')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export image collection as geotiff \n",
    "# geemap.ee_export_image_collection(mnws_ts, out_dir='./data/mnws_ts_wiw',region=poly_geom,scale=90)\n",
    "# remove_zips = list(map(lambda x:os.remove(x),glob('./data/mnws_ts_wiw/*.zip')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export image to drive\n",
    "# task = ee.batch.Export.image.toDrive(ee.Image(mnws_ts_list.get(0)), \n",
    "#                                      'output',\n",
    "#                                      folder='GEE_output',\n",
    "#                                     fileNamePrefix='mnws',\n",
    "#                                     crs='EPSG:32736',\n",
    "#                                     scale=10,\n",
    "#                                     maxPixels=1e8,\n",
    "#                                     fileFormat='GeoTIFF',\n",
    "#                                     skipEmptyTiles=True,\n",
    "#                                     region=ee_to_geojson(poly_geom)['coordinates'][0])\n",
    "# task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
